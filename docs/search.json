{
  "articles": [
    {
      "path": "1_data_wrangling.html",
      "title": "Data Wrangling",
      "description": "Cleaning and Merging Air Pollution, Weather and Calendar Datasets.\n",
      "author": [
        {
          "name": "Léo Zabrocki",
          "url": "https://lzabrocki.github.io/"
        },
        {
          "name": "Anna Alari",
          "url": "https://scholar.google.com/citations?user=MiFY320AAAAJ&hl=fr"
        },
        {
          "name": "Tarik Benmarhnia",
          "url": "https://profiles.ucsd.edu/tarik.benmarhnia"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\r\n\r\nContents\r\nRequired Packages\r\nCleaning Air Pollution Data\r\nCleaning Weather Data\r\nCleaning Calendar Data\r\nMerging All Datasets\r\nImputing Missing Values\r\nEDA of Missing Values\r\nUsing Chained Random Forest for Imputation\r\nActual Imputation\r\n\r\nLast Cleaning Steps\r\nCodebook\r\n\r\n\r\nbody {\r\ntext-align: justify}\r\nRequired Packages\r\nWe load the required packages:\r\n\r\n\r\n# load required packages\r\nlibrary(here) # for files paths organization\r\nlibrary(tidyverse) # for data manipulation and visualization\r\nlibrary(lubridate) # for manipulating date variables\r\nlibrary(missRanger) # for missing values imputation\r\nlibrary(Cairo) # for printing custom police of graphs\r\n\r\n\r\n\r\nWe also load our custom ggplot2 theme for graphs:\r\n\r\n\r\n# load ggplot custom theme\r\nsource(here::here(\r\n  \"inputs\",\r\n  \"2.functions\",\r\n  \"script_theme_tufte.R\"\r\n))\r\n# define nice colors\r\nmy_blue <- \"#0081a7\"\r\nmy_orange <- \"#fb8500\"\r\n\r\n\r\n\r\nCleaning Air Pollution Data\r\nAir pollution data comes from the background measuring stations of the Airparif. Using OpenStreetMap data and the osmdata package, we map below their location (see the script script_map_paris.R located in the “inputs/2.functions” folder for the code to reproduce the map). NO\\(_{2}\\) concentrations are measured at stations PA07, PA12, PA13, PA18; O\\(_{3}\\) concentrations at PA13, PA18; PM\\(_{10}\\) at PA18; PM\\(_{2.5}\\) at PA01H and PA04C. Grey lines represent the road network. The orange line is the orbital ring surrounding Paris. Blue crosses are the locations of air pollution measuring stations.\r\n\r\n\r\n\r\nWe load and clean NO\\(_{2}\\) data:\r\n\r\n\r\n# clean no2 data\r\ndata_no2 <-\r\n  data.table::fread(\r\n    here::here(\r\n      \"inputs\", \"1.data\",\r\n      \"1.air_pollutants_data\",\r\n      \"20080101_20200901-NO2_auto.csv\"\r\n    ),\r\n    check.names = TRUE\r\n  ) %>%\r\n  select(date, heure, PA01H, PA04C, PA06, PA07, PA12, PA13, PA15L, PA18) %>%\r\n  # drop first line\r\n  slice(-1) %>%\r\n  # paste the elements of date together\r\n  mutate(date = paste(date, heure, sep = \"/\")) %>%\r\n  # convert to date\r\n  mutate(date = lubridate::dmy_h(date)) %>%\r\n  select(-heure) %>%\r\n  rename_all( ~ tolower(.)) %>%\r\n  mutate_at(vars(-date), ~ as.numeric(.)) %>%\r\n  filter(date > \"2008-01-01 00:00:00\" &\r\n           date <= \"2019-01-01 00:00:00\")\r\n\r\n# select relevant measuring stations\r\ndata_no2 <- data_no2 %>%\r\n  select(date, pa07, pa12, pa13, pa18) %>%\r\n  rename_at(vars(-date), ~ paste(\"mean_no2\", ., sep = \"_\"))\r\n\r\n\r\n\r\nWe load and clean O\\(_{3}\\) data:\r\n\r\n\r\n# clean o3 data\r\ndata_o3 <-\r\n  data.table::fread(\r\n    here::here(\r\n      \"inputs\", \"1.data\",\r\n      \"1.air_pollutants_data\",\r\n      \"20080101_20200901-O3_auto.csv\"\r\n    ),\r\n    check.names = TRUE\r\n  ) %>%\r\n  select(date, heure, PA01H, PA04C, PA06, PA13, PA18) %>%\r\n  # drop first line\r\n  slice(-1) %>%\r\n  # paste the elements of date together\r\n  mutate(date = paste(date, heure, sep = \"/\")) %>%\r\n  # convert to date\r\n  mutate(date = lubridate::dmy_h(date)) %>%\r\n  select(-heure) %>%\r\n  rename_all( ~ tolower(.)) %>%\r\n  mutate_at(vars(-date), ~ as.numeric(.)) %>%\r\n  filter(date > \"2008-01-01 00:00:00\" &\r\n           date <= \"2019-01-01 00:00:00\")\r\n\r\n# select relevant measuring stations\r\ndata_o3 <- data_o3 %>%\r\n  select(date, pa13, pa18) %>%\r\n  rename_at(vars(-date), ~ paste(\"mean_o3\", ., sep = \"_\"))\r\n\r\n\r\n\r\nWe load and clean PM\\(_{10}\\) data:\r\n\r\n\r\n# clean pm10 data\r\ndata_pm10 <-\r\n  data.table::fread(\r\n    here::here(\r\n      \"inputs\", \"1.data\",\r\n      \"1.air_pollutants_data\",\r\n      \"20080101_20200901-PM10_auto.csv\"\r\n    ),\r\n    check.names = TRUE\r\n  ) %>%\r\n  select(date, heure, PA01H, PA04C, PA15L, PA18) %>%\r\n  # drop first line\r\n  slice(-1) %>%\r\n  # paste the elements of date together\r\n  mutate(date = paste(date, heure, sep = \"/\")) %>%\r\n  # convert to date\r\n  mutate(date = lubridate::dmy_h(date)) %>%\r\n  select(-heure) %>%\r\n  rename_all( ~ tolower(.)) %>%\r\n  mutate_at(vars(-date), ~ as.numeric(.)) %>%\r\n  filter(date > \"2008-01-01 00:00:00\" &\r\n           date <= \"2019-01-01 00:00:00\")\r\n\r\n# select relevant measuring stations\r\ndata_pm10 <- data_pm10 %>%\r\n  select(date, pa18)  %>%\r\n  rename_at(vars(-date), ~ paste(\"mean_pm10\", ., sep = \"_\"))\r\n\r\n\r\n\r\nWe load and clean PM\\(_{2.5}\\) data:\r\n\r\n\r\n# clean pm2.5 data\r\ndata_pm25 <-\r\n  data.table::fread(\r\n    here::here(\r\n      \"inputs\", \"1.data\",\r\n      \"1.air_pollutants_data\",\r\n      \"20080101_20200901-PM25_auto.csv\"\r\n    ),\r\n    check.names = TRUE\r\n  ) %>%\r\n  select(date, heure, PA01H, PA04C) %>%\r\n  # drop first line\r\n  slice(-1) %>%\r\n  # paste the elements of date together\r\n  mutate(date = paste(date, heure, sep = \"/\")) %>%\r\n  # convert to date\r\n  mutate(date = lubridate::dmy_h(date)) %>%\r\n  select(-heure) %>%\r\n  rename_all( ~ tolower(.)) %>%\r\n  mutate_at(vars(-date), ~ as.numeric(.)) %>%\r\n  filter(date > \"2008-01-01 00:00:00\" &\r\n           date <= \"2019-01-01 00:00:00\") %>%\r\n  pivot_longer(cols = -c(date),\r\n               names_to = \"variable\",\r\n               values_to = \"concentration\") %>%\r\n  group_by(date) %>%\r\n  summarise(mean_pm25 = mean(concentration, na.rm = TRUE))\r\n\r\n\r\n\r\nMerge all pollutants variables together:\r\n\r\n\r\n# merge pollutants\r\ndata_pollutants <- left_join(data_no2, data_o3, by = \"date\") %>%\r\n  left_join(., data_pm10, by = \"date\") %>%\r\n  left_join(., data_pm25, by = \"date\") %>%\r\n  # add date at the daily level\r\n  mutate(date = str_sub(date, 1, 10) %>% ymd(.))\r\n\r\n\r\n\r\nCompute the average concentration for each day by pollutant. We use the following procedure:\r\nWe compute a 2.5% trimmed mean to average the hourly concentrations at the daily level.\r\nFor days with more than 3 missing hourly concentrations, we set the daily mean to missing.\r\n\r\n\r\n# compute number of missing values\r\ndata_pollutants_missing <- data_pollutants %>%\r\n  group_by(date) %>%\r\n  summarise_at(vars(mean_no2_pa07:mean_pm25), ~ sum(is.na(.))) %>%\r\n  pivot_longer(\r\n    cols = c(mean_no2_pa07:mean_pm25),\r\n    names_to = \"pollutant\",\r\n    values_to = \"n_missing\"\r\n  )\r\n\r\n# compute daily averages\r\ndata_pollutants <- data_pollutants %>%\r\n  pivot_longer(\r\n    cols = c(mean_no2_pa07:mean_pm25),\r\n    names_to = \"pollutant\",\r\n    values_to = \"concentration\"\r\n  ) %>%\r\n  left_join(., data_pollutants_missing, by = c(\"date\", \"pollutant\")) %>%\r\n  group_by(date, pollutant) %>%\r\n  summarise(daily_concentration = ifelse(n_missing <= 3, mean(concentration, trim =                                                              0.025, na.rm = TRUE), NA)) %>%\r\n  group_by(date, pollutant) %>%\r\n  summarise(daily_concentration = mean(daily_concentration)) %>%\r\n  pivot_wider(., names_from = pollutant, values_from = daily_concentration)\r\n\r\n\r\n\r\nCleaning Weather Data\r\nWe load and clean weather data. Since we were not allowed to share the data from Météo-France, we decided to add some noise to the variables to make the analysis reproducible by other researchers:\r\n\r\n\r\n# read the data and rename the variables\r\nweather_data <-\r\n  read.csv(\r\n    here::here(\r\n      \"inputs\", \"1.data\",\r\n      \"2.weather_data\",\r\n      \"daily_weather_data_paris_2008_2018.txt\"\r\n    ),\r\n    header = TRUE,\r\n    sep = \",\",\r\n    stringsAsFactors = FALSE,\r\n    dec = \".\"\r\n  ) %>%\r\n  rename(\r\n    \"date\" = \"DATE\",\r\n    \"rainfall_height\" = \"RR\",\r\n    \"rainfall_duration\" = \"DRR\",\r\n    \"temperature_average\" = \"TM\",\r\n    \"humidity_average\" = \"UM\",\r\n    \"wind_speed\" = \"FXY\",\r\n    \"wind_direction\" = \"DXY\"\r\n  ) %>%\r\n  select(-POSTE)\r\n\r\n# convert date variable in date format\r\nweather_data <- weather_data %>%\r\n  mutate(date = lubridate::ymd(weather_data$date)) %>%\r\n  filter(date <= \"2018-12-31\")\r\n\r\n# select relevant variables\r\nweather_data <- weather_data %>%\r\n  select(\r\n    date,\r\n    temperature_average,\r\n    rainfall_duration,\r\n    humidity_average,\r\n    wind_speed,\r\n    wind_direction\r\n  )\r\n\r\n\r\n\r\nCleaning Calendar Data\r\nFirst, we create a dataframe with the date variable, the year, the month, and the day of the week:\r\n\r\n\r\n# create a dataframe with the date variable\r\ndates_data <-\r\n  tibble(date = seq.Date(\r\n    from = as.Date(\"2008-01-01\"),\r\n    to = as.Date(\"2018-12-31\"),\r\n    by = \"day\"\r\n  ))\r\n\r\n# create julian data: the starting date is 2008-01-01\r\ndates_data <- dates_data %>%\r\n  mutate(julian_date = 1:n())\r\n\r\n# create year, month and day of the week indicators\r\ndates_data <- dates_data %>%\r\n  mutate(\r\n    year = lubridate::year(date),\r\n    month = lubridate::month(date, label = TRUE, abbr = FALSE),\r\n    weekday = lubridate::wday(date, label = TRUE, abbr = FALSE)\r\n  )\r\n\r\n# reorder day of the week levels\r\ndates_data <- dates_data %>%\r\n  mutate(weekday = ordered(\r\n    weekday,\r\n    levels = c(\r\n      \"Monday\",\r\n      \"Tuesday\",\r\n      \"Wednesday\",\r\n      \"Thursday\",\r\n      \"Friday\",\r\n      \"Saturday\",\r\n      \"Sunday\"\r\n    )\r\n  ))\r\n\r\n# create weekend dummy\r\ndates_data <- dates_data %>%\r\n  mutate(weekend = ifelse(weekday %in% c(\"Saturday\", \"Sunday\"), \"Weekend\", \"Work Days\") %>% as_factor(.))\r\n\r\n\r\n\r\nThen, we load two datasets on holidays and bank days indicators:\r\n\r\n\r\n# cleaning holidays data\r\ndata_holidays <-\r\n  read.csv(\r\n    here::here(\"inputs\", \"1.data\", \"3.calendar_data\", \"data_holidays.csv\"),\r\n    stringsAsFactors = FALSE,\r\n    encoding = \"UTF-8\"\r\n  ) %>%\r\n  select(date, vacances_zone_c, nom_vacances) %>%\r\n  rename(holidays_dummy = vacances_zone_c, holidays_name = nom_vacances) %>%\r\n  mutate(holidays_dummy = ifelse(holidays_dummy == \"True\", 1, 0)) %>%\r\n  mutate(date = lubridate::ymd(date)) %>%\r\n  filter(date >= \"2008-01-01\" & date <= \"2018-12-31\")\r\n\r\n# cleaning bank days data\r\ndata_bank_days <-\r\n  read.csv(\r\n    here::here(\"inputs\", \"1.data\", \"3.calendar_data\", \"data_bank_days.csv\"),\r\n    stringsAsFactors = FALSE,\r\n    encoding = \"UTF-8\"\r\n  ) %>%\r\n  rename(bank_day_dummy = est_jour_ferie, name_bank_day = nom_jour_ferie) %>%\r\n  mutate(bank_day_dummy = ifelse(bank_day_dummy == \"True\", 1, 0)) %>%\r\n  mutate(date = lubridate::ymd(date)) %>%\r\n  filter(date >= \"2008-01-01\" & date <= \"2018-12-31\")\r\n\r\n\r\n\r\nWe merge the three datasets together:\r\n\r\n\r\n# merge the three datasets together\r\ndata_calendar <-\r\n  left_join(dates_data, data_holidays, by = \"date\") %>%\r\n  left_join(., data_bank_days, by = \"date\")\r\n\r\n\r\n\r\nMerging All Datasets\r\nWe merge all datasets together:\r\n\r\n\r\ndata <- left_join(data_calendar, data_pollutants, by = \"date\") %>%\r\n  left_join(., weather_data, by = \"date\")\r\n\r\n\r\n\r\nImputing Missing Values\r\nEDA of Missing Values\r\nWe first display below the proportion (%) of missing values for each variable:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# compute proportion of missing observations\r\ndata %>%\r\n  pivot_longer(\r\n    cols = c(mean_no2_pa07:wind_direction),\r\n    names_to = \"Variable\",\r\n    values_to = \"value\"\r\n  ) %>%\r\n  group_by(Variable) %>%\r\n  summarise(\"Proportion Missing (%)\" = round(sum(is.na(value)) / n() * 100, 1)) %>%\r\n  arrange(-`Proportion Missing (%)`) %>%\r\n  knitr::kable(., align = c(\"l\", \"c\"))\r\n\r\n\r\nVariable\r\nProportion Missing (%)\r\nmean_pm25\r\n24.5\r\nmean_pm10_pa18\r\n9.1\r\nmean_o3_pa18\r\n5.2\r\nmean_no2_pa12\r\n4.4\r\nmean_no2_pa18\r\n4.3\r\nmean_no2_pa13\r\n4.2\r\nmean_o3_pa13\r\n3.7\r\nmean_no2_pa07\r\n2.8\r\nrainfall_duration\r\n2.5\r\nwind_direction\r\n0.6\r\nwind_speed\r\n0.6\r\nhumidity_average\r\n0.1\r\ntemperature_average\r\n0.0\r\n\r\nWe see that all air pollutants have at least 10% of their observations missing. To better understand when values are missing, we plot below the distribution of the missing dummy for each variable over time:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# make stripes graph\r\ngraph_stripes_missing <- data %>%\r\n    pivot_longer(\r\n    cols = c(mean_no2_pa07:wind_direction),\r\n    names_to = \"variable\",\r\n    values_to = \"value\"\r\n  ) %>%\r\n  mutate(is_missing = ifelse(is.na(value), \"Missing\", \"Not Missing\")) %>%\r\n  ggplot(., aes(x = date, y = 1, fill = is_missing)) +\r\n  geom_tile() +\r\n  scale_y_continuous(expand = c(0, 0)) +\r\n  facet_wrap( ~ variable, scales = \"free\") +\r\n  scale_fill_manual(name = \"Daily Observations:\", values = c(my_orange, my_blue)) +\r\n  xlab(\"Date\") + ylab(\"\") +\r\n  theme_tufte() +\r\n  theme(axis.ticks.y = element_blank(),\r\n        axis.text.y = element_blank())\r\n\r\n# display the graph\r\ngraph_stripes_missing\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the graph\r\nggsave(\r\n  graph_stripes_missing,\r\n  filename = here::here(\"inputs\", \"3.outputs\", \"1.eda\", \"graph_stripes_missing.pdf\"),\r\n  width = 30,\r\n  height = 15,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nWe can see that the station measuring PM\\(_{2.5}\\) stopped twice recording concentrations over a long period of time. For the other pollutants, the stations stopped recording concentrations over much shorter periods. We will therefore not impute the missing values of PM\\(_{2.5}\\) because they are missing over too long consecutive periods of days.\r\nWe can also explore how missing values are distributed by weekday:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# make graph missing weekday\r\ngraph_weekday_missing <- data %>%\r\n  pivot_longer(\r\n    cols = c(mean_no2_pa07:mean_pm25),\r\n    names_to = \"pollutant\",\r\n    values_to = \"concentration\"\r\n  ) %>%\r\n  group_by(pollutant, weekday) %>%\r\n  summarise(proportion_missing = sum(is.na(concentration)) / n() * 100) %>%\r\n  ggplot(., aes(x = weekday, y = proportion_missing)) +\r\n  geom_segment(aes(x = weekday, xend = weekday, y = 0, yend = proportion_missing), size = 0.5) +\r\n  geom_point(colour = my_orange, size = 4) +\r\n  facet_wrap(~ pollutant) +\r\n  xlab(\"Day of the Week\") + ylab(\"Missing Proportion (%)\") +\r\n  theme_tufte()\r\n  \r\n  \r\n# display the graph\r\ngraph_weekday_missing\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the graph\r\nggsave(\r\n  graph_weekday_missing,\r\n  filename = here::here(\"inputs\", \"3.outputs\", \"1.eda\", \"graph_weekday_missing.pdf\"),\r\n  width = 40,\r\n  height = 20,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)  \r\n\r\n\r\n\r\nWe see that missing concentrations occur less on weekends. We make the same plot but by month:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# make graph missing month\r\ngraph_month_missing <- data %>%\r\n  pivot_longer(\r\n    cols = c(mean_no2_pa07:mean_pm25),\r\n    names_to = \"pollutant\",\r\n    values_to = \"concentration\"\r\n  ) %>%\r\n  group_by(pollutant, month) %>%\r\n  summarise(proportion_missing = sum(is.na(concentration)) / n() * 100) %>%\r\n  ggplot(., aes(x = month, y = proportion_missing, group = \"l\")) +\r\n  geom_line(colour = \"gray80\") +\r\n  geom_point(colour = my_orange, size = 4) +\r\n  facet_wrap(~ pollutant, ncol = 1) +\r\n  xlab(\"Month\") + ylab(\"Missing Proportion (%)\") +\r\n  theme_tufte()\r\n  \r\n# display the graph\r\ngraph_month_missing\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the graph\r\nggsave(\r\n  graph_month_missing,\r\n  filename = here::here(\"inputs\", \"3.outputs\", \"1.eda\", \"graph_month_missing.pdf\"),\r\n  width = 28,\r\n  height = 40,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)  \r\n\r\n\r\n\r\nWe do not see a clear pattern of missingness depending on the month of year. Overall, missing values are not missing completely are random but we can use values from past and future periods and those coming from other stations to impute them.\r\nLast but not least, before imputing the missing values, we save a dataset with the observed concentrations aggregated at the city-level. This dataset will be used as a robutness check to see if our results depend on our imputation procedure.\r\n\r\n\r\n# aggregation of each pollutant's concentrations at the city level\r\n# when concentrations are not imputed\r\ndata_not_imputed <- data %>%\r\n  select(date,mean_no2_pa07:mean_pm25) %>%\r\n  rowwise() %>%\r\n  mutate(mean_no2 = mean(c(\r\n    mean_no2_pa07, mean_no2_pa12, mean_no2_pa13, mean_no2_pa18\r\n  )),\r\n  mean_o3 = mean(c(mean_o3_pa13, mean_o3_pa18)),\r\n  mean_pm10 = mean_pm10_pa18) %>%\r\n  select(date, mean_pm25:mean_pm10) %>%\r\n  rename_at(vars(mean_pm25:mean_pm10), ~ paste(\"not_imputed\", ., sep = \"_\")) %>%\r\n  ungroup()\r\n\r\n# save the dataset\r\nsaveRDS(data_not_imputed, here::here(\"inputs\", \"1.data\", \"4.data_for_analysis\", \"data_pollutants_not_imputed.RDS\"))\r\n\r\n\r\n\r\nUsing Chained Random Forest for Imputation\r\nBefore imputing missing values, we carry out a small simulation exercise where we keep rows without any missing values and then randomly erase 20% of the observations for two air pollutants:\r\n\r\n\r\n# create data_test with missing values\r\ndata_test_missing <- data %>%\r\n  select(date, year:weekday, holidays_dummy, bank_day_dummy, mean_no2_pa07:wind_direction, -mean_pm25) %>%\r\n# drop rows with at least a missing value\r\n  drop_na() %>%\r\n# create an index\r\n  mutate(id = seq(1:nrow(.)))\r\n\r\n# sample rows indexes where missing values will be erased\r\nset.seed(42)\r\nindex_missing <- sample(1:nrow(data_test_missing), round(nrow(data_test_missing)*0.2, 0))\r\n\r\n# erase values for two pollutants\r\ndata_test_missing <- data_test_missing %>%\r\n  mutate_at(vars(mean_no2_pa12, mean_pm10_pa18), ~ ifelse(id %in% index_missing, NA, .))\r\n\r\n# create data_test with observed values\r\ndata_test_observed <- data %>%\r\n  select(date, year:weekday, holidays_dummy, bank_day_dummy, mean_no2_pa07:wind_direction, - mean_pm25) %>%\r\n# drop rows with at least a missing value\r\n  drop_na() %>%\r\n# create an index\r\n  mutate(id = seq(1:nrow(.))) %>%\r\n# add dataset indicator\r\n  mutate(data = \"Observed\")\r\n\r\n\r\n\r\nWe impute the missing values using the chained forest algorithm:\r\n\r\n\r\n# imputation of missing values\r\ndata_test_imputed <- missRanger::missRanger(data_test_missing, mean_no2_pa12 + mean_pm10_pa18 ~ . -date - id,\r\n                               splitrule = \"extratrees\",\r\n                               pmm.k = 10,\r\n                               num.trees = 100,\r\n                               seed = 42)\r\n\r\n\r\n\r\nMissing value imputation by random forests\r\n\r\n  Variables to impute:      mean_no2_pa12, mean_pm10_pa18\r\n  Variables used to impute: year, month, weekday, holidays_dummy, bank_day_dummy, mean_no2_pa07, mean_no2_pa12, mean_no2_pa13, mean_no2_pa18, mean_o3_pa13, mean_o3_pa18, mean_pm10_pa18, temperature_average, rainfall_duration, humidity_average, wind_speed, wind_direction\r\niter 1: ..\r\niter 2: ..\r\niter 3: ..\r\niter 4: ..\r\niter 5: ..\r\niter 6: ..\r\n\r\nWe then compare the distribution of true and imputed concentrations for each air pollutant:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# add dataset indicator\r\ndata_test_imputed <- data_test_imputed %>%\r\n  filter(id %in% index_missing) %>%\r\n  mutate(data = \"Imputed\") %>%\r\n  select(data, id, mean_no2_pa12, mean_pm10_pa18)\r\n\r\n# bind the imputed and observed datasets\r\ndata_imputation_comparison <- data_test_observed %>%\r\n  filter(id %in% index_missing) %>%\r\n  select(data, id, mean_no2_pa12, mean_pm10_pa18) %>%\r\n  bind_rows(., data_test_imputed) \r\n\r\n# plotting density distributions\r\ngraph_imputation <- data_imputation_comparison %>%\r\n  pivot_longer(cols = c(mean_no2_pa12, mean_pm10_pa18), names_to = \"pollutant\", values_to = \"concentration\") %>%\r\n  ggplot(.,  aes(x = concentration, fill = data)) +\r\n  geom_density(alpha = 0.2, colour = NA) +\r\n  scale_fill_manual(name = \"Observations:\", values=c(my_orange, my_blue)) +\r\n  facet_wrap(~ pollutant, nrow = 1, scales = \"free_x\") +\r\n  ylab(\"Density\") +\r\n  xlab(\"Concentration (µg/m³)\") + \r\n  labs(colour = \"Observations:\") +\r\n  theme_tufte()\r\n\r\n# display the graph\r\ngraph_imputation\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the graph\r\nggsave(\r\n  graph_imputation,\r\n  filename = here::here(\"inputs\", \"3.outputs\", \"1.eda\", \"graph_imputation.pdf\"),\r\n  width = 15,\r\n  height = 10,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)  \r\n\r\n\r\n\r\nWe see that the two distributions overlap relatively well. We also compute the mean absolute difference of concentrations for each pollutant:\r\n\r\n\r\nPlease show me the code!\r\n\r\ndata_imputation_comparison %>%\r\n  pivot_longer(cols = -c(data, id), names_to = \"Pollutant\", values_to = \"concentration\") %>%\r\n  pivot_wider(names_from = data, values_from = concentration) %>%\r\n  group_by(Pollutant) %>%\r\n  summarise(\"Absolute Difference\" = mean(abs(Observed - Imputed)),\r\n            \"Root Mean Square Error\" = sqrt(mean((Observed - Imputed)^2)),\r\n            \"Mean Concentration\" = mean(Observed),\r\n            \"Standard Deviation\" = sd(Observed)) %>%\r\n  mutate_at(vars(-Pollutant), ~ round(., 1)) %>%\r\n  knitr::kable(., align = c(\"l\", \"c\", \"c\", \"c\", \"c\"))\r\n\r\n\r\nPollutant\r\nAbsolute Difference\r\nRoot Mean Square Error\r\nMean Concentration\r\nStandard Deviation\r\nmean_no2_pa12\r\n3.2\r\n4.2\r\n37.6\r\n13.9\r\nmean_pm10_pa18\r\n6.1\r\n9.1\r\n23.4\r\n12.3\r\n\r\nThe absolute difference is small for NO\\(_{2}\\) but high for PM\\(_{10}\\). Of course, when many variables have a large fraction of missing values and missing values occurring on the same date, the algorithm could completely fail to correctly impute the values.\r\nActual Imputation\r\nWe finally impute missing values using the missRanger package:\r\n\r\n\r\n# set the seed\r\nset.seed(42)\r\n\r\n# imputation of missing values\r\ndata <- missRanger::missRanger(\r\n  data,\r\n  # variables to impute\r\n  mean_no2_pa07 +\r\n    mean_no2_pa12 +\r\n    mean_no2_pa13 +\r\n    mean_no2_pa18 +\r\n    mean_o3_pa13 +\r\n    mean_o3_pa18 +\r\n    mean_pm10_pa18 +\r\n    rainfall_duration +\r\n    humidity_average +\r\n    wind_speed +\r\n    wind_direction -\r\n    mean_pm25 ~\r\n    # variables used for the imputation\r\n    . - date - julian_date - weekend - holidays_name - name_bank_day,\r\n  pmm.k = 10,\r\n  num.trees = 100\r\n)\r\n\r\n\r\n\r\nMissing value imputation by random forests\r\n\r\n  Variables to impute:      mean_no2_pa07, mean_no2_pa12, mean_no2_pa13, mean_no2_pa18, mean_o3_pa13, mean_o3_pa18, mean_pm10_pa18, rainfall_duration, humidity_average, wind_speed, wind_direction\r\n  Variables used to impute: year, month, weekday, holidays_dummy, bank_day_dummy, mean_no2_pa07, mean_no2_pa12, mean_no2_pa13, mean_no2_pa18, mean_o3_pa13, mean_o3_pa18, mean_pm10_pa18, temperature_average, rainfall_duration, humidity_average, wind_speed, wind_direction\r\niter 1: ...........\r\niter 2: ...........\r\niter 3: ...........\r\niter 4: ...........\r\niter 5: ...........\r\niter 6: ...........\r\n\r\n# dirty fix for wind_direction imputed values equal to 370 \r\ndata <- data %>%\r\n  mutate(wind_direction = ifelse(wind_direction == 370, 10, wind_direction))\r\n\r\n\r\n\r\nLast Cleaning Steps\r\nWe cut the rainfall duration into quartiles and wind direction into the main four directions:\r\n\r\n\r\n# add rainfall duration quartiles\r\ndata <- data %>%\r\n  mutate(rainfall_duration = Hmisc::cut2(rainfall_duration, g = 4)) %>%\r\n  # create wind direction categories\r\n  mutate(\r\n    wind_direction_categories = cut(\r\n      wind_direction,\r\n      breaks = seq(0, 360, by  = 90),\r\n      include.lowest = TRUE\r\n    ) %>%\r\n      recode(\r\n        .,\r\n        \"[0,90]\" = \"North-East\",\r\n        \"(90,180]\" = \"South-East\",\r\n        \"(180,270]\" = \"South-West\",\r\n        \"(270,360]\" = \"North-West\"\r\n      )\r\n  ) \r\n\r\n\r\n\r\nWe finally aggregate air pollutant concentrations at the city level:\r\n\r\n\r\n# aggregation of each pollutant's concentrations at the city level\r\ndata <- data %>%\r\n  rowwise() %>%\r\n  mutate(mean_no2 = mean(c(\r\n    mean_no2_pa07, mean_no2_pa12, mean_no2_pa13, mean_no2_pa18\r\n  )),\r\n  mean_o3 = mean(c(mean_o3_pa13, mean_o3_pa18)),\r\n  mean_pm10 = mean_pm10_pa18) %>%\r\n  ungroup()\r\n\r\n\r\n\r\nWe finally select relevant variables and save the data:\r\n\r\n\r\ndata %>%\r\n  select(\r\n    date:holidays_dummy,\r\n    bank_day_dummy,\r\n    mean_no2,\r\n    mean_o3,\r\n    mean_pm10,\r\n    mean_pm25,\r\n    mean_no2_pa07,\r\n    mean_no2_pa12,\r\n    mean_no2_pa13,\r\n    mean_no2_pa18,\r\n    mean_o3_pa13,\r\n    mean_o3_pa18,\r\n    mean_pm10_pa18,\r\n    mean_pm25,\r\n    temperature_average:wind_speed,\r\n    wind_direction,\r\n    wind_direction_categories\r\n  ) %>%\r\n  saveRDS(.,\r\n          here::here(\"inputs\", \"1.data\", \"4.data_for_analysis\", \"data_for_analysis.RDS\"))\r\n\r\n\r\n\r\nCodebook\r\nWe load below the codebook of the data:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# load the codebook\r\nread.csv(here::here(\"inputs\", \"1.data\", \"4.data_for_analysis\", \"codebook.csv\"), sep = \",\") %>%\r\n  DT::datatable(.)\r\n\r\n\r\n\r\n{\"x\":{\"filter\":\"none\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\"],[\"date\",\"julian_date\",\"year\",\"month\",\"weekday\",\"holidays_dummy\",\"bank_day_dummy\",\"mean_no2\",\"mean_o3\",\"mean_pm10\",\"mean_pm25\",\"temperature_average\",\"rainfall_duration\",\"humidity_average\",\"wind_speed\",\"wind_direction\",\"wind_direction_categories\"],[\"date of the day in year-month-day\",\"index of the day from 2008 to 2018\",\"year of the day\",\"month of the day\",\"day of the week\",\"dummy equal to 1 if the day belongs to holidays\",\"dummy equal to 1 if the day is a bank day\",\"concentration of nitrogen dioxide in µg/m3\",\"concentration of ozone in µg/m3\",\"concentration of coarse particulate matters in µg/m3\",\"concentration of fine particulate matters in µg/m3\",\"average temperature in °c\",\"rainfall duration in min\",\"relative humidity in %\",\"wind speed in m/s\",\"wind direction measured on 360° compass where 0° is the true north\",\"wind direction divided in four categories (north-east\"],[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\" south-east\"],[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\" south-west\"],[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\" north-west)\"]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>variable_name<\\/th>\\n      <th>definition<\\/th>\\n      <th>X<\\/th>\\n      <th>X.1<\\/th>\\n      <th>X.2<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"order\":[],\"autoWidth\":false,\"orderClasses\":false,\"columnDefs\":[{\"orderable\":false,\"targets\":0}]}},\"evals\":[],\"jsHooks\":[]}\r\n\r\n\r\n\r\n",
      "last_modified": "2022-04-08T10:17:22+02:00"
    },
    {
      "path": "2_eda.html",
      "title": "Exploratory Data Analysis",
      "description": "Wind Patterns & Air Pollution in Paris, France.\n",
      "author": [
        {
          "name": "Léo Zabrocki",
          "url": "https://lzabrocki.github.io/"
        },
        {
          "name": "Anna Alari",
          "url": "https://scholar.google.com/citations?user=MiFY320AAAAJ&hl=fr"
        },
        {
          "name": "Tarik Benmarhnia",
          "url": "https://profiles.ucsd.edu/tarik.benmarhnia"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\r\n\r\nContents\r\nRequired Packages\r\nGeneral EDA\r\nWind Direction & Air Pollutants\r\nWind Direction & Other Weather Parameters\r\nWind Direction & Calendar Indicators\r\n\r\nCovariates Imbalance EDA\r\nDefining Treatment\r\nWeather Covariates Imbalance\r\nCalendar Imbalance\r\n\r\n\r\n\r\nbody {\r\ntext-align: justify}\r\nIn this document, we carry out an exploratory data analysis to understand the relationships of wind patterns with other variables:\r\nWe first explore general patterns related to wind directions.\r\nWe then check if covariates are balanced when we define treated days as units with North-East winds and control days as units where winds blow from other directions.\r\nShould you have any questions, need help to reproduce the analysis or find coding errors, please do not hesitate to contact me at leo.zabrocki@psemail.eu\r\nRequired Packages\r\nTo reproduce exactly the script_eda.html document, we first need to have installed:\r\nthe R programming language on your computer\r\nRStudio, an integrated development environment for R, which will allow you to knit the script_eda.Rmd file and interact with the R code chunks\r\nthe R Markdown package\r\nand the Distill package which provides the template of this document.\r\nOnce everything is set up, we have to load the following packages:\r\n\r\n\r\n# load required packages\r\nlibrary(knitr) # for creating the R Markdown document\r\nlibrary(here) # for files paths organization\r\nlibrary(tidyverse) # for data manipulation and visualization\r\nlibrary(ggridges) # for ridge plots\r\nlibrary(openair) # polar plots\r\n\r\n\r\n\r\nWe load our custom ggplot2 theme for graphs:\r\n\r\n\r\n# load ggplot custom theme\r\nsource(here::here(\r\n    \"inputs\", \"2.functions\",\r\n  \"script_theme_tufte.R\"\r\n))\r\n# define nice colors\r\nmy_blue <- \"#0081a7\"\r\nmy_orange <- \"#fb8500\"\r\n\r\n\r\n\r\nWe finally load the data:\r\n\r\n\r\n# load data\r\ndata <-\r\n  readRDS(here::here(\"inputs\", \"1.data\", \"4.data_for_analysis\", \"data_for_analysis.RDS\"))\r\n\r\n\r\n\r\nGeneral EDA\r\nWe explore general patterns related to wind directions.\r\nWind Direction & Air Pollutants\r\nWe plot the distribution of PM10 concentration by wind direction:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# make the graph\r\ngraph_wd_pm10 <- data %>%\r\n  ggplot(., aes(x = mean_pm10, y = fct_rev(wind_direction_categories))) +\r\n  geom_density_ridges(\r\n    color = NA,\r\n    size = 0.3,\r\n    fill = my_blue,\r\n    alpha = 0.8\r\n  ) +\r\n  scale_x_continuous(breaks = scales::pretty_breaks(n = 8)) +\r\n  xlab(\"Concentration (µg/m³)\") +\r\n  ylab(\"Wind Direction\") +\r\n  theme_tufte() +\r\n  theme(axis.title.y = element_text(angle = 90, hjust = 1))\r\n\r\n# display the graph\r\ngraph_wd_pm10\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the graph\r\nggsave(\r\n  graph_wd_pm10,\r\n  filename = here::here(\"inputs\", \"3.outputs\", \"1.eda\", \"graph_wd_pm10.pdf\"),\r\n  width = 15,\r\n  height = 8,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nWe plot the distribution of all pollutant concentrations by wind direction:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# make the graph\r\ngraph_wd_pollutants <- data %>%\r\n  rename(\r\n    \"PM10\" = mean_pm10,\r\n    \"PM2.5\" = mean_pm25,\r\n    \"NO2\" = mean_no2,\r\n    \"O3\" = mean_o3\r\n  ) %>%\r\n  pivot_longer(\r\n    cols = c(PM10, PM2.5, NO2, O3),\r\n    names_to = \"pollutant\",\r\n    values_to = \"concentration\"\r\n  ) %>%\r\n  ggplot(.,  aes(x = concentration, y = fct_rev(wind_direction_categories))) +\r\n  geom_density_ridges(\r\n    color = NA,\r\n    size = 0.3,\r\n    fill = my_blue,\r\n    alpha = 0.8\r\n  ) +\r\n  scale_x_continuous(breaks = scales::pretty_breaks(n = 8)) +\r\n  facet_wrap( ~ pollutant, scales = \"free\") +\r\n  xlab(\"Concentration (µg/m³)\") +\r\n  ylab(\"Wind Direction\") +\r\n  theme_tufte()\r\n\r\n# display the graph\r\ngraph_wd_pollutants\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the graph\r\nggsave(\r\n  graph_wd_pollutants,\r\n  filename = here::here(  \"inputs\", \"3.outputs\", \"1.eda\", \"graph_wd_pollutants.pdf\"),\r\n  width = 20,\r\n  height = 12,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nUsing the openair package, we predict air pollutant concentrations using wind components:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# select relevant variables for the polar plots\r\ndata_polar_plots <- data %>%\r\n  select(wind_speed,\r\n         wind_direction,\r\n         mean_no2,\r\n         mean_o3,\r\n         mean_pm10,\r\n         mean_pm25) %>%\r\n  rename('Wind Speed' = wind_speed)\r\n\r\n# make the polarPlot for all pollutants\r\nno2_plot <-\r\n  polarPlot(\r\n    data_polar_plots,\r\n    pollutant = \"mean_no2\",\r\n    x = \"Wind Speed\",\r\n    wd = \"wind_direction\",\r\n    main = \"Average NO2 (' * mu * 'g/m' ^3 *')\",\r\n    key.header = \"\",\r\n    key.footer = \"\",\r\n    resolution = \"fine\",\r\n    par.settings = list(fontsize = list(text = 18))\r\n  )\r\n\r\no3_plot <-\r\n  polarPlot(\r\n    data_polar_plots,\r\n    pollutant = \"mean_o3\",\r\n    x = \"Wind Speed\",\r\n    wd = \"wind_direction\",\r\n    main = \"Average O3 (' * mu * 'g/m' ^3 *')\",\r\n    key.header = \"\",\r\n    key.footer = \"\",\r\n    resolution = \"fine\",\r\n    par.settings = list(fontsize = list(text = 18))\r\n  )\r\n\r\npm10_plot <-\r\n  polarPlot(\r\n    data_polar_plots,\r\n    pollutant = \"mean_pm10\",\r\n    x = \"Wind Speed\",\r\n    wd = \"wind_direction\",\r\n    main = \"Average PM10 (' * mu * 'g/m' ^3 *')\",\r\n    key.header = \"\",\r\n    key.footer = \"\",\r\n    resolution = \"fine\",\r\n    par.settings = list(fontsize = list(text = 18))\r\n  )\r\n\r\npm25_plot <-\r\n  polarPlot(\r\n    data_polar_plots,\r\n    pollutant = \"mean_pm25\",\r\n    x = \"Wind Speed\",\r\n    wd = \"wind_direction\",\r\n    main = \"Average PM2.5 (' * mu * 'g/m' ^3 *')\",\r\n    key.header = \"\",\r\n    key.footer = \"\",\r\n    resolution = \"fine\",\r\n    par.settings = list(fontsize = list(text = 18))\r\n  )\r\n\r\n# save the graph\r\npdf(\r\n  here::here(  \"inputs\", \"3.outputs\", \"1.eda\", \"graph_polar_plots_pollutants.pdf\"),\r\n  width = 15,\r\n  height = 5\r\n)\r\nprint(no2_plot, split = c(1, 1, 4, 1), more = TRUE)\r\nprint(o3_plot, split = c(2, 1, 4, 1), more = TRUE)\r\nprint(pm10_plot, split = c(3, 1, 4, 1), more = TRUE)\r\nprint(pm25_plot, split = c(4, 1, 4, 1), more = FALSE)\r\ndev.off()\r\n\r\n\r\n\r\nWind Direction & Other Weather Parameters\r\nWe plot the distribution of continuous weather parameter by wind direction:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# make the graph\r\ngraph_wd_weather <- data %>%\r\n  rename(\r\n    \"Average Temperature (°C)\" = temperature_average,\r\n    \"Average Humidity (%)\" = humidity_average,\r\n    \"Wind Speed (m/s)\" = wind_speed\r\n  ) %>%\r\n  pivot_longer(\r\n    cols = c(\r\n      \"Average Temperature (°C)\",\r\n      \"Average Humidity (%)\",\r\n      \"Wind Speed (m/s)\"\r\n    ),\r\n    names_to = \"weather_parameter\",\r\n    values_to = \"value\"\r\n  ) %>%\r\n  mutate(\r\n    horizontal_lines = case_when(\r\n      weather_parameter == \"Average Temperature (°C)\" ~ -6,\r\n      weather_parameter == \"Average Humidity (%)\" ~ 25,\r\n      weather_parameter == \"Wind Speed (m/s)\" ~ 0\r\n    )\r\n  ) %>%\r\n  ggplot(., aes(x = value, y = wind_direction_categories)) +\r\n  geom_density_ridges(\r\n    color = NA,\r\n    size = 0.3,\r\n    fill = my_blue,\r\n    alpha = 0.8\r\n  ) +\r\n  scale_x_continuous(breaks = scales::pretty_breaks(n = 8)) +\r\n  facet_wrap(~ weather_parameter, scales = \"free\") +\r\n  xlab(\"\") +\r\n  ylab(\"Wind Direction\") +\r\n  theme_tufte()\r\n\r\n# display the graph\r\ngraph_wd_weather\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the graph\r\nggsave(\r\n  graph_wd_weather,\r\n  filename = here::here(  \"inputs\", \"3.outputs\", \"1.eda\", \"graph_wd_weather.pdf\"),\r\n  width = 30,\r\n  height = 10,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nWe plot the distribution of rainfall duration by wind direction:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# make the graph\r\ngraph_wd_rainfall <- data %>%\r\n  select(rainfall_duration, wind_direction_categories) %>%\r\n  group_by(wind_direction_categories, rainfall_duration) %>%\r\n  summarise(n = n()) %>%\r\n  mutate(proportion = n / sum(n) * 100) %>%\r\n  ungroup() %>%\r\n  mutate(\r\n    rainfall_duration = case_when(\r\n      rainfall_duration == \"  0\" ~ \"0 minute\",\r\n      rainfall_duration == \"[  1,  12)\" ~ \"[1, 12) minutes\",\r\n      rainfall_duration == \"[ 12, 159)\" ~ \"[12, 159) minutes\",\r\n      rainfall_duration == \"[159,1440]\" ~ \"[159,1440] minutes\"\r\n    )\r\n  ) %>%\r\n  mutate(\r\n    rainfall_duration = fct_relevel(\r\n      rainfall_duration,\r\n      \"0 minute\",\r\n      \"[1, 12) minutes\",\r\n      \"[12, 159) minutes\",\r\n      \"[159,1440] minutes\"\r\n    )\r\n  ) %>%\r\n  ggplot(., aes(x = proportion, y = rainfall_duration)) +\r\n  geom_point(shape = 16,\r\n             colour = my_blue,\r\n             size = 4) +\r\n  geom_vline(xintercept = 0,\r\n             size = 0.3,\r\n             colour = \"black\") +\r\n  facet_wrap( ~ wind_direction_categories, ncol = 4) +\r\n  xlab(\"Proportion (%)\") + ylab(\"\") +\r\n  theme_tufte() +\r\n  theme(axis.text.y = element_text(hjust = 1))\r\n\r\n# display the graph\r\ngraph_wd_rainfall\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the graph\r\nggsave(\r\n  graph_wd_rainfall,\r\n  filename = here::here(  \"inputs\", \"3.outputs\", \"1.eda\", \"graph_wd_rainfall.pdf\"),\r\n  width = 25,\r\n  height = 10,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nWind Direction & Calendar Indicators\r\nWe plot the distribution of wind direction by month:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# make the graph\r\ngraph_wd_month <- data %>%\r\n  select(month, wind_direction_categories) %>%\r\n  group_by(wind_direction_categories, month) %>%\r\n  summarise(n = n()) %>%\r\n  mutate(proportion = n / sum(n) * 100) %>%\r\n  ungroup() %>%\r\n  ggplot(., aes(x = month, y = proportion, group = \"l\")) +\r\n  geom_line(colour = \"gray80\") +\r\n  geom_point(colour = my_blue, size = 3) +\r\n  scale_y_continuous(breaks = scales::pretty_breaks(n = 7)) +\r\n  facet_wrap( ~ wind_direction_categories, ncol = 2) +\r\n  xlab(\"\") + ylab(\"Proportion (%)\") +\r\n  theme_tufte()\r\n# display the graph\r\ngraph_wd_month\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the graph\r\nggsave(\r\n  graph_wd_month,\r\n  filename = here::here(  \"inputs\", \"3.outputs\", \"1.eda\", \"graph_wd_month.pdf\"),\r\n  width = 35,\r\n  height = 15,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nWe plot the distribution of wind direction by year:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# make the graph\r\ngraph_wd_year <- data %>%\r\n  select(year, wind_direction_categories) %>%\r\n  mutate(year = as.factor(year)) %>%\r\n  group_by(wind_direction_categories, year) %>%\r\n  summarise(n = n()) %>%\r\n  mutate(proportion = n / sum(n) * 100) %>%\r\n  ungroup() %>%\r\n  ggplot(., aes(x = year, y = proportion, group = \"l\")) +\r\n  geom_line(colour = \"gray80\") +\r\n  geom_point(colour = my_blue, size = 3) +\r\n  scale_y_continuous(breaks = scales::pretty_breaks(n = 7)) +\r\n  facet_wrap( ~ wind_direction_categories, ncol = 2) +\r\n  xlab(\"\") + ylab(\"Proportion (%)\") +\r\n  theme_tufte()\r\n\r\n# display the graph\r\ngraph_wd_year\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the graph\r\nggsave(\r\n  graph_wd_year,\r\n  filename = here::here(  \"inputs\", \"3.outputs\", \"1.eda\", \"graph_wd_year.pdf\"),\r\n  width = 30,\r\n  height = 15,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nCovariates Imbalance EDA\r\nWe check if covariates are balanced when we define treated days as units with North-East winds and control days as units where winds blow from other directions.\r\nDefining Treatment\r\nThe treatment is defined as follows:\r\ntreated units are days where winds blow from the North-East in t.\r\ncontrol units are day winds blow from other directions in t.\r\n\r\n\r\n# construct treatment allocation variable\r\ndata <- data %>%\r\n  mutate(is_treated = ifelse(\r\n    wind_direction_categories == \"North-East\",\r\n    \"Treated\",\r\n    \"Control\"\r\n  ))\r\n\r\n\r\n\r\nWeather Covariates Imbalance\r\nWe plot density distributions for continuous weather covariate by treatment status:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# we select control variables and store them in a long dataframe\r\ndata_weather_continuous_variables <- data %>%\r\n  select(temperature_average,\r\n         humidity_average,\r\n         wind_speed,\r\n         is_treated) %>%\r\n  pivot_longer(\r\n    cols = -c(is_treated),\r\n    names_to = \"variable\",\r\n    values_to = \"values\"\r\n  ) %>%\r\n  mutate(\r\n    variable = NA %>%\r\n      ifelse(\r\n        str_detect(variable, \"temperature_average\"),\r\n        \"Average Temperature (°C)\",\r\n        .\r\n      ) %>%\r\n      ifelse(\r\n        str_detect(variable, \"humidity_average\"),\r\n        \"Humidity Average (%)\",\r\n        .\r\n      ) %>%\r\n      ifelse(str_detect(variable, \"wind_speed\"), \"Wind Speed (m/s)\", .)\r\n  )\r\n\r\n# make the graph\r\ngraph_boxplot_continuous_weather <-\r\n  ggplot(data_weather_continuous_variables,\r\n         aes(x = values, y = is_treated, fill = is_treated)) +\r\n  geom_density_ridges(colour = NA) +\r\n  scale_fill_manual(values = c(my_blue, my_orange)) +\r\n  scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) +\r\n  xlab(\"Covariate Value\") +\r\n  ylab(\"\") +\r\n  labs(fill = \"Units Status:\") +\r\n  facet_wrap( ~ variable, scale = \"free\", ncol = 3) +\r\n  theme_tufte()\r\n\r\n# we print the graph\r\ngraph_boxplot_continuous_weather\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the graph\r\nggsave(\r\n  graph_boxplot_continuous_weather,\r\n  filename = here::here(  \"inputs\", \"3.outputs\", \"1.eda\", \"graph_boxplot_continuous_weather.pdf\"),\r\n  width = 30,\r\n  height = 10,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nWe draw love plots which display the standardized mean differences between treated and control days for each weather covariate and by month:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# compute absolute differences\r\ndata_abs_difference <- data %>%\r\n  select(month,\r\n         is_treated,\r\n         temperature_average,\r\n         humidity_average,\r\n         wind_speed) %>%\r\n  group_by(month, is_treated) %>%\r\n  summarise_all(., ~ mean(., na.rm = TRUE)) %>%\r\n  pivot_longer(\r\n    cols = -c(month, is_treated),\r\n    names_to = \"variable\",\r\n    values_to = \"average\"\r\n  ) %>%\r\n  arrange(month, variable) %>%\r\n  group_by(month, variable) %>%\r\n  summarise(abs_difference = abs(average[2] - average[1]))\r\n\r\n# we compute the standard deviation of each treatment group covariate\r\ndata_sd <- data %>%\r\n  select(month,\r\n         is_treated,\r\n         temperature_average,\r\n         humidity_average,\r\n         wind_speed) %>%\r\n  filter(is_treated == \"Treated\") %>%\r\n  select(-is_treated) %>%\r\n  group_by(month) %>%\r\n  summarise_all(., ~ sd(., na.rm = TRUE)) %>%\r\n  pivot_longer(cols = -c(month),\r\n               names_to = \"variable\",\r\n               values_to = \"sd_treatment\")\r\n\r\n# we merge data_abs_difference and data_sd\r\ndata_love <-\r\n  left_join(data_abs_difference, data_sd, by = c(\"month\", \"variable\")) %>%\r\n  mutate(standardized_difference = abs_difference / sd_treatment) %>%\r\n  select(-c(abs_difference, sd_treatment)) %>%\r\n  mutate(\r\n    variable = case_when(\r\n      variable == \"temperature_average\" ~ \"Average Temperature (°C)\",\r\n      variable == \"humidity_average\" ~ \"Humidity Average (%)\",\r\n      variable == \"wind_speed\" ~ \"Wind Speed (m/s)\"\r\n    )\r\n  )\r\n\r\n# we make the graph\r\ngraph_love <-\r\n  ggplot(data_love, aes(y = fct_rev(variable), x = standardized_difference)) +\r\n  geom_vline(xintercept = 0, size = 0.3) +\r\n  geom_vline(xintercept = 0.1,\r\n             color = my_orange,\r\n             size = 0.3) +\r\n  geom_point(size = 2, colour = my_blue) +\r\n  facet_wrap( ~ month, ncol = 4) +\r\n  xlab(\"Standardized Mean Differences\") +\r\n  ylab(\"\") +\r\n  theme_tufte() +\r\n  theme(\r\n    axis.text.y = element_text(hjust = 1, size = 10),\r\n    axis.text.x = element_text(size = 10),\r\n    panel.spacing = unit(0.5, \"cm\"),\r\n    plot.margin = unit(c(0.5, 0.5, 0.5, -0.5), \"cm\")\r\n  )\r\n\r\n\r\n# we print the graph\r\ngraph_love\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the graph\r\nggsave(\r\n  graph_love,\r\n  filename = here::here(  \"inputs\", \"3.outputs\", \"1.eda\", \"graph_love_weather.pdf\"),\r\n  width = 20,\r\n  height = 12,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nWe can also the imbalance and lack of overlap for the average temperature by drawing a ridgeline plot:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# make ridgeline plot for temperature\r\ngraph_ridgeline_temperature <-\r\n  ggplot(data, aes(x = temperature_average, y = month, fill = is_treated)) +\r\n  ggridges::geom_density_ridges2(alpha = 0.4, colour = NA) +\r\n  scale_fill_manual(values = c(my_blue, my_orange)) +\r\n  facet_wrap(~ year) +\r\n  labs(x = \"Average Temperatue (°C)\", y = \"\", fill = \"Group:\") +\r\n  theme_tufte()\r\n\r\n# we print the graph\r\ngraph_ridgeline_temperature\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the graph\r\nggsave(\r\n  graph_ridgeline_temperature,\r\n  filename = here::here(  \"inputs\", \"3.outputs\", \"1.eda\", \"graph_ridgeline_temperature.pdf\"),\r\n  width = 30,\r\n  height = 20,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nCalendar Imbalance\r\nWe plot the proportion of treated units by month:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# make the graph\r\ngraph_treated_month <- data %>%\r\n  select(month, is_treated) %>%\r\n  group_by(month, is_treated) %>%\r\n  summarise(n = n()) %>%\r\n  mutate(proportion = n / sum(n) * 100) %>%\r\n  ungroup() %>%\r\n  filter(is_treated == \"Treated\") %>%\r\n  ggplot(., aes(x = month, y = proportion, group = \"l\")) +\r\n  geom_line(colour = \"gray80\") +\r\n  geom_point(colour = my_blue, size = 3) +\r\n  scale_y_continuous(breaks = scales::pretty_breaks(n = 7)) +\r\n  xlab(\"\") + ylab(\"Proportion (%)\") +\r\n  theme_tufte()\r\n\r\n# display the graph\r\ngraph_treated_month\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the graph\r\nggsave(\r\n  graph_treated_month,\r\n  filename = here::here(  \"inputs\", \"3.outputs\", \"1.eda\", \"graph_treated_month.pdf\"),\r\n  width = 20,\r\n  height = 8,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2022-04-08T10:18:31+02:00"
    },
    {
      "path": "3_matching_procedure.html",
      "title": "Matching Procedure",
      "description": "Comparing days with Wind Blowing from the North-East to Other Directions. Adjusting for calendar indicators and other weather variables.\n",
      "author": [
        {
          "name": "Léo Zabrocki",
          "url": "https://lzabrocki.github.io/"
        },
        {
          "name": "Anna Alari",
          "url": "https://scholar.google.com/citations?user=MiFY320AAAAJ&hl=fr"
        },
        {
          "name": "Tarik Benmarhnia",
          "url": "https://profiles.ucsd.edu/tarik.benmarhnia"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\r\n\r\nContents\r\nRequired Packages\r\nPreparing the Data for Matching\r\nSelecting and Creating Relevant Variables\r\nCreating Potential Experiments\r\n\r\nMatching Procedure\r\nDefining Thresholds for Matching Covariates\r\nRunning the Matching Procedure\r\n\r\n\r\n\r\nbody {\r\ntext-align: justify}\r\nIn this document, we provide all steps required to reproduce our matching procedure. We compare days where:\r\ntreated units are days where winds blow from the North-East in t.\r\ncontrol units are day winds blow from other directions in t.\r\nWe adjust for calendar indicators and weather confouding factors.\r\nShould you have any questions, need help to reproduce the analysis or find coding errors, please do not hesitate to contact me at leo.zabrocki@psemail.eu\r\nRequired Packages\r\nTo reproduce exactly the script_matching_procedure.html document, we first need to have installed:\r\nthe R programming language on your computer\r\nRStudio, an integrated development environment for R, which will allow you to knit the script_matching_procedure.Rmd file and interact with the R code chunks\r\nthe R Markdown package\r\nand the Distill package which provides the template of this document.\r\nOnce everything is set up, we have to load the following packages:\r\n\r\n\r\n# load required packages\r\nlibrary(knitr) # for creating the R Markdown document\r\nlibrary(here) # for files paths organization\r\nlibrary(tidyverse) # for data manipulation and visualization\r\nlibrary(Rcpp) # for running the matching algorithm\r\nlibrary(optmatch) # for matching pairs\r\nlibrary(igraph) # for pair matching via bipartite maximal weighted matching\r\n\r\n\r\n\r\nWe load our custom ggplot2 theme for graphs:\r\n\r\n\r\n# load ggplot custom theme\r\nsource(here::here(\r\n  \"inputs\", \"2.functions\",\r\n  \"script_theme_tufte.R\"\r\n))\r\n# define nice colors\r\nmy_blue <- \"#0081a7\"\r\nmy_orange <- \"#fb8500\"\r\n\r\n\r\n\r\nWe also have to load the script_time_series_matching_function.R located in the 0.script_matching_algorithm folder and which provides the functions used for matching time series:\r\n\r\n\r\n# load matching functions\r\nsource(\r\n  here::here(\r\n    \"inputs\", \"2.functions\",\r\n    \"script_time_series_matching_function.R\"\r\n  )\r\n)\r\n\r\n\r\n\r\nPreparing the Data for Matching\r\nSelecting and Creating Relevant Variables\r\nFirst, we load the data:\r\n\r\n\r\n# load data\r\ndata <-\r\n  readRDS(here::here(\"inputs\", \"1.data\", \"4.data_for_analysis\", \"data_for_analysis.RDS\")) %>%\r\n  # drop wind direction variable as we use instead wind direction categories\r\n  select(-wind_direction)\r\n\r\n\r\n\r\nFor each covariate, we create the first daily lags and leads and create a new dataframe called processed_data:\r\n\r\n\r\n# create first daily lead for each variable\r\ndata_leads <- data %>%\r\n  select(date, mean_no2:wind_direction_categories) %>%\r\n  mutate_at(vars(-date), ~  lead(., n = 1, order_by = date)) %>%\r\n  rename_at(vars(-date), function(x)\r\n    paste0(x, \"_lead_\", 1))\r\n\r\n# create first daily lag for each variable\r\ndata_lags <- data %>%\r\n  select(date, mean_no2:wind_direction_categories) %>%\r\n  mutate_at(vars(-date), ~  lag(., n = 1, order_by = date)) %>%\r\n  rename_at(vars(-date), function(x)\r\n    paste0(x, \"_lag_\", 1))\r\n\r\n# create processed_data\r\nprocessed_data <- left_join(data, data_lags, by = \"date\") %>%\r\n  left_join(., data_leads, by = \"date\")\r\n\r\n\r\n\r\nWe can now define the hypothetical experiment that we would like to investigate.\r\nCreating Potential Experiments\r\nWe defined our potential experiments such that:\r\ntreated units are days where winds blow from the North-East in t.\r\ncontrol units are day winds blow from other directions in t.\r\nBelow are the required steps to select the corresponding treated and control units whose observations are stored in the matching_data:\r\n\r\n\r\n# construct treatment assignment variable\r\nprocessed_data <- processed_data %>%\r\n  mutate(is_treated = ifelse(wind_direction_categories == \"North-East\", TRUE, FALSE),\r\n         is_treated_lag_1 = lag(is_treated, n = 1, order_by = date))\r\n\r\n# remove the days for which assignment is undefined\r\nmatching_data = processed_data[!is.na(processed_data$is_treated),]\r\n\r\n# susbet treated and control units\r\ntreated_units = subset(matching_data, is_treated)\r\ncontrol_units = subset(matching_data,!is_treated)\r\nN_treated = nrow(treated_units)\r\nN_control = nrow(control_units)\r\n\r\n\r\n\r\nThere are 912 treated units and 3106 control units. We display the distribution of treated and control units through time:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# make stripes graph\r\ngraph_stripes_wd_experiment <- matching_data %>%\r\n  mutate(is_treated = ifelse(is_treated == \"TRUE\", \"Treated\", \"Control\")) %>%\r\n  ggplot(., aes(x = date, y = 1, fill = is_treated)) +\r\n  geom_tile() +\r\n  scale_x_date(breaks = scales::pretty_breaks(n = 10)) +\r\n  scale_y_continuous(expand = c(0, 0)) +\r\n  scale_fill_manual(name = \"Daily Observations:\", values = c(my_blue, my_orange)) +\r\n  xlab(\"Date\") +\r\n  theme_tufte() +\r\n  theme(\r\n    panel.grid.major.y = element_blank(),\r\n    axis.ticks.x = element_blank(),\r\n    axis.ticks.y = element_blank(),\r\n    axis.title.y = element_blank(),\r\n    axis.text.y = element_blank()\r\n  )\r\n\r\n# display the graph\r\ngraph_stripes_wd_experiment\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the graph\r\nggsave(\r\n  graph_stripes_wd_experiment,\r\n  filename = here::here(\r\n    \"inputs\", \"3.outputs\",\r\n    \"2.matching_analysis\",\r\n    \"graph_stripes_wd_experiment.pdf\"\r\n  ),\r\n  width = 30,\r\n  height = 10,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nWe save the matching_data :\r\n\r\n\r\n# save the matching data\r\nsaveRDS(matching_data,\r\n        here::here(\"inputs\", \"1.data\", \"5.matched_data\", \"matching_data.Rds\"))\r\n\r\n\r\n\r\nMatching Procedure\r\nDefining Thresholds for Matching Covariates\r\nBelow is the code to define the relevant thresholds:\r\n\r\n\r\n# we create the scaling list as it is needed for running the algorithm\r\n# but we do not use it\r\n\r\nscaling =  rep(list(1), ncol(matching_data))\r\nnames(scaling) = colnames(matching_data)\r\n\r\n# instead, we manually defined the threshold for each covariate\r\nthresholds = rep(list(Inf), ncol(matching_data))\r\nnames(thresholds) = colnames(matching_data)\r\n\r\n# threshold for julian date\r\nthresholds$julian_date = 60\r\n\r\n# threshold for weekend\r\nthresholds$weekend = 0\r\n\r\n# threshold for holidays\r\nthresholds$holidays_dummy = 0\r\n\r\n# threshold for bank days\r\nthresholds$bank_day_dummy = 0\r\n\r\n# thresholds for average temperature\r\nthresholds$temperature_average = 5\r\n\r\n# thresholds for average humidity\r\nthresholds$humidity_average = 12\r\n\r\n# threshold for wind speed\r\nthresholds$wind_speed = 0.5\r\n\r\n# for lag of treatment indicator\r\nthresholds$is_treated_lag_1 = 0\r\n\r\n# threshold for rainfall duration\r\nthresholds$rainfall_duration = 0\r\n\r\n# thresholds for pm10 in t-1\r\nthresholds$mean_pm10_lag_1 = 8\r\n\r\n\r\n\r\nRunning the Matching Procedure\r\nWe compute discrepancy matrix and run the matching algorithm:\r\n\r\n\r\n# first we compute the discrepancy matrix\r\ndiscrepancies = discrepancyMatrix(treated_units, control_units, thresholds, scaling)\r\n\r\n# convert matching data to data.frame\r\nmatching_data <- as.data.frame(matching_data)\r\n\r\nrownames(discrepancies) = format(matching_data$date[which(matching_data$is_treated)], \"%Y-%m-%d\")\r\ncolnames(discrepancies) = format(matching_data$date[which(!matching_data$is_treated)], \"%Y-%m-%d\")\r\nrownames(matching_data) = matching_data$date\r\n\r\n# run the fullmatch algorithm\r\nmatched_groups = fullmatch(\r\n  discrepancies,\r\n  data = matching_data,\r\n  remove.unmatchables = TRUE,\r\n  max.controls = 1\r\n)\r\n\r\n# get list of matched  treated-control groups\r\ngroups_labels = unique(matched_groups[!is.na(matched_groups)])\r\ngroups_list = list()\r\nfor (i in 1:length(groups_labels)) {\r\n  IDs = names(matched_groups)[(matched_groups == groups_labels[i])]\r\n  groups_list[[i]] = as.Date(IDs[!is.na(IDs)])\r\n}\r\n\r\n\r\n\r\nFor somes cases, several controls units were matched to a treatment unit. We use the igraph package to force pair matching via bipartite maximal weighted matching. Below is the required code:\r\n\r\n\r\n# we build a bipartite graph with one layer of treated nodes, and another layer of control nodes.\r\n# the nodes are labeled by integers from 1 to (N_treated + N_control)\r\n# by convention, the first N_treated nodes correspond to the treated units, and the remaining N_control\r\n# nodes correspond to the control units.\r\n\r\n# build pseudo-adjacency matrix: edge if and only if match is admissible\r\n# NB: this matrix is rectangular so it is not per say the adjacendy matrix of the graph\r\n# (for this bipartite graph, the adjacency matrix had four blocks: the upper-left block of size\r\n# N_treated by N_treated filled with 0's, bottom-right block of size N_control by N_control filled with 0's,\r\n# top-right block of size N_treated by N_control corresponding to adj defined below, and bottom-left block\r\n# of size N_control by N_treated corresponding to the transpose of adj)\r\nadj = (discrepancies < Inf)\r\n\r\n# extract endpoints of edges\r\nedges_mat = which(adj, arr.ind = TRUE)\r\n\r\n# build weights, listed in the same order as the edges (we use a decreasing function x --> 1/(1+x) to\r\n# have weights inversely proportional to the discrepancies, since maximum.bipartite.matching\r\n# maximizes the total weight and we want to minimize the discrepancy)\r\nweights = 1 / (1 + sapply(1:nrow(edges_mat), function(i)\r\n  discrepancies[edges_mat[i, 1], edges_mat[i, 2]]))\r\n\r\n# format list of edges (encoded as a vector resulting from concatenating the end points of each edge)\r\n# i.e c(edge1_endpoint1, edge1_endpoint2, edge2_endpoint1, edge2_endpoint1, edge3_endpoint1, etc...)\r\nedges_mat[, \"col\"] = edges_mat[, \"col\"] + N_treated\r\nedges_vector = c(t(edges_mat))\r\n\r\n# NB: by convention, the first N_treated nodes correspond to the treated units, and the remaining N_control\r\n# nodes correspond to the control units (hence the \"+ N_treated\" to shift the labels of the control nodes)\r\n\r\n# build the graph from the list of edges\r\nBG = make_bipartite_graph(c(rep(TRUE, N_treated), rep(FALSE, N_control)), edges = edges_vector)\r\n\r\n# find the maximal weighted matching\r\nMBM = maximum.bipartite.matching(BG, weights = weights)\r\n\r\n# list the dates of the matched pairs\r\npairs_list = list()\r\nN_matched = 0\r\nfor (i in 1:N_treated) {\r\n  if (!is.na(MBM$matching[i])) {\r\n    N_matched = N_matched + 1\r\n    pairs_list[[N_matched]] = c(treated_units$date[i], control_units$date[MBM$matching[i] -\r\n                                                                            N_treated])\r\n  }\r\n}\r\n\r\n# transform the list of matched pairs to a dataframe\r\nmatched_pairs <- enframe(pairs_list) %>%\r\n  unnest(cols = \"value\") %>%\r\n  rename(pair_number = name,\r\n         date = value)\r\n\r\n\r\n\r\nThe hypothetical experiment we set up had 912 treated units and 3106 control units. The matching procedure results in 169 matched treated units.\r\nOne issue with our matching procedure is that matched pairs can be temporarily too close: this would violate the Stable Unit Treatment Value Assumption (STUVA), which states that the potential outcomes of each unit is independent from the potential outcomes from other units. Another way to put it is that there is no interference between treated and control units.\r\nWe compute below the temporal distance in days between treated and control units for each pair:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# compute temporal distance within pairs\r\npair_temporal_distance <- matched_pairs %>%\r\n  group_by(pair_number) %>%\r\n  summarise(date_difference = abs(date[2]-date[1])) %>%\r\n  ungroup() \r\n\r\n# summary statistics\r\npair_temporal_distance %>%\r\n  summarise(Mean = mean(date_difference),\r\n            SD =  sd(date_difference),\r\n            Min = min(date_difference),\r\n            Max = max(date_difference)) %>%\r\n  mutate_all(~ round(., 0)) %>%\r\n  kable(., align = c(rep(\"c\", 4)))\r\n\r\n\r\nMean\r\nSD\r\nMin\r\nMax\r\n13 days\r\n14\r\n1 days\r\n59 days\r\n\r\nThere are exactly 48 pairs for which the absolute difference in days is less or equal to 3. We therefore decided to drop these pairs to make the STUVA more credible:\r\n\r\n\r\n# pairs to keep\r\npairs_to_keep <- pair_temporal_distance %>%\r\n  filter(date_difference > 3) %>%\r\n  pull(pair_number)\r\n\r\nmatched_pairs <- matched_pairs %>%\r\n  filter(pair_number %in% pairs_to_keep)\r\n\r\n\r\n\r\nThe resulting number of matched pairs is equal to 121.\r\nWe finally merge the matched_pairs with the matching_matching_data to retrieve covariates values for the matched pairs and save the data:\r\n\r\n\r\n# select the matched data for the analysis\r\nfinal_data <- left_join(matched_pairs, matching_data, by = \"date\")\r\n\r\n# save the matched data\r\nsaveRDS(final_data,\r\n        here::here(\"inputs\", \"1.data\", \"5.matched_data\", \"matched_data.Rds\"))\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2022-04-08T10:18:52+02:00"
    },
    {
      "path": "4_comparing_initial_to_matched_data.html",
      "title": "Comparing the Matched Data to the Initial Data",
      "description": "Comparing days with Wind Blowing from the North-East to Other Directions. Adjusting for calendar indicators and other weather variables.\n",
      "author": [
        {
          "name": "Léo Zabrocki",
          "url": "https://lzabrocki.github.io/"
        },
        {
          "name": "Anna Alari",
          "url": "https://scholar.google.com/citations?user=MiFY320AAAAJ&hl=fr"
        },
        {
          "name": "Tarik Benmarhnia",
          "url": "https://profiles.ucsd.edu/tarik.benmarhnia"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\r\n\r\nContents\r\nRequired Packages\r\nComparing Distribution of Covariates in Matched and Initial Datasets\r\nWeather Covariates\r\nCalendar Indicators\r\n\r\n\r\n\r\nbody {\r\ntext-align: justify}\r\nIn this document, we take great care providing all steps and R codes required to compare the matched data to the initial data. We compare days where:\r\ntreated units are days where winds blow from the North-East in t.\r\ncontrol units are day winds blow from other directions in t.\r\nWe adjust for calendar indicators and weather confouding factors.\r\nShould you have any questions, need help to reproduce the analysis or find coding errors, please do not hesitate to contact me at leo.zabrocki@psemail.eu\r\nRequired Packages\r\nTo reproduce exactly the 2_script_comparing_two_datasets.html document, we first need to have installed:\r\nthe R programming language\r\nRStudio, an integrated development environment for R, which will allow you to knit the 2_script_comparing_two_datasets.Rmd file and interact with the R code chunks\r\nthe R Markdown package\r\nand the Distill package which provides the template for this document.\r\nOnce everything is set up, we have to load the following packages:\r\n\r\n\r\n# load required packages\r\nlibrary(knitr) # for creating the R Markdown document\r\nlibrary(here) # for files paths organization\r\nlibrary(tidyverse) # for data manipulation and visualization\r\nlibrary(ggridges) # for ridge density plots\r\nlibrary(kableExtra) # for table formatting\r\nlibrary(Cairo) # for printing customed police of graphs\r\nlibrary(patchwork) # combining plots\r\n\r\n\r\n\r\nWe finally load our custom ggplot2 theme for graphs:\r\n\r\n\r\n# load ggplot custom theme\r\nsource(here::here(\r\n  \"inputs\",\r\n  \"2.functions\",\r\n  \"script_theme_tufte.R\"\r\n))\r\n# define nice colors\r\nmy_blue <- \"#0081a7\"\r\nmy_orange <- \"#fb8500\"\r\n\r\n\r\n\r\nComparing Distribution of Covariates in Matched and Initial Datasets\r\nWe explore the characteristics of the matched data by comparing the distribution of its covariates to those of the matching data. We load the two datasets and bind them in the data_all object:\r\n\r\n\r\n# load matching data\r\ndata_matching <-\r\n  readRDS(here::here(\"inputs\", \"1.data\", \"5.matched_data\", \"matching_data.Rds\")) %>%\r\n  mutate(dataset = \"Initial Data\")\r\n\r\n# load matched data\r\ndata_matched <-\r\n  readRDS(here::here(\"inputs\", \"1.data\", \"5.matched_data\", \"matched_data.Rds\")) %>%\r\n  mutate(dataset = \"Matched Data\")\r\n\r\n# bind the three datasets\r\ndata_all <- bind_rows(data_matching, data_matched)\r\n\r\n\r\n\r\nWeather Covariates\r\nWe plot below the density distributions of continuous weather covariates for the two datasets:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# we select continuous weather variables and store them in a long dataframe\r\ndata_continuous_weather_variables <- data_all %>%\r\n  select(temperature_average, wind_speed, humidity_average, dataset) %>%\r\n  pivot_longer(\r\n    .,\r\n    cols =  c(temperature_average:humidity_average),\r\n    names_to = \"variable\",\r\n    values_to = \"values\"\r\n  ) %>%\r\n  mutate(\r\n    variable =  factor(\r\n      variable,\r\n      levels = c(\"temperature_average\", \"humidity_average\", \"wind_speed\")\r\n    ) %>%\r\n      fct_recode(\r\n        .,\r\n        \"Temperature Average (°C)\" = \"temperature_average\",\r\n        \"Average Humidity (%)\" = \"humidity_average\",\r\n        \"Wind Speed (m/s)\" = \"wind_speed\"\r\n      )\r\n  ) %>%\r\n  mutate(dataset = fct_relevel(dataset, \"Initial Data\", \"Matched Data\"))\r\n\r\n# we plot the density distributions\r\ngraph_density_continuous_weather_variables <-\r\n  ggplot(data_continuous_weather_variables,\r\n         aes(\r\n           x = values,\r\n           y = fct_rev(dataset),\r\n           fill = fct_rev(dataset)\r\n         )) +\r\n  geom_density_ridges(colour = NA) +\r\n  scale_fill_manual(values = c(my_blue, my_orange),\r\n                    guide = guide_legend(reverse = TRUE)) +\r\n  xlab(\"Covariate Value\") + ylab(\"\") +\r\n  labs(fill = \"Dataset:\") +\r\n  facet_wrap( ~ variable, scale = \"free_x\", ncol = 3) +\r\n  theme_tufte() +\r\n  theme(\r\n    legend.position = \"top\",\r\n    legend.justification = \"left\",\r\n    legend.direction = \"horizontal\",\r\n    axis.text.x = element_text(\r\n      family = \"Roboto Condensed\",\r\n      color = \"gray18\",\r\n      size = 8,\r\n      margin = ggplot2::margin(t = 0, unit = \"cm\")\r\n    )\r\n  )\r\n\r\n# print the graph\r\ngraph_density_continuous_weather_variables\r\n\r\n\r\n\r\n\r\nWe plot the proportion of weather categorical variables for the two datasets\r\n\r\n\r\nPlease show me the code!\r\n\r\n# we select categorical weather variables and store them in a long dataframe\r\ndata_categorical_weather_variables <- data_all %>%\r\n  # select relevant variables\r\n  select(wind_direction_categories, rainfall_duration, dataset) %>%\r\n  drop_na() %>%\r\n  mutate(rainfall_duration = paste(\"Rainfall Duration:\", rainfall_duration, sep = \" \"))  %>%\r\n  mutate(\r\n    rainfall_duration = case_when(\r\n      rainfall_duration == \"Rainfall Duration:   0\" ~ \"Rainfall Duration: 0 min\",\r\n      rainfall_duration == \"Rainfall Duration: [  1,  12)\" ~ \"Rainfall Duration: [1, 12) min\",\r\n      rainfall_duration == \"Rainfall Duration: [ 12, 159)\" ~ \"Rainfall Duration: [12, 159) min\",\r\n      rainfall_duration == \"Rainfall Duration: [159,1440]\" ~ \"Rainfall Duration: [159, 1440] min\"\r\n    )\r\n  ) %>%\r\n  mutate(\r\n    wind_direction_categories = fct_recode(\r\n      wind_direction_categories,\r\n      \"Wind Direction: North-East\" = \"North-East\",\r\n      \"Wind Direction: South-East\" = \"South-East\",\r\n      \"Wind Direction: South-West\" = \"South-West\",\r\n      \"Wind Direction: North-West\" = \"North-West\"\r\n    )\r\n  ) %>%\r\n  # transform variables to character\r\n  mutate_all( ~ as.character(.)) %>%\r\n  # transform the data to long to compute the proportion of observations for each variable\r\n  pivot_longer(cols = -c(dataset),\r\n               names_to = \"variable\",\r\n               values_to = \"values\") %>%\r\n  # group by dataset, variable and values\r\n  group_by(dataset, variable, values) %>%\r\n  # compute the number of observations\r\n  summarise(n = n()) %>%\r\n  # compute the proportion\r\n  mutate(freq = round(n / sum(n) * 100, 0)) %>%\r\n  # reorder labels of the dataset variable\r\n  ungroup() %>%\r\n  mutate(dataset = fct_relevel(dataset, \"Initial Data\", \"Matched Data\"))\r\n\r\n# we plot the cleveland dots plots\r\ngraph_categorical_weather_variables <-\r\n  ggplot(data_categorical_weather_variables,\r\n         aes(\r\n           x = freq,\r\n           y = fct_rev(dataset),\r\n           fill =  fct_rev(dataset)\r\n         )) +\r\n  geom_segment(aes(\r\n    x = 0,\r\n    xend = freq,\r\n    y =  fct_rev(dataset),\r\n    yend =  fct_rev(dataset)\r\n  )) +\r\n  geom_point(shape = 21,\r\n             color = \"black\",\r\n             size = 4) +\r\n  scale_fill_manual(values = c(my_blue, my_orange),\r\n                    guide = guide_legend(reverse = TRUE)) +\r\n  facet_wrap( ~ values, scale = \"free_x\", ncol = 3) +\r\n  ylab(\"\") +\r\n  xlab(\"Proportion (%)\") +\r\n  labs(fill = \"Dataset:\") +\r\n  theme_tufte() +\r\n  theme(\r\n    legend.position = \"top\",\r\n    legend.justification = \"left\",\r\n    legend.direction = \"horizontal\",\r\n    axis.text.x = element_text(\r\n      family = \"Roboto Condensed\",\r\n      color = \"gray18\",\r\n      size = 8,\r\n      margin = ggplot2::margin(t = 0, unit = \"cm\")\r\n    )\r\n  )\r\n\r\n# print the graph\r\ngraph_categorical_weather_variables\r\n\r\n\r\n\r\n\r\nWe combine the graph_density_continuous_weather_variables and graph_categorical_weather_variables :\r\n\r\n\r\nPlease show me the code!\r\n\r\n# combine plots\r\ngraph_weather_three_datasets <- graph_density_continuous_weather_variables / graph_categorical_weather_variables +\r\n  plot_annotation(tag_levels = 'A') & theme(plot.tag = element_text(size = 20, face = \"bold\"))\r\n\r\n# display graph\r\ngraph_weather_three_datasets\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the plot\r\nggsave(graph_weather_three_datasets, filename = here::here(\"inputs\", \"3.outputs\", \"2.matching_analysis\", \"graph_weather_two_datasets.pdf\"), \r\n       width = 35, height = 20, units = \"cm\", device = cairo_pdf)\r\n\r\n\r\n\r\nCalendar Indicators\r\nWe plot the proportions of observations belonging to each day of the week by dataset:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# compute the proportions of observations belonging to each day of the week by dataset\r\ndata_weekday <- data_all %>%\r\n  mutate(weekday = lubridate::wday(date, abbr = FALSE, label = TRUE)) %>%\r\n  select(weekday, dataset) %>%\r\n  mutate(\r\n    weekday = fct_relevel(\r\n      weekday,\r\n      \"Monday\",\r\n      \"Tuesday\",\r\n      \"Wednesday\",\r\n      \"Thursday\",\r\n      \"Friday\",\r\n      \"Saturday\",\r\n      \"Sunday\"\r\n    )\r\n  ) %>%\r\n  pivot_longer(.,-dataset) %>%\r\n  group_by(name, dataset, value) %>%\r\n  summarise(n = n()) %>%\r\n  mutate(proportion = round(n / sum(n) * 100, 0)) %>%\r\n  ungroup() %>%\r\n  mutate(dataset = fct_relevel(dataset, \"Initial Data\", \"Matched Data\"))\r\n\r\n# we plot the data using cleveland dot plots\r\ngraph_weekday <-\r\n  ggplot(data_weekday,\r\n         aes(\r\n           x = as.factor(value),\r\n           y = proportion,\r\n           colour = dataset,\r\n           group = dataset\r\n         )) +\r\n  geom_line(size = 1) +\r\n  scale_colour_manual(values = c(my_orange, my_blue),\r\n                      guide = guide_legend(reverse = FALSE)) +\r\n  ggtitle(\"Day of the Week\") +\r\n  ylab(\"Proportion (%)\") +\r\n  xlab(\"\") +\r\n  labs(colour = \"Dataset:\") +\r\n  theme_tufte() +\r\n  theme(\r\n    legend.position = \"top\",\r\n    legend.justification = \"left\",\r\n    legend.direction = \"horizontal\"\r\n  )\r\n\r\n# we print the graph\r\ngraph_weekday\r\n\r\n\r\n\r\n\r\nWe plot the proportions of observations belonging to bank days and holidays by dataset:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# compute the proportions of observations belonging to bank days and holidays by dataset\r\ndata_bank_holidays <- data_all %>%\r\n  select(bank_day_dummy, holidays_dummy, dataset) %>%\r\n  pivot_longer(.,-dataset) %>%\r\n  mutate(name = recode(name, bank_day_dummy = \"Bank Day\", holidays_dummy = \"Holidays\")) %>%\r\n  group_by(name, dataset, value) %>%\r\n  summarise(n = n()) %>%\r\n  mutate(proportion = round(n / sum(n) * 100, 0)) %>%\r\n  ungroup() %>%\r\n  mutate(dataset = fct_relevel(dataset, \"Data\", \"Initial Data\", \"Matched Data\")) %>%\r\n  filter(value == 1) %>%\r\n  mutate(name = paste(name, \": True\", sep = \"\"))\r\n\r\n# we plot the data using cleveland dot plots\r\ngraph_bank_holidays <-\r\n  ggplot(data_bank_holidays,\r\n         aes(\r\n           x = proportion,\r\n           y = as.factor(dataset),\r\n           fill = dataset\r\n         )) +\r\n  geom_segment(aes(\r\n    x = 0,\r\n    xend = proportion,\r\n    y =  fct_rev(dataset),\r\n    yend =  fct_rev(dataset)\r\n  )) +\r\n  geom_point(shape = 21,\r\n             colour = \"black\",\r\n             size = 4) +\r\n  scale_fill_manual(values = c(my_orange, my_blue),\r\n                    guide = guide_legend(reverse = FALSE)) +\r\n  facet_wrap( ~ name) +\r\n  ggtitle(\"Bank Days and Holidays\") +\r\n  ylab(\"Proportion (%)\") +\r\n  xlab(\"\") +\r\n  labs(fill = \"Dataset:\") +\r\n  theme_tufte() +\r\n  theme(\r\n    legend.position = \"top\",\r\n    legend.justification = \"left\",\r\n    legend.direction = \"horizontal\"\r\n  )\r\n\r\n# we print the graph\r\ngraph_bank_holidays\r\n\r\n\r\n\r\n\r\nWe plot the proportions of observations belonging to each month by dataset:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# compute the proportions of observations belonging to each month by dataset\r\ndata_month <- data_all %>%\r\n  select(month, dataset) %>%\r\n  mutate(\r\n    month = recode(\r\n      month,\r\n      `1` = \"January\",\r\n      `2` = \"February\",\r\n      `3` = \"March\",\r\n      `4` = \"April\",\r\n      `5` = \"May\",\r\n      `6` = \"June\",\r\n      `7` = \"July\",\r\n      `8` = \"August\",\r\n      `9` = \"September\",\r\n      `10` = \"October\",\r\n      `11` = \"November\",\r\n      `12` = \"December\"\r\n    ) %>%\r\n      fct_relevel(\r\n        .,\r\n        \"January\",\r\n        \"February\",\r\n        \"March\",\r\n        \"April\",\r\n        \"May\",\r\n        \"June\",\r\n        \"July\",\r\n        \"August\",\r\n        \"September\",\r\n        \"October\",\r\n        \"November\",\r\n        \"December\"\r\n      )\r\n  ) %>%\r\n  pivot_longer(.,-dataset) %>%\r\n  group_by(name, dataset, value) %>%\r\n  summarise(n = n()) %>%\r\n  mutate(proportion = round(n / sum(n) * 100, 0)) %>%\r\n  ungroup() %>%\r\n  mutate(dataset = fct_relevel(dataset, \"Initial Data\", \"Matched Data\"))\r\n\r\n\r\n# we plot the data using cleveland dot plots\r\ngraph_month <-\r\n  ggplot(data_month,\r\n         aes(\r\n           x = as.factor(value),\r\n           y = proportion,\r\n           colour = dataset,\r\n           group = dataset\r\n         )) +\r\n  geom_line(size = 1) +\r\n  scale_colour_manual(values = c(my_orange, my_blue),\r\n                      guide = guide_legend(reverse = FALSE)) +\r\n  ggtitle(\"Month\") +\r\n  ylab(\"Proportion (%)\") +\r\n  xlab(\"\") +\r\n  labs(colour = \"Dataset:\") +\r\n  theme_tufte() +\r\n  theme(\r\n    legend.position = \"top\",\r\n    legend.justification = \"left\",\r\n    legend.direction = \"horizontal\"\r\n  )\r\n\r\n# we print the graph\r\ngraph_month\r\n\r\n\r\n\r\n\r\nWe plot the proportions of observations belonging to each year by dataset:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# compute the proportions of observations belonging to each year by dataset\r\ndata_year <- data_all %>%\r\n  select(year, dataset) %>%\r\n  pivot_longer(.,-dataset) %>%\r\n  group_by(name, dataset, value) %>%\r\n  summarise(n = n()) %>%\r\n  mutate(proportion = round(n / sum(n) * 100, 0)) %>%\r\n  ungroup() %>%\r\n  mutate(dataset = fct_relevel(dataset, \"Initial Data\", \"Matched Data\"))\r\n\r\n\r\n# we plot the data using cleveland dot plots\r\ngraph_year <-\r\n  ggplot(data_year,\r\n         aes(\r\n           x = as.factor(value),\r\n           y = proportion,\r\n           colour = dataset,\r\n           group = dataset\r\n         )) +\r\n  geom_line(size = 1) +\r\n  scale_colour_manual(values = c(my_orange, my_blue),\r\n                      guide = guide_legend(reverse = FALSE)) +\r\n  ggtitle(\"Year\") +\r\n  ylab(\"Proportion (%)\") +\r\n  xlab(\"\") +\r\n  labs(colour = \"Dataset:\") +\r\n  theme_tufte() +\r\n  theme(\r\n    legend.position = \"top\",\r\n    legend.justification = \"left\",\r\n    legend.direction = \"horizontal\"\r\n  )\r\n\r\n# we print the graph\r\ngraph_year\r\n\r\n\r\n\r\n\r\nWe combine all plots for calendar variables:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# combine plots\r\ngraph_calendar_three_datasets <-\r\n  (graph_weekday + graph_bank_holidays) / (graph_month + graph_year) +\r\n  plot_annotation(tag_levels = 'A') &\r\n  theme(plot.tag = element_text(size = 20, face = \"bold\"))\r\n\r\n# display\r\ngraph_calendar_three_datasets\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the plot\r\nggsave(\r\n  graph_calendar_three_datasets,\r\n  filename = here::here(\r\n    \"inputs\", \"3.outputs\",\r\n    \"2.matching_analysis\",\r\n    \"graph_calendar_two_datasets.pdf\"\r\n  ),\r\n  width = 40,\r\n  height = 20,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2022-04-08T10:19:40+02:00"
    },
    {
      "path": "5_checking_covariates_balance.html",
      "title": "Checking Covariates Balance",
      "description": "Comparing days with Wind Blowing from the North-East to Other Directions. Adjusting for calendar indicators and other weather variables.\n",
      "author": [
        {
          "name": "Léo Zabrocki",
          "url": "https://lzabrocki.github.io/"
        },
        {
          "name": "Anna Alari",
          "url": "https://scholar.google.com/citations?user=MiFY320AAAAJ&hl=fr"
        },
        {
          "name": "Tarik Benmarhnia",
          "url": "https://profiles.ucsd.edu/tarik.benmarhnia"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\r\n\r\nContents\r\nRequired Packages\r\nPreparing the Data\r\nFigures for Covariates Distribution for Treated and Control Units\r\nWeather Covariates\r\nPollutants\r\nCalendar Indicator\r\n\r\n\r\n\r\nbody {\r\ntext-align: justify}\r\nIn this document, we take great care providing all steps and R codes required to check whether our matching procedure achieved balance. We compare days where:\r\ntreated units are days where winds blow from the North-East in t.\r\ncontrol units are day winds blow from other directions in t.\r\nWe adjust for calendar indicators and weather confouding factors.\r\nShould you have any questions, need help to reproduce the analysis or find coding errors, please do not hesitate to contact me at leo.zabrocki@psemail.eu\r\nRequired Packages\r\nTo reproduce exactly the 3_script_checking_balance_figures.html document, we first need to have installed:\r\nthe R programming language\r\nRStudio, an integrated development environment for R, which will allow you to knit the 3_script_checking_balance_figures.Rmd file and interact with the R code chunks\r\nthe R Markdown package\r\nand the Distill package which provides the template for this document.\r\nOnce everything is set up, we have to load the following packages:\r\n\r\n\r\n# load required packages\r\nlibrary(knitr) # for creating the R Markdown document\r\nlibrary(here) # for files paths organization\r\nlibrary(tidyverse) # for data manipulation and visualization\r\nlibrary(ggridges) # for ridge density plots\r\nlibrary(Cairo) # for printing customed police of graphs\r\nlibrary(patchwork) # combining plots\r\n\r\n\r\n\r\nWe finally load our custom ggplot2 theme for graphs:\r\n\r\n\r\n# load ggplot custom theme\r\nsource(here::here(\r\n  \"inputs\",\r\n  \"2.functions\",\r\n  \"script_theme_tufte.R\"\r\n))\r\n# define nice colors\r\nmy_blue <- \"#0081a7\"\r\nmy_orange <- \"#fb8500\"\r\n\r\n\r\n\r\nThe theme is based on the fantastic hrbrthemes package. If you do not want to use this theme or are unable to install it because of fonts issues, you can use the theme_bw() already included in the ggplot2 package.\r\nPreparing the Data\r\nWe load the matched data:\r\n\r\n\r\n# load matched data\r\ndata_matched <-\r\n  readRDS(here::here(\"inputs\", \"1.data\", \"5.matched_data\", \"matched_data.Rds\"))\r\n\r\n\r\n\r\nFigures for Covariates Distribution for Treated and Control Units\r\nWe check whether coviariates balance was achieved with the thresholds we defined for our matching procedure. We plot distributions of weather and calendar variables (Lags 0-1) and pollutants (Lag 1) for treated and control groups.\r\nWeather Covariates\r\nFor continuous weather covariates, we draw boxplots for treated and control groups:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# we select control variables and store them in a long dataframe\r\ndata_weather_continuous_variables <- data_matched %>%\r\n  select(\r\n    temperature_average,\r\n    temperature_average_lag_1,\r\n    humidity_average,\r\n    humidity_average_lag_1,\r\n    wind_speed,\r\n    wind_speed_lag_1,\r\n    is_treated\r\n  ) %>%\r\n  pivot_longer(\r\n    cols = -c(is_treated),\r\n    names_to = \"variable\",\r\n    values_to = \"values\"\r\n  ) %>%\r\n  mutate(\r\n    new_variable = NA %>%\r\n      ifelse(\r\n        str_detect(variable, \"temperature_average\"),\r\n        \"Average Temperature (°C)\",\r\n        .\r\n      ) %>%\r\n      ifelse(\r\n        str_detect(variable, \"humidity_average\"),\r\n        \"Humidity Average (%)\",\r\n        .\r\n      ) %>%\r\n      ifelse(str_detect(variable, \"wind_speed\"), \"Wind Speed (m/s)\", .)\r\n  ) %>%\r\n  mutate(time = \"in t\" %>%\r\n           ifelse(str_detect(variable, \"lag_1\"), \"in t-1\", .)) %>%\r\n  mutate(variable = paste(new_variable, time, sep = \" \")) %>%\r\n  mutate(is_treated = if_else(is_treated == TRUE, \"Treated\", \"Control\"))\r\n\r\ngraph_boxplot_continuous_weather <-\r\n  ggplot(data_weather_continuous_variables,\r\n         aes(x = is_treated, y = values, colour = is_treated)) +\r\n  geom_violin(size = 1) +\r\n  geom_boxplot(width = 0.1, outlier.shape = NA) +\r\n  scale_color_manual(values = c(my_blue, my_orange)) +\r\n  scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) +\r\n  ylab(\"Covariate Value\") +\r\n  xlab(\"\") +\r\n  labs(colour = \"Units Status:\") +\r\n  facet_wrap( ~ variable, scale = \"free\", ncol = 2) +\r\n  theme_tufte() +\r\n  theme(\r\n    legend.position = \"top\",\r\n    legend.justification = \"left\",\r\n    legend.direction = \"horizontal\"\r\n  )\r\n\r\n# we print the graph\r\ngraph_boxplot_continuous_weather\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the graph\r\nggsave(\r\n  graph_boxplot_continuous_weather,\r\n  filename = here::here(\r\n    \"inputs\", \"3.outputs\",\r\n    \"2.matching_analysis\",\r\n    \"graph_boxplot_continuous_weather.pdf\"\r\n  ),\r\n  width = 20,\r\n  height = 20,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nFor the rainfall duration and the wind direction categories, we plot the proportions:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# we select the rainfall variables\r\ndata_weather_categorical <- data_matched %>%\r\n  select(\r\n    rainfall_duration,\r\n    rainfall_duration_lag_1,\r\n    wind_direction_categories_lag_1,\r\n    is_treated\r\n  ) %>%\r\n  mutate_all( ~ as.character(.)) %>%\r\n  pivot_longer(\r\n    cols = -c(is_treated),\r\n    names_to = \"variable\",\r\n    values_to = \"values\"\r\n  ) %>%\r\n  # group by is_treated, variable and values\r\n  group_by(is_treated, variable, values) %>%\r\n  # compute the number of observations\r\n  summarise(n = n()) %>%\r\n  # compute the proportion\r\n  mutate(freq = round(n / sum(n) * 100, 0)) %>%\r\n  ungroup() %>%\r\n  filter(!(\r\n    variable %in% c(\"rainfall_duration\", \"rainfall_duration_lag_1\") &\r\n      values == \"False\"\r\n  )) %>%\r\n  mutate(\r\n    new_variable = NA %>%\r\n      ifelse(str_detect(variable, \"wind\"), \"Wind Direction\", .) %>%\r\n      ifelse(str_detect(variable, \"rainfall\"), \"Rainfall Duration\", .)\r\n  ) %>%\r\n  mutate(time = \"\\nin t\" %>%\r\n           ifelse(str_detect(variable, \"lag_1\"), \"\\nin t-1\", .)) %>%\r\n  mutate(variable = paste(new_variable, time, sep = \" \")) %>%\r\n  mutate(is_treated = if_else(is_treated == TRUE, \"Treated\", \"Control\"))\r\n\r\n\r\n# build the graph for wind direction\r\ngraph_categorical_wd_weather <- data_weather_categorical %>%\r\n  filter(new_variable == \"Wind Direction\") %>%\r\n  ggplot(., aes(x = freq, y = values, fill = is_treated)) +\r\n  geom_point(shape = 21,\r\n             size = 4,\r\n             alpha = 0.8) +\r\n  geom_vline(xintercept = 0, size = 0.3) +\r\n  scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) +\r\n  scale_fill_manual(values = c(my_blue, my_orange)) +\r\n  facet_wrap( ~ variable, scales = \"free\") +\r\n  xlab(\"Proportion (%)\") +\r\n  ylab(\"\") +\r\n  labs(fill = \"Units Status:\") +\r\n  theme_tufte() +\r\n  theme(\r\n    legend.position = \"top\",\r\n    legend.justification = \"left\",\r\n    legend.direction = \"horizontal\"\r\n  )\r\n\r\n# we print the graph\r\ngraph_categorical_wd_weather\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# build the graph for rainfall dummy\r\ngraph_categorical_rainfall_weather <- data_weather_categorical %>%\r\n  filter(new_variable == \"Rainfall Duration\") %>%\r\n  ggplot(., aes(x = freq, y = values, fill = is_treated)) +\r\n  geom_point(shape = 21,\r\n             size = 4,\r\n             alpha = 0.8) +\r\n  geom_vline(xintercept = 0, size = 0.3) +\r\n  scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) +\r\n  scale_fill_manual(values = c(my_blue, my_orange)) +\r\n  facet_wrap( ~ variable) +\r\n  xlab(\"Proportion (%)\") +\r\n  ylab(\"\") +\r\n  labs(fill = \"Units Status:\") +\r\n  theme_tufte() +\r\n  theme(\r\n    legend.position = \"top\",\r\n    legend.justification = \"left\",\r\n    legend.direction = \"horizontal\"\r\n  )\r\n\r\n# we print the graph\r\ngraph_categorical_rainfall_weather\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# combine plots\r\ngraph_categorical_weather <-\r\n  graph_categorical_wd_weather / graph_categorical_rainfall_weather +\r\n  plot_annotation(tag_levels = 'A') &\r\n  theme(plot.tag = element_text(size = 20, face = \"bold\"))\r\n\r\n# save the graph\r\nggsave(\r\n  graph_categorical_weather,\r\n  filename = here::here(\r\n    \"inputs\", \"3.outputs\",\r\n    \"2.matching_analysis\",\r\n    \"graph_categorical_weather.pdf\"\r\n  ),\r\n  width = 20,\r\n  height = 20,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nPollutants\r\nFor pollutants lag 1, we draw boxplots for treated and control groups:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# we select control variables and store them in a long dataframe\r\ndata_pollutant_variables <- data_matched %>%\r\n  select(mean_no2_lag_1:mean_pm25_lag_1,\r\n         is_treated) %>%\r\n  # transform the data to long to compute the proportion of observations for each variable\r\n  pivot_longer(\r\n    cols = -c(is_treated),\r\n    names_to = \"variable\",\r\n    values_to = \"values\"\r\n  ) %>%\r\n  mutate(is_treated = ifelse(is_treated == \"TRUE\", \"Treated\", \"Control\")) %>%\r\n  mutate(\r\n    pollutant = NA %>%\r\n      ifelse(str_detect(variable, \"no2\"), \"NO2\", .) %>%\r\n      ifelse(str_detect(variable, \"o3\"), \"O3\", .) %>%\r\n      ifelse(str_detect(variable, \"pm10\"), \"PM10\", .) %>%\r\n      ifelse(str_detect(variable, \"pm25\"), \"PM2.5\", .)\r\n  ) %>%\r\n  mutate(time = \"in t-1\") %>%\r\n  mutate(variable = paste(pollutant, time, sep = \" \"))\r\n\r\n# make graph\r\ngraph_boxplot_pollutants <- data_pollutant_variables %>%\r\n  ggplot(., aes(x = is_treated, y = values, colour = is_treated)) +\r\n  geom_violin(size = 0.5) +\r\n  geom_boxplot(width = 0.1, outlier.shape = NA) +\r\n  scale_color_manual(values = c(my_blue, my_orange)) +\r\n  scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) +\r\n  ylab(\"Concentration (µg/m³)\") +\r\n  xlab(\"\") +\r\n  labs(colour = \"Units Status:\") +\r\n  facet_wrap( ~ variable, ncol = 4) +\r\n  theme_tufte() +\r\n  theme(\r\n    legend.position = \"top\",\r\n    legend.justification = \"left\",\r\n    legend.direction = \"horizontal\"\r\n  )\r\n\r\n# we print the graph\r\ngraph_boxplot_pollutants\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the graph\r\nggsave(\r\n  graph_boxplot_pollutants,\r\n  filename = here::here(\r\n    \"inputs\", \"3.outputs\",\r\n    \"2.matching_analysis\",\r\n    \"graph_boxplot_pollutants.pdf\"\r\n  ),\r\n  width = 30,\r\n  height = 10,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nCalendar Indicator\r\nFor calendar variables such as the day of the week, bank days and holidays we matched strictly. We plot the proportions of observations belonging to each month by treatment status:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# compute the proportions of observations belonging to each month by treatment status\r\ndata_month <- data_matched %>%\r\n  mutate(is_treated = ifelse(is_treated == \"TRUE\", \"Treated\", \"Control\")) %>%\r\n  select(month, is_treated) %>%\r\n  mutate(\r\n    month = recode(\r\n      month,\r\n      `1` = \"January\",\r\n      `2` = \"February\",\r\n      `3` = \"March\",\r\n      `4` = \"April\",\r\n      `5` = \"May\",\r\n      `6` = \"June\",\r\n      `7` = \"July\",\r\n      `8` = \"August\",\r\n      `9` = \"September\",\r\n      `10` = \"October\",\r\n      `11` = \"November\",\r\n      `12` = \"December\"\r\n    ) %>%\r\n      fct_relevel(\r\n        .,\r\n        \"January\",\r\n        \"February\",\r\n        \"March\",\r\n        \"April\",\r\n        \"May\",\r\n        \"June\",\r\n        \"July\",\r\n        \"August\",\r\n        \"September\",\r\n        \"October\",\r\n        \"November\",\r\n        \"December\"\r\n      )\r\n  ) %>%\r\n  pivot_longer(.,-is_treated) %>%\r\n  group_by(name, is_treated, value) %>%\r\n  summarise(n = n()) %>%\r\n  mutate(proportion = round(n / sum(n) * 100, 0)) %>%\r\n  ungroup()\r\n\r\n# we plot the data using cleveland dot plots\r\ngraph_month <-\r\n  ggplot(data_month,\r\n         aes(\r\n           x = as.factor(value),\r\n           y = proportion,\r\n           colour = is_treated,\r\n           group = is_treated\r\n         )) +\r\n  geom_line(size = 1) +\r\n  scale_colour_manual(values = c(my_blue, my_orange),\r\n                      guide = guide_legend(reverse = FALSE)) +\r\n  ggtitle(\"Month\") +\r\n  ylab(\"Proportion (%)\") +\r\n  xlab(\"\") +\r\n  labs(colour = \"Units Status:\") +\r\n  theme_tufte() +\r\n  theme(\r\n    legend.position = \"top\",\r\n    legend.justification = \"left\",\r\n    legend.direction = \"horizontal\"\r\n  )\r\n\r\n# we print the graph\r\ngraph_month\r\n\r\n\r\n\r\n\r\nWe plot the proportions of observations belonging to each year by treatment status:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# compute the proportions of observations belonging to each year by treatment status\r\ndata_year <- data_matched %>%\r\n  mutate(is_treated = ifelse(is_treated == \"TRUE\", \"Treated\", \"Control\")) %>%\r\n  select(year, is_treated) %>%\r\n  pivot_longer(.,-is_treated) %>%\r\n  group_by(name, is_treated, value) %>%\r\n  summarise(n = n()) %>%\r\n  mutate(proportion = round(n / sum(n) * 100, 0)) %>%\r\n  ungroup()\r\n\r\n# we plot the data using cleveland dot plots\r\ngraph_year <-\r\n  ggplot(data_year,\r\n         aes(\r\n           x = as.factor(value),\r\n           y = proportion,\r\n           colour = is_treated,\r\n           group = is_treated\r\n         )) +\r\n  geom_line(size = 1) +\r\n  scale_colour_manual(values = c(my_blue, my_orange),\r\n                      guide = guide_legend(reverse = FALSE)) +\r\n  ggtitle(\"Year\") +\r\n  ylab(\"Proportion (%)\") +\r\n  xlab(\"\") +\r\n  labs(colour = \"Units Status:\") +\r\n  theme_tufte() +\r\n  theme(\r\n    legend.position = \"top\",\r\n    legend.justification = \"left\",\r\n    legend.direction = \"horizontal\"\r\n  )\r\n\r\n# we print the graph\r\ngraph_year\r\n\r\n\r\n\r\n\r\nWe combine and save the two previous plots:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# combine plots\r\ngraph_month_year <- graph_month / graph_year +\r\n  plot_annotation(tag_levels = 'A') &\r\n  theme(plot.tag = element_text(size = 20, face = \"bold\"))\r\n\r\n# save the plot\r\nggsave(\r\n  graph_month_year,\r\n  filename = here::here(\"inputs\", \"3.outputs\", \"2.matching_analysis\", \"graph_month_year.pdf\"),\r\n  width = 20,\r\n  height = 17,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2022-04-08T10:20:21+02:00"
    },
    {
      "path": "6_checking_balance_improvement.html",
      "title": "Checking Balance Improvement",
      "description": "Comparing days with Wind Blowing from the North-East to Other Directions. Adjusting for calendar indicators and other weather variables.\n",
      "author": [
        {
          "name": "Léo Zabrocki",
          "url": "https://lzabrocki.github.io/"
        },
        {
          "name": "Anna Alari",
          "url": "https://scholar.google.com/citations?user=MiFY320AAAAJ&hl=fr"
        },
        {
          "name": "Tarik Benmarhnia",
          "url": "https://profiles.ucsd.edu/tarik.benmarhnia"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\r\n\r\nContents\r\nRequired Packages\r\nPreparing the Data\r\nLove Plots\r\nContinuous Weather Covariates\r\nCategorical Weather Covariates\r\nPollutants\r\nCalendar Indicators\r\n\r\nOverall Balance Improvement\r\nContinuous Covariates\r\nCategorical Covariates\r\nCombining Plots\r\n\r\nRandomization Check\r\n\r\n\r\nbody {\r\ntext-align: justify}\r\nIn this document, we take great care providing all steps and R codes required to check whether our matching procedure allowed to improve covariates balance. We compare days where:\r\ntreated units are days where winds blow from the North-East in t.\r\ncontrol units are day winds blow from other directions in t.\r\nWe adjust for calendar indicators and weather confouding factors.\r\nShould you have any questions, need help to reproduce the analysis or find coding errors, please do not hesitate to contact me at leo.zabrocki@psemail.eu\r\nRequired Packages\r\nTo reproduce exactly the 4_script_checking_balance_improvement.html document, we first need to have installed:\r\nthe R programming language\r\nRStudio, an integrated development environment for R, which will allow you to knit the 4_script_checking_balance_improvement.Rmd file and interact with the R code chunks\r\nthe R Markdown package\r\nand the Distill package which provides the template for this document.\r\nOnce everything is set up, we have to load the following packages:\r\n\r\n\r\n# load required packages\r\nlibrary(knitr) # for creating the R Markdown document\r\nlibrary(here) # for files paths organization\r\nlibrary(tidyverse) # for data manipulation and visualization\r\nlibrary(ggridges) # for ridge density plots\r\nlibrary(Cairo) # for printing custom police of graphs\r\nlibrary(patchwork) # combining plots\r\n\r\n\r\n\r\nWe finally load our custom ggplot2 theme for graphs:\r\n\r\n\r\n# load ggplot custom theme\r\nsource(here::here(\r\n  \"inputs\",\r\n  \"2.functions\",\r\n  \"script_theme_tufte.R\"\r\n))\r\n# define nice colors\r\nmy_blue <- \"#0081a7\"\r\nmy_orange <- \"#fb8500\"\r\n\r\n\r\n\r\nPreparing the Data\r\nWe load the initial and matched data and bind them together:\r\n\r\n\r\n# load matching data\r\ndata_matching <-\r\n  readRDS(here::here(\"inputs\", \"1.data\", \"5.matched_data\", \"matching_data.rds\")) %>%\r\n  mutate(dataset = \"Initial Data\")\r\n\r\n# load matched data\r\ndata_matched <-\r\n  readRDS(here::here(\"inputs\", \"1.data\", \"5.matched_data\", \"matched_data.rds\")) %>%\r\n  mutate(dataset = \"Matched Data\")\r\n\r\n# bind the two datasets\r\ndata <- bind_rows(data_matching, data_matched)\r\n\r\n\r\n\r\nWe change labels of the is_treated variable :\r\n\r\n\r\ndata <- data %>%\r\n  mutate(is_treated = ifelse(is_treated == \"TRUE\", \"True\", \"False\"))\r\n\r\n\r\n\r\nLove Plots\r\nContinuous Weather Covariates\r\n\r\n\r\nPlease show me the code!\r\n\r\n# compute figures for the love plot\r\ndata_weather_continuous <- data %>%\r\n  select(\r\n    dataset,\r\n    is_treated,\r\n    contains(\"temperature\"),\r\n    contains(\"humidity\"),\r\n    contains(\"wind_speed\")\r\n  ) %>%\r\n  pivot_longer(\r\n    cols = -c(is_treated, dataset),\r\n    names_to = \"variable\",\r\n    values_to = \"values\"\r\n  ) %>%\r\n  mutate(\r\n    weather_variable = NA %>%\r\n      ifelse(\r\n        str_detect(variable, \"temperature_average\"),\r\n        \"Average Temperature\",\r\n        .\r\n      ) %>%\r\n      ifelse(\r\n        str_detect(variable, \"humidity_average\"),\r\n        \"Humidity Average\",\r\n        .\r\n      ) %>%\r\n      ifelse(str_detect(variable, \"wind_speed\"), \"Wind Speed\", .)\r\n  ) %>%\r\n  mutate(time = \"0\" %>%\r\n           ifelse(str_detect(variable, \"lag_1\"), \"-1\", .) %>%\r\n           ifelse(str_detect(variable, \"lead_1\"), \"+1\", .)) %>%\r\n  filter(time != \"+1\") %>%\r\n  mutate(time = fct_relevel(time, \"-1\", \"0\")) %>%\r\n  select(dataset, is_treated, weather_variable, time, values)\r\n\r\ndata_abs_difference_continuous_weather <-\r\n  data_weather_continuous %>%\r\n  group_by(dataset, weather_variable, time, is_treated) %>%\r\n  summarise(mean_values = mean(values, na.rm = TRUE)) %>%\r\n  summarise(abs_difference = abs(mean_values[2] - mean_values[1]))\r\n\r\ndata_sd_weather_continuous <-  data_weather_continuous %>%\r\n  filter(dataset== \"Initial Data\" & is_treated == \"True\") %>%\r\n  group_by(dataset, weather_variable, time, is_treated) %>%\r\n  summarise(sd_treatment = sd(values, na.rm = TRUE)) %>%\r\n  ungroup() %>%\r\n  select(weather_variable, time, sd_treatment)\r\n\r\ndata_love_continuous_weather <-\r\n  left_join(\r\n    data_abs_difference_continuous_weather,\r\n    data_sd_weather_continuous,\r\n    by = c(\"weather_variable\", \"time\")\r\n  ) %>%\r\n  mutate(standardized_difference = abs_difference / sd_treatment) %>%\r\n  select(-c(abs_difference, sd_treatment))\r\n\r\n# make the graph\r\ngraph_love_plot_continuous_weather <-\r\n  ggplot(\r\n    data_love_continuous_weather,\r\n    aes(\r\n      y = time,\r\n      x = standardized_difference,\r\n      colour = fct_rev(dataset),\r\n      shape = fct_rev(dataset)\r\n    )\r\n  ) +\r\n  geom_vline(xintercept = 0, size = 0.3) +\r\n  geom_vline(xintercept = 0.1,\r\n             color = \"black\",\r\n             linetype = \"dashed\") +\r\n  geom_point(size = 4, alpha = 0.8) +\r\n  scale_x_continuous(breaks = scales::pretty_breaks(n = 5)) +\r\n  scale_colour_manual(name = \"Dataset:\", values = c(my_blue, my_orange)) +\r\n  scale_shape_manual(name = \"Dataset:\", values = c(17, 16)) +\r\n  facet_wrap( ~ weather_variable, scales = \"free_y\") +\r\n  xlab(\"Standardized Mean Differences\") +\r\n  ylab(\"Day\") +\r\n  theme_tufte()\r\n\r\n# plot the graph\r\ngraph_love_plot_continuous_weather\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the graph\r\nggsave(\r\n  graph_love_plot_continuous_weather,\r\n  filename = here::here(\r\n    \"inputs\", \"3.outputs\",\r\n    \"2.matching_analysis\",\r\n    \"graph_love_plot_continuous_weather.pdf\"\r\n  ),\r\n  width = 30,\r\n  height = 12,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nCategorical Weather Covariates\r\n\r\n\r\nPlease show me the code!\r\n\r\n# compute figures for the love plot\r\ndata_weather_categorical <- data %>%\r\n  select(\r\n    dataset,\r\n    is_treated,\r\n    contains(\"rainfall_duration\"),\r\n    \"wind_direction_categories_lag_1\"\r\n  ) %>%\r\n  drop_na() %>%\r\n  mutate_all( ~ as.character(.)) %>%\r\n  pivot_longer(\r\n    cols = -c(dataset, is_treated),\r\n    names_to = \"variable\",\r\n    values_to = \"values\"\r\n  ) %>%\r\n  # group by is_treated, variable and values\r\n  group_by(dataset, is_treated, variable, values) %>%\r\n  # compute the number of observations\r\n  summarise(n = n()) %>%\r\n  # compute the proportion\r\n  mutate(freq = round(n / sum(n) * 100, 0)) %>%\r\n  ungroup() %>%\r\n  mutate(\r\n    weather_variable = NA %>%\r\n      ifelse(str_detect(variable, \"wind\"), \"Wind Direction\", .) %>%\r\n      ifelse(str_detect(variable, \"rainfall\"), \"Rainfall Duration\", .)\r\n  ) %>%\r\n  mutate(time = \"t\" %>%\r\n           ifelse(str_detect(variable, \"lag_1\"), \"t-1\", .) %>%\r\n           ifelse(str_detect(variable, \"lead_1\"), \"t+1\", .)) %>%\r\n  filter(time != \"t+1\") %>%\r\n  mutate(variable = paste(weather_variable, time, sep = \" \")) %>%\r\n  select(dataset, is_treated, weather_variable, variable, values, freq) %>%\r\n  pivot_wider(names_from = is_treated, values_from = freq) %>%\r\n  mutate(abs_difference = abs(`True` - `False`)) %>%\r\n  filter(weather_variable != \"Wind Direction t\")\r\n\r\n\r\n# create the figure for wind direction\r\ngraph_love_plot_wind_direction <- data_weather_categorical %>%\r\n  filter(weather_variable == \"Wind Direction\") %>%\r\n  ggplot(.,\r\n         aes(\r\n           y = fct_rev(values),\r\n           x = abs_difference,\r\n           colour = fct_rev(dataset),\r\n           shape = fct_rev(dataset)\r\n         )) +\r\n  geom_vline(xintercept = 0, size = 0.3) +\r\n  geom_point(size = 4, alpha = 0.8) +\r\n  scale_colour_manual(name = \"Dataset:\", values = c(my_blue, my_orange)) +\r\n  scale_shape_manual(name = \"Dataset:\", values = c(17, 16)) +\r\n  facet_wrap( ~ variable, scales = \"free_y\", ncol = 3) +\r\n  xlab(\"Absolute Difference in Percentage Points\") +\r\n  ylab(\"\") +\r\n  theme_tufte() +\r\n  theme(axis.text.x = element_text(margin = ggplot2::margin(t = 0, unit = \"cm\")))\r\n\r\n# print the figure for wind direction\r\ngraph_love_plot_wind_direction\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the figure for wind direction\r\nggsave(\r\n  graph_love_plot_wind_direction,\r\n  filename = here::here(\r\n    \"inputs\", \"3.outputs\",\r\n    \"2.matching_analysis\",\r\n    \"graph_love_plot_wind_direction.pdf\"\r\n  ),\r\n  width = 20,\r\n  height = 10,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n# create the figure for rainfall dummy\r\ngraph_love_plot_rainfall <- data_weather_categorical %>%\r\n  filter(weather_variable == \"Rainfall Duration\") %>%\r\n  mutate(variable = fct_relevel(variable, \"Rainfall Duration t-1\", \"Rainfall Duration t\")) %>%\r\n  ggplot(.,\r\n         aes(\r\n           y = fct_rev(values),\r\n           x = abs_difference,\r\n           colour = fct_rev(dataset),\r\n           shape = fct_rev(dataset)\r\n         )) +\r\n  geom_vline(xintercept = 0, size = 0.3) +\r\n  geom_point(size = 4, alpha = 0.8) +\r\n  facet_wrap( ~ variable) +\r\n  scale_colour_manual(name = \"Dataset:\", values = c(my_blue, my_orange)) +\r\n  scale_shape_manual(name = \"Dataset:\", values = c(17, 16)) +\r\n  xlab(\"Absolute Difference in Percentage Points\") +\r\n  ylab(\"\") +\r\n  theme_tufte() +\r\n  theme(axis.text.x = element_text(margin = ggplot2::margin(t = 0, unit = \"cm\")),\r\n        axis.text.y = element_text(hjust = 1))\r\n\r\n# print the figure for rainfall dummy\r\ngraph_love_plot_rainfall\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the figure for rainfall dummy\r\nggsave(\r\n  graph_love_plot_rainfall,\r\n  filename = here::here(\r\n    \"inputs\", \"3.outputs\",\r\n    \"2.matching_analysis\",\r\n    \"graph_love_plot_rainfall.pdf\"\r\n  ),\r\n  width = 20,\r\n  height = 10,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nPollutants\r\n\r\n\r\nPlease show me the code!\r\n\r\n# compute figures for the love plot\r\ndata_pollutants <- data %>%\r\n  select(\r\n    dataset,\r\n    is_treated,\r\n    mean_no2_lag_1,\r\n    mean_o3_lag_1,\r\n    mean_pm10_lag_1,\r\n    mean_pm25_lag_1\r\n  ) %>%\r\n  pivot_longer(\r\n    cols = -c(dataset, is_treated),\r\n    names_to = \"variable\",\r\n    values_to = \"values\"\r\n  ) %>%\r\n  mutate(\r\n    pollutant = NA %>%\r\n      ifelse(str_detect(variable, \"no2\"), \"NO2 in t-1\", .) %>%\r\n      ifelse(str_detect(variable, \"o3\"), \"O3 in t-1\", .) %>%\r\n      ifelse(str_detect(variable, \"pm10\"), \"PM10 in t-1\", .) %>%\r\n      ifelse(str_detect(variable, \"pm25\"), \"PM2.5 in t-1\", .)\r\n  ) %>%\r\n  select(dataset, is_treated, pollutant, values)\r\n\r\ndata_abs_difference_pollutants <- data_pollutants %>%\r\n  group_by(dataset, pollutant, is_treated) %>%\r\n  summarise(mean_values = mean(values, na.rm = TRUE)) %>%\r\n  summarise(abs_difference = abs(mean_values[2] - mean_values[1]))\r\n\r\ndata_sd_pollutants <-  data_pollutants %>%\r\n  filter(dataset== \"Initial Data\" & is_treated == \"True\") %>%\r\n  group_by(pollutant, is_treated) %>%\r\n  summarise(sd_treatment = sd(values, na.rm = TRUE)) %>%\r\n  ungroup() %>%\r\n  select(pollutant, sd_treatment)\r\n\r\ndata_love_pollutants <-\r\n  left_join(data_abs_difference_pollutants,\r\n            data_sd_pollutants,\r\n            by = c(\"pollutant\")) %>%\r\n  mutate(standardized_difference = abs_difference / sd_treatment) %>%\r\n  select(-c(abs_difference, sd_treatment))\r\n\r\n# create the graph\r\ngraph_love_plot_pollutants <-\r\n  ggplot(\r\n    data_love_pollutants,\r\n    aes(\r\n      y = fct_rev(pollutant),\r\n      x = standardized_difference,\r\n      colour = fct_rev(dataset),\r\n      shape = fct_rev(dataset)\r\n    )\r\n  ) +\r\n  geom_vline(xintercept = 0, size = 0.3) +\r\n  geom_vline(xintercept = 0.1,\r\n             color = \"black\",\r\n             linetype = \"dashed\") +\r\n  geom_point(size = 4, alpha = 0.8) +\r\n  scale_x_continuous(breaks = scales::pretty_breaks(n = 5)) +\r\n  scale_colour_manual(name = \"Dataset:\", values = c(my_blue, my_orange)) +\r\n  scale_shape_manual(name = \"Dataset:\", values = c(17, 16)) +\r\n  xlab(\"Standardized Mean Differences\") +\r\n  ylab(\"\") +\r\n  theme_tufte() +\r\n  theme(axis.text.x = element_text(margin = ggplot2::margin(t = 0, unit = \"cm\")),\r\n        axis.text.y = element_text(hjust = 1))\r\n\r\n# print the graph\r\ngraph_love_plot_pollutants\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the graph\r\nggsave(\r\n  graph_love_plot_pollutants,\r\n  filename = here::here(\r\n    \"inputs\", \"3.outputs\",\r\n    \"2.matching_analysis\",\r\n    \"graph_love_plot_pollutants.pdf\"\r\n  ),\r\n  width = 20,\r\n  height = 10,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nCalendar Indicators\r\nCreate the relevant data:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# compute figures for the love plot\r\ndata_calendar <- data %>%\r\n  mutate(weekday = lubridate::wday(date, abbr = FALSE, label = TRUE)) %>%\r\n  select(dataset,\r\n         is_treated,\r\n         weekday,\r\n         holidays_dummy,\r\n         bank_day_dummy,\r\n         month,\r\n         year) %>%\r\n  mutate_at(vars(holidays_dummy, bank_day_dummy),\r\n            ~ ifelse(. == 1, \"True\", \"False\")) %>%\r\n  mutate_all( ~ as.character(.)) %>%\r\n  pivot_longer(\r\n    cols = -c(dataset, is_treated),\r\n    names_to = \"variable\",\r\n    values_to = \"values\"\r\n  ) %>%\r\n  # group by is_treated, variable and values\r\n  group_by(dataset, is_treated, variable, values) %>%\r\n  # compute the number of observations\r\n  summarise(n = n()) %>%\r\n  # compute the proportion\r\n  mutate(freq = round(n / sum(n) * 100, 0)) %>%\r\n  ungroup() %>%\r\n  mutate(\r\n    calendar_variable = NA %>%\r\n      ifelse(str_detect(variable, \"weekday\"), \"Day of the Week\", .) %>%\r\n      ifelse(str_detect(variable, \"holidays_dummy\"), \"Holidays\", .) %>%\r\n      ifelse(str_detect(variable, \"bank_day_dummy\"), \"Bank Day\", .) %>%\r\n      ifelse(str_detect(variable, \"month\"), \"Month\", .) %>%\r\n      ifelse(str_detect(variable, \"year\"), \"Year\", .)\r\n  ) %>%\r\n  select(dataset, is_treated, calendar_variable, values, freq) %>%\r\n  pivot_wider(names_from = is_treated, values_from = freq) %>%\r\n  mutate(abs_difference = abs(`True` - `False`)) %>%\r\n  filter(values != \"False\")\r\n\r\n\r\n\r\nPlot for bank days and holidays:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# graph for bank days and holidays\r\ngraph_love_plot_bank_holidays <- data_calendar %>%\r\n  filter(calendar_variable %in% c(\"Bank Day\", \"Holidays\")) %>%\r\n  ggplot(.,\r\n         aes(\r\n           y = values,\r\n           x = abs_difference,\r\n           colour = fct_rev(dataset),\r\n           shape = fct_rev(dataset)\r\n         )) +\r\n  geom_vline(xintercept = 0, size = 0.3) +\r\n  geom_point(size = 4, alpha = 0.8) +\r\n  scale_colour_manual(name = \"Dataset:\", values = c(my_blue, my_orange)) +\r\n  scale_shape_manual(name = \"Dataset:\", values = c(17, 16)) +\r\n  facet_wrap(~ calendar_variable) +\r\n  xlab(\"Absolute Difference in Percentage Points\") +\r\n  ylab(\"\") +\r\n  theme_tufte() +\r\n  theme(axis.text.x = element_text(margin = ggplot2::margin(t = 0, unit = \"cm\")))\r\n\r\n# print the plot\r\ngraph_love_plot_bank_holidays\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the plot\r\nggsave(\r\n  graph_love_plot_bank_holidays,\r\n  filename = here::here(\r\n    \"inputs\", \"3.outputs\",\r\n    \"2.matching_analysis\",\r\n    \"graph_love_plot_bank_holidays.pdf\"\r\n  ),\r\n  width = 16,\r\n  height = 8,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nPlot for days of the week:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# graph for weekdays\r\ngraph_love_plot_weekday <- data_calendar %>%\r\n  filter(calendar_variable == \"Day of the Week\") %>%\r\n  mutate(\r\n    values = fct_relevel(\r\n      values,\r\n      \"Monday\",\r\n      \"Tuesday\",\r\n      \"Wednesday\",\r\n      \"Thursday\",\r\n      \"Friday\",\r\n      \"Saturday\",\r\n      \"Sunday\"\r\n    )\r\n  ) %>%\r\n  ggplot(.,\r\n         aes(\r\n           y = fct_rev(values),\r\n           x = abs_difference,\r\n           colour = fct_rev(dataset),\r\n           shape = fct_rev(dataset)\r\n         )) +\r\n  geom_vline(xintercept = 0, size = 0.3) +\r\n  geom_point(size = 4, alpha = 0.8) +\r\n  scale_colour_manual(name = \"Dataset:\", values = c(my_blue, my_orange)) +\r\n  scale_shape_manual(name = \"Dataset:\", values = c(17, 16)) +\r\n  xlab(\"Absolute Difference in Percentage Points\") +\r\n  ylab(\"\") +\r\n  theme_tufte() +\r\n  theme(axis.text.x = element_text(margin = ggplot2::margin(t = 0, unit = \"cm\")),\r\n        axis.text.y = element_text(hjust = 1))\r\n\r\n\r\n# print the plot\r\ngraph_love_plot_weekday\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the plot\r\nggsave(\r\n  graph_love_plot_weekday,\r\n  filename = here::here(\r\n    \"inputs\", \"3.outputs\",\r\n    \"2.matching_analysis\",\r\n    \"graph_love_plot_weekday.pdf\"\r\n  ),\r\n  width = 16,\r\n  height = 8,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nPlot for months:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# graph for month\r\ngraph_love_plot_month <- data_calendar %>%\r\n  filter(calendar_variable == \"Month\") %>%\r\n  mutate(\r\n    values = fct_relevel(\r\n      values,\r\n      \"January\",\r\n      \"February\",\r\n      \"March\",\r\n      \"April\",\r\n      \"May\",\r\n      \"June\",\r\n      \"July\",\r\n      \"August\",\r\n      \"September\",\r\n      \"October\",\r\n      \"November\",\r\n      \"December\"\r\n    )\r\n  ) %>%\r\n  ggplot(.,\r\n         aes(\r\n           y = fct_rev(values),\r\n           x = abs_difference,\r\n           colour = fct_rev(dataset),\r\n           shape = fct_rev(dataset)\r\n         )) +\r\n  geom_vline(xintercept = 0, size = 0.3) +\r\n  geom_point(size = 4, alpha = 0.8) +\r\n  scale_colour_manual(name = \"Dataset:\", values = c(my_blue, my_orange)) +\r\n  scale_shape_manual(name = \"Dataset:\", values = c(17, 16)) +\r\n  ggtitle(\"Month\") +\r\n  xlab(\"Absolute Difference in Percentage Points\") +\r\n  ylab(\"\") +\r\n  theme_tufte() +\r\n  theme(axis.text.x = element_text(margin = ggplot2::margin(t = 0, unit = \"cm\")),\r\n        axis.text.y = element_text(hjust = 1))\r\n\r\n# print the plot\r\ngraph_love_plot_month\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the plot\r\nggsave(\r\n  graph_love_plot_month,\r\n  filename = here::here(\r\n    \"inputs\", \"3.outputs\",\r\n    \"2.matching_analysis\",\r\n    \"graph_love_plot_month.pdf\"\r\n  ),\r\n  width = 16,\r\n  height = 8,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nPlot for years:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# graph for year\r\ngraph_love_plot_year <- data_calendar %>%\r\n  filter(calendar_variable == \"Year\") %>%\r\n  ggplot(.,\r\n         aes(\r\n           y = as.factor(as.numeric(values)),\r\n           x = abs_difference,\r\n           colour = fct_rev(dataset),\r\n           shape = fct_rev(dataset)\r\n         )) +\r\n  geom_vline(xintercept = 0, size = 0.3) +\r\n  geom_point(size = 4, alpha = 0.8) +\r\n  scale_colour_manual(name = \"Dataset:\", values = c(my_blue, my_orange)) +\r\n  scale_shape_manual(name = \"Dataset:\", values = c(17, 16)) +\r\n  ggtitle(\"Year\") +\r\n  xlab(\"Absolute Difference in Percentage Points\") +\r\n  ylab(\"\") +\r\n  theme_tufte() +\r\n  theme(axis.text.x = element_text(margin = ggplot2::margin(t = 0, unit = \"cm\")),\r\n        axis.text.y = element_text(hjust = 1))\r\n\r\n\r\n# print the graph\r\ngraph_love_plot_year\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the plot\r\nggsave(\r\n  graph_love_plot_year,\r\n  filename = here::here(\r\n    \"inputs\", \"3.outputs\",\r\n    \"2.matching_analysis\",\r\n    \"graph_love_plot_year.pdf\"\r\n  ),\r\n  width = 16,\r\n  height = 8,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nOverall Balance Improvement\r\nWe finally plot the distribution of standardized mean differences for continuous covariates or the absolute percentage points differences for categorical covariates between treated and control units before and after matching.\r\nContinuous Covariates\r\n\r\n\r\nPlease show me the code!\r\n\r\n# we select the dataset indicator and the standardized difference\r\ndata_love_pollutants <- data_love_pollutants %>%\r\n  ungroup() %>%\r\n  select(dataset, standardized_difference)\r\n\r\ndata_love_continuous_weather <- data_love_continuous_weather %>%\r\n  ungroup() %>%\r\n  select(dataset, standardized_difference)\r\n\r\ndata_continuous_love <-\r\n  bind_rows(data_love_pollutants, data_love_continuous_weather)\r\n\r\n# create the graph\r\ngraph_boxplot_continuous_balance_improvement <-\r\n  ggplot(data_continuous_love,\r\n         aes(x = dataset, y = standardized_difference)) +\r\n  ggbeeswarm::geom_quasirandom(\r\n    shape = 16,\r\n    size = 2,\r\n    width = 0.1,\r\n    color = my_blue,\r\n    alpha = 0.8\r\n  ) +\r\n  scale_y_continuous(breaks = scales::pretty_breaks(n = 5)) +\r\n  xlab(\"Dataset\") +\r\n  ylab(\"Standardized\\nMean Differences\") +\r\n  ggtitle(\"Continuous Variables\") +\r\n  theme_tufte() +\r\n  theme(axis.text.x = element_text(margin = ggplot2::margin(t = 0, unit = \"cm\")))\r\n\r\n# print the graph\r\ngraph_boxplot_continuous_balance_improvement\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the graph\r\nggsave(\r\n  graph_boxplot_continuous_balance_improvement,\r\n  filename = here::here(\r\n    \"inputs\", \"3.outputs\",\r\n    \"2.matching_analysis\",\r\n    \"graph_boxplot_continuous_balance_improvement.pdf\"\r\n  ),\r\n  width = 12,\r\n  height = 8,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nCategorical Covariates\r\n\r\n\r\nPlease show me the code!\r\n\r\n# we select the dataset indicator and the standardized difference\r\ndata_calendar <- data_calendar %>%\r\n  ungroup() %>%\r\n  select(dataset, abs_difference)\r\n\r\ndata_weather_categorical <- data_weather_categorical %>%\r\n  ungroup() %>%\r\n  select(dataset, abs_difference)\r\n\r\ndata_categorical_love <-\r\n  bind_rows(data_calendar, data_weather_categorical)\r\n\r\n# create the graph\r\ngraph_boxplot_categorical_balance_improvement <-\r\n  ggplot(data_categorical_love, aes(x = dataset, y = abs_difference)) +\r\n  ggbeeswarm::geom_quasirandom(\r\n    shape = 16,\r\n    size = 2,\r\n    width = 0.2,\r\n    color = my_blue,\r\n    alpha = 0.8\r\n  ) +\r\n  scale_y_continuous(breaks = scales::pretty_breaks(n = 5)) +\r\n  xlab(\"Dataset\") +\r\n  ylab(\"Absolute Difference \\nin Percentage Points\") +\r\n  ggtitle(\"Categorical Variables\") +\r\n  theme_tufte() +\r\n  theme(axis.text.x = element_text(margin = ggplot2::margin(t = 0, unit = \"cm\")))\r\n\r\n\r\n# print the graph\r\ngraph_boxplot_categorical_balance_improvement\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the graph\r\nggsave(\r\n  graph_boxplot_categorical_balance_improvement,\r\n  filename = here::here(\r\n    \"inputs\", \"3.outputs\",\r\n    \"2.matching_analysis\",\r\n    \"graph_boxplot_categorical_balance_improvement.pdf\"\r\n  ),\r\n  width = 12,\r\n  height = 8,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nCombining Plots\r\nWe combine the two previous plots:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# combine the two previous plots\r\ngraph_overall_balance  <-\r\n  graph_boxplot_continuous_balance_improvement + graph_boxplot_categorical_balance_improvement +\r\n  plot_annotation(tag_levels = 'A')\r\n\r\n\r\n# display graph\r\ngraph_overall_balance\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the graph\r\nggsave(\r\n  graph_overall_balance,\r\n  filename = here::here(\r\n    \"inputs\", \"3.outputs\",\r\n    \"2.matching_analysis\",\r\n    \"graph_overall_balance.pdf\"\r\n  ),\r\n  width = 20,\r\n  height = 10,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nAnd we compute the overall figures for imbalance before and after matching:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# compute average imbalance before and after matching\r\ndata_categorical_love <- data_categorical_love %>%\r\n  mutate(Type = \"Categorical (Difference in Percentage Points)\") %>%\r\n  rename(standardized_difference = abs_difference)\r\n  \r\ndata_continuous_love %>%\r\n  mutate(Type = \"Continuous (Standardized Difference)\") %>%\r\n  bind_rows(data_categorical_love) %>%\r\n  group_by(Type, dataset) %>%\r\n  summarise(\"Mean Imbalance\" = round(mean(standardized_difference), 2)) %>%\r\n  rename(Dataset = dataset) %>%\r\n  knitr::kable(., align = c(\"l\", \"l\", \"c\"))\r\n\r\n\r\nType\r\nDataset\r\nMean Imbalance\r\nCategorical (Difference in Percentage Points)\r\nInitial Data\r\n6.23\r\nCategorical (Difference in Percentage Points)\r\nMatched Data\r\n1.75\r\nContinuous (Standardized Difference)\r\nInitial Data\r\n0.26\r\nContinuous (Standardized Difference)\r\nMatched Data\r\n0.07\r\n\r\nRandomization Check\r\nFinally, we carry out a randomization check to statistically test whether the overall balance has increased after matching. As proposed by Gerber and Green (2012), we use as a balance measure the F-statistic from a regression where we regress the treatment indicator on all covariates.\r\nWe first compute the observed F-statistic for the initial data:\r\n\r\n\r\n# compute f-statistic for initial data \r\nfstat_initial_data <- data_matching %>%\r\n    lm(\r\n      is_treated ~ temperature_average + I(temperature_average ^ 2) +\r\n        temperature_average_lag_1 + I(temperature_average_lag_1 ^ 2) +\r\n        rainfall_duration + rainfall_duration_lag_1 +\r\n        humidity_average + humidity_average_lag_1 +\r\n        wind_speed + wind_speed_lag_1 +\r\n        weekday + holidays_dummy +\r\n        bank_day_dummy + month * as.factor(year),\r\n      data = .\r\n    ) %>%\r\n    broom::glance() %>%\r\n    pull(statistic)\r\n\r\n\r\n\r\nThe F-statistic is equal to 8 for the initial data. We then freely permute 1000 times the treatment indicator to build the null distribution of the F-statistic:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# function to permute freely the treatment indicator\r\nf_stat_free_permutation <- function(data) {\r\n  data %>%\r\n    mutate(is_treated = dqrng::dqsample(is_treated)) %>%\r\n    lm(\r\n      is_treated ~ temperature_average + I(temperature_average ^ 2) +\r\n        temperature_average_lag_1 + I(temperature_average_lag_1 ^ 2) +\r\n        rainfall_duration + rainfall_duration_lag_1 +\r\n        humidity_average + humidity_average_lag_1 +\r\n        wind_speed + wind_speed_lag_1 +\r\n        weekday + holidays_dummy +\r\n        bank_day_dummy + month * as.factor(year),\r\n      data = .\r\n    ) %>%\r\n    broom::glance() %>%\r\n    pull(statistic)\r\n} \r\n\r\n# run 1000 permutations\r\ndata_f_stat_free_permutation <- tibble(sim_id = 1:1000) %>%\r\n  crossing(data_matching) %>%\r\n  group_by(sim_id) %>%\r\n  nest() %>%\r\n  mutate(f_stat = map(data, ~ f_stat_free_permutation(.))) %>%\r\n  select(-data) %>%\r\n  unnest(f_stat)\r\n\r\n# save results\r\nsaveRDS(data_f_stat_free_permutation, here::here(\"inputs\", \"1.data\", \"5.matched_data\", \"data_f_stat_free_permutation.rds\"))\r\n\r\n\r\n\r\nWe plot the null distribution of the F-statistic:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# open results\r\ndata_f_stat_free_permutation <- readRDS(here::here(\"inputs\", \"1.data\", \"5.matched_data\", \"data_f_stat_free_permutation.rds\"))\r\n\r\n# make the graph\r\ngraph_f_stat_free_permutation <- data_f_stat_free_permutation %>%\r\n  ggplot(., aes(x = f_stat)) +\r\n  geom_density(colour = my_blue) +\r\n  geom_vline(xintercept = fstat_initial_data, colour = my_orange) +\r\n  xlim(0, 8) +\r\n  labs(x = \"Simulated F-Statistics\", y = \"Density\", title = \"Null Distribution of the F-statistic\\nUnder Free Permutations of the Treatment\") +\r\n  theme_tufte()\r\n\r\n\r\n# display the graph\r\ngraph_f_stat_free_permutation\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the graph\r\nggsave(\r\n  graph_f_stat_free_permutation + labs(title = NULL),\r\n  filename = here::here(\r\n    \"inputs\", \"3.outputs\",\r\n    \"2.matching_analysis\",\r\n    \"graph_balance_check_initial_data_1.pdf\"\r\n  ),\r\n  width = 15,\r\n  height = 10,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nWe can clearly reject the hypothesis that the no observed covariates have any effect on the treatment assignment. However, we freely permuted the treatment indicator, which removed the temporal structure of the data. To keep this temporal structure, we therefore carry out another balancing test where we permute the treatment indicator within a year and a month:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# function to permute by block the treatment indicator\r\nf_stat_block_permutation <- function(data) {\r\n  data %>%\r\n    group_by(year, month) %>%\r\n    mutate(is_treated = dqrng::dqsample(is_treated)) %>%\r\n    lm(\r\n      is_treated ~ temperature_average + I(temperature_average ^ 2) +\r\n        temperature_average_lag_1 + I(temperature_average_lag_1 ^ 2) +\r\n        rainfall_duration + rainfall_duration_lag_1 +\r\n        humidity_average + humidity_average_lag_1 +\r\n        wind_speed + wind_speed_lag_1 +\r\n        weekday + holidays_dummy +\r\n        bank_day_dummy + month * as.factor(year),\r\n      data = .\r\n    ) %>%\r\n    broom::glance() %>%\r\n    pull(statistic)\r\n} \r\n\r\n# run 1000 permutations\r\ndata_f_stat_block_permutation <- tibble(sim_id = 1:1000) %>%\r\n  crossing(data_matching) %>%\r\n  group_by(sim_id) %>%\r\n  nest() %>%\r\n  mutate(f_stat = map(data, ~ f_stat_block_permutation(.))) %>%\r\n  select(-data) %>%\r\n  unnest(f_stat)\r\n\r\n# save results\r\nsaveRDS(data_f_stat_block_permutation, here::here(\"inputs\", \"1.data\", \"5.matched_data\", \"data_f_stat_block_permutation.rds\"))\r\n\r\n\r\n\r\nWe plot the null distribution of the F-statistic:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# open results\r\ndata_f_stat_block_permutation <- readRDS(here::here(\"inputs\", \"1.data\", \"5.matched_data\", \"data_f_stat_block_permutation.rds\"))\r\n\r\n# make the graph\r\ngraph_f_stat_block_permutation <- data_f_stat_block_permutation %>%\r\n  ggplot(., aes(x = f_stat)) +\r\n  geom_density(colour = my_blue) +\r\n  geom_vline(xintercept = fstat_initial_data, colour = my_orange) +\r\n  xlim(0, 8) +\r\n  labs(x = \"Simulated F-Statistics\", y = \"Density\", title = \"Null Distribution of the F-statistic\\nUnder Permutations of the Treatment Within a Year and a Month\") +\r\n  theme_tufte()\r\n\r\n# display the graph\r\ngraph_f_stat_block_permutation\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the graph\r\nggsave(\r\n  graph_f_stat_block_permutation + labs(title = NULL),\r\n  filename = here::here(\r\n    \"inputs\", \"3.outputs\",\r\n    \"2.matching_analysis\",\r\n    \"graph_balance_check_initial_data_2.pdf\"\r\n  ),\r\n  width = 15,\r\n  height = 10,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nAgain, we can reject the null hypothesis that no observed covariates have any effect on the treatment assignment.\r\nWe then compute the balance check for the matched data. We permute the treatment indicator within each pair as our matching procedure approximates a pairwise randomized experiment.\r\nWe compute the observed F-statistic for the matched data:\r\n\r\n\r\n# compute f-statistic for matched data \r\nfstat_matched_data <- data_matched %>%\r\n    lm(\r\n      is_treated ~ temperature_average + I(temperature_average ^ 2) +\r\n        temperature_average_lag_1 + I(temperature_average_lag_1 ^ 2) +\r\n        rainfall_duration + rainfall_duration_lag_1 +\r\n        humidity_average + humidity_average_lag_1 +\r\n        wind_speed + wind_speed_lag_1 +\r\n        weekday + holidays_dummy +\r\n        bank_day_dummy + month + as.factor(year),\r\n      data = .\r\n    ) %>%\r\n    broom::glance() %>%\r\n    pull(statistic)\r\n\r\n\r\n\r\nThe F-statistic is equal to 0.5 for the matched data. We then implement our balance test:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# function to permute by pair the treatment indicator\r\nf_stat_pair_permutation <- function(data) {\r\n  data %>%\r\n    group_by(pair_number) %>%\r\n    mutate(is_treated = dqrng::dqsample(is_treated)) %>%\r\n    lm(\r\n      is_treated ~ temperature_average + I(temperature_average ^ 2) +\r\n        temperature_average_lag_1 + I(temperature_average_lag_1 ^ 2) +\r\n        rainfall_duration + rainfall_duration_lag_1 +\r\n        humidity_average + humidity_average_lag_1 +\r\n        wind_speed + wind_speed_lag_1 +\r\n        weekday + holidays_dummy +\r\n        bank_day_dummy + month + as.factor(year),\r\n      data = .\r\n    ) %>%\r\n    broom::glance() %>%\r\n    pull(statistic)\r\n} \r\n\r\n# run 1000 permutations\r\ndata_f_stat_matched_permutation <- tibble(sim_id = 1:1000) %>%\r\n  crossing(data_matched) %>%\r\n  group_by(sim_id) %>%\r\n  nest() %>%\r\n  mutate(f_stat = map(data, ~ f_stat_pair_permutation(.))) %>%\r\n  select(-data) %>%\r\n  unnest(f_stat)\r\n\r\n# save results\r\nsaveRDS(data_f_stat_matched_permutation, here::here(\"inputs\", \"1.data\", \"5.matched_data\", \"data_f_stat_matched_permutation.rds\"))\r\n\r\n\r\n\r\nWe plot the null distribution of the F-statistic:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# open results\r\ndata_f_stat_matched_permutation <- readRDS(here::here(\"inputs\", \"1.data\", \"5.matched_data\", \"data_f_stat_matched_permutation.rds\"))\r\n\r\n# make the graph\r\ngraph_f_stat_matched_permutation <- data_f_stat_matched_permutation %>%\r\n  ggplot(., aes(x = f_stat)) +\r\n  geom_density(colour = my_blue) +\r\n  geom_vline(xintercept = fstat_matched_data, colour = my_orange) +\r\n  xlim(0, 1.5) +\r\n  labs(x = \"Simulated F-Statistics\", y = \"Density\", title = \"Null Distribution of the F-statistic\\nUnder Permutations of the Treatment Within Pairs\") +\r\n  theme_tufte()\r\n\r\n# display graph\r\ngraph_f_stat_matched_permutation\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the graph\r\nggsave(\r\n  graph_f_stat_matched_permutation + labs(title = NULL),\r\n  filename = here::here(\r\n    \"inputs\", \"3.outputs\",\r\n    \"2.matching_analysis\",\r\n    \"graph_balance_check_matched_data.pdf\"\r\n  ),\r\n  width = 15,\r\n  height = 10,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nWe can clearly see that the value of our observed F-statistic is likely to be obtained under the null hypothesis. Matching seems to have improve the covariates balance.\r\n\r\n\r\n\r\n",
      "last_modified": "2022-04-08T11:02:00+02:00"
    },
    {
      "path": "7_analyzing_results.html",
      "title": "Analyzing Results",
      "description": "Comparing days with Wind Blowing from the North-East to Other Directions. Adjusting for calendar indicators and other weather variables.\n",
      "author": [
        {
          "name": "Léo Zabrocki",
          "url": "https://lzabrocki.github.io/"
        },
        {
          "name": "Anna Alari",
          "url": "https://scholar.google.com/citations?user=MiFY320AAAAJ&hl=fr"
        },
        {
          "name": "Tarik Benmarhnia",
          "url": "https://profiles.ucsd.edu/tarik.benmarhnia"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\r\n\r\nContents\r\nRequired Packages\r\nPreparing the Data\r\nDistribution of the Pair Differences in Concentration between Treated and Control units for each Pollutant\r\nComputing Pairs Differences in Pollutant Concentrations\r\nPairs Differences in NO2 Concentrations\r\nPairs Differences in O3 Concentrations\r\nPairs Differences in PM10 Concentrations\r\nPairs Differences in PM2.5 Concentrations\r\n\r\nNeymanian Inference: Computing 95% and 99% Confidence Intervals for the Average Treatment Effects\r\nRobustness Checks\r\nMissing Concentrations\r\nAre results on PM\\(_{10}\\) sensitive to hidden bias?\r\nDoes pairing improve precision?\r\nComparison with an Outcome Regression Analysis on Initial Data\r\n\r\n\r\n\r\nbody {\r\ntext-align: justify}\r\nIn this document, we take great care providing all steps and R codes required to estimate the influence of North-East winds on air pollutants. We compare days where:\r\ntreated units are days where winds blow from the North-East in t.\r\ncontrol units are day winds blow from other directions in t.\r\nWe adjust for calendar indicators and weather confouding factors.\r\nShould you have any questions, need help to reproduce the analysis or find coding errors, please do not hesitate to contact me at leo.zabrocki@psemail.eu\r\nRequired Packages\r\nTo reproduce exactly the 5_script_analyzing_results.html document, we first need to have installed:\r\nthe R programming language\r\nRStudio, an integrated development environment for R, which will allow you to knit the 5_script_analyzing_results.Rmd file and interact with the R code chunks\r\nthe R Markdown package\r\nand the Distill package which provides the template for this document.\r\nOnce everything is set up, we have to load the following packages:\r\n\r\n\r\n# load required packages\r\nlibrary(knitr) # for creating the R Markdown document\r\nlibrary(here) # for files paths organization\r\nlibrary(tidyverse) # for data manipulation and visualization\r\nlibrary(retrodesign) # for assessing type m and s errors\r\nlibrary(Cairo) # for printing custom police of graphs\r\nlibrary(patchwork) # combining plots\r\nlibrary(DT) # for tables\r\n\r\n\r\n\r\nWe finally load our custom ggplot2 theme for graphs:\r\n\r\n\r\n# load ggplot custom theme\r\nsource(here::here(\r\n  \"inputs\",\r\n  \"2.functions\",\r\n  \"script_theme_tufte.R\"\r\n))\r\n# define nice colors\r\nmy_blue <- \"#0081a7\"\r\nmy_orange <- \"#fb8500\"\r\n\r\n\r\n\r\nPreparing the Data\r\nWe load the matched data:\r\n\r\n\r\n# load matched data\r\ndata_matched <-\r\n  readRDS(here::here(\"inputs\", \"1.data\", \"5.matched_data\", \"matched_data.rds\"))\r\n\r\n\r\n\r\nDistribution of the Pair Differences in Concentration between Treated and Control units for each Pollutant\r\nComputing Pairs Differences in Pollutant Concentrations\r\nWe first compute the differences in a pollutant’s concentration for each pair over time:\r\n\r\n\r\ndata_matched_wide <- data_matched %>%\r\n  mutate(is_treated = ifelse(is_treated == TRUE, \"treated\", \"control\")) %>%\r\n  select(\r\n    is_treated,\r\n    pair_number,\r\n    contains(\"mean_no2\"),\r\n    contains(\"mean_o3\"),\r\n    contains(\"mean_pm10\"),\r\n    contains(\"mean_pm25\")\r\n  ) %>%\r\n  pivot_longer(\r\n    cols = -c(pair_number, is_treated),\r\n    names_to = \"variable\",\r\n    values_to = \"concentration\"\r\n  ) %>%\r\n  mutate(\r\n    pollutant = NA %>%\r\n      ifelse(str_detect(variable, \"no2\"), \"NO2\", .) %>%\r\n      ifelse(str_detect(variable, \"o3\"), \"O3\", .) %>%\r\n      ifelse(str_detect(variable, \"pm10\"), \"PM10\", .) %>%\r\n      ifelse(str_detect(variable, \"pm25\"), \"PM2.5\", .)\r\n  ) %>%\r\n  mutate(time = 0 %>%\r\n           ifelse(str_detect(variable, \"lag_1\"),-1, .) %>%\r\n           ifelse(str_detect(variable, \"lead_1\"), 1, .)) %>%\r\n  select(-variable) %>%\r\n  select(pair_number, is_treated, pollutant, time, concentration) %>%\r\n  pivot_wider(names_from = is_treated, values_from = concentration) %>%\r\n  unnest()\r\n\r\ndata_pair_difference_pollutant <- data_matched_wide %>%\r\n  mutate(difference = treated - control) %>%\r\n  select(-c(treated, control)) \r\n\r\n\r\n\r\nPairs Differences in NO2 Concentrations\r\nBoxplots for NO2:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# create the graph for no2\r\ngraph_boxplot_difference_pollutant_no2 <-\r\n  data_pair_difference_pollutant %>%\r\n  filter(str_detect(pollutant, \"NO2\")) %>%\r\n  ggplot(., aes(x = as.factor(time), y = difference)) +\r\n  geom_boxplot(colour = my_blue, size = 0.3) +\r\n  scale_y_continuous(breaks = scales::pretty_breaks(n = 8)) +\r\n  facet_wrap( ~ pollutant) +\r\n  ylab(\"Pair Difference in \\nConcentration (µg/m3)\") + xlab(\"Day\") +\r\n  theme_tufte()\r\n\r\n# display the graph\r\ngraph_boxplot_difference_pollutant_no2\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the graph\r\nggsave(\r\n  graph_boxplot_difference_pollutant_no2,\r\n  filename = here::here(\r\n    \"inputs\", \"3.outputs\",\r\n    \"2.matching_analysis\",\r\n    \"graph_boxplot_difference_pollutant_no2.pdf\"\r\n  ),\r\n  width = 18,\r\n  height = 9,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nPairs Differences in O3 Concentrations\r\nBoxplots for O3:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# create the graph for o3\r\ngraph_boxplot_difference_pollutant_o3 <-\r\n  data_pair_difference_pollutant %>%\r\n  filter(str_detect(pollutant, \"O3\")) %>%\r\n  ggplot(., aes(x = as.factor(time), y = difference)) +\r\n  geom_boxplot(colour = my_blue, size = 0.3) +\r\n  scale_y_continuous(breaks = scales::pretty_breaks(n = 8)) +\r\n  ylab(\"Pair Difference in \\nConcentration (µg/m3)\") + xlab(\"Day\") +\r\n  theme_tufte()\r\n\r\n# display the graph\r\ngraph_boxplot_difference_pollutant_o3\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the graph\r\nggsave(\r\n  graph_boxplot_difference_pollutant_o3,\r\n  filename = here::here(\r\n    \"inputs\", \"3.outputs\",\r\n    \"2.matching_analysis\",\r\n    \"graph_boxplot_difference_pollutant_o3.pdf\"\r\n  ),\r\n  width = 18,\r\n  height = 9,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nPairs Differences in PM10 Concentrations\r\nBoxplots for PM10:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# create the graph for pm10\r\ngraph_boxplot_difference_pollutant_pm10 <-\r\n  data_pair_difference_pollutant %>%\r\n  filter(str_detect(pollutant, \"PM10\")) %>%\r\n  ggplot(., aes(x = as.factor(time), y = difference)) +\r\n  geom_boxplot(colour = my_blue, size = 0.3) +\r\n  scale_y_continuous(breaks = scales::pretty_breaks(n = 8)) +\r\n  facet_wrap( ~ pollutant) +\r\n  ylab(\"Pair Difference in \\nConcentration (µg/m3)\") + xlab(\"Day\") +\r\n  theme_tufte()\r\n\r\n# display the graph\r\ngraph_boxplot_difference_pollutant_pm10\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the graph\r\nggsave(\r\n  graph_boxplot_difference_pollutant_pm10,\r\n  filename = here::here(\r\n    \"inputs\", \"3.outputs\",\r\n    \"2.matching_analysis\",\r\n    \"graph_boxplot_difference_pollutant_pm10.pdf\"\r\n  ),\r\n  width = 18,\r\n  height = 9,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nPairs Differences in PM2.5 Concentrations\r\nBoxplots for PM2.5:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# create the graph for pm10\r\ngraph_boxplot_difference_pollutant_pm25 <-\r\n  data_pair_difference_pollutant %>%\r\n  filter(str_detect(pollutant, \"PM2.5\")) %>%\r\n  ggplot(., aes(x = as.factor(time), y = difference)) +\r\n  geom_boxplot(colour = my_blue, size = 0.3) +\r\n  scale_y_continuous(breaks = scales::pretty_breaks(n = 8)) +\r\n  facet_wrap( ~ pollutant) +\r\n  ylab(\"Pair Difference in \\nConcentration (µg/m3)\") + xlab(\"Day\") +\r\n  theme_tufte()\r\n\r\n# display the graph\r\ngraph_boxplot_difference_pollutant_pm25\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the graph\r\nggsave(\r\n  graph_boxplot_difference_pollutant_pm25,\r\n  filename = here::here(\r\n    \"inputs\", \"3.outputs\",\r\n    \"2.matching_analysis\",\r\n    \"graph_boxplot_difference_pollutant_pm25.pdf\"\r\n  ),\r\n  width = 18,\r\n  height = 9,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nNeymanian Inference: Computing 95% and 99% Confidence Intervals for the Average Treatment Effects\r\nWe compute confidence intervals for the average treatment effect of North-East winds using Neyman’s approach. We use the formula for the standard error of pair randomized experiment found in Imbens and Rubin (2015).\r\n\r\n\r\n# we first compute the average treatment effects for each pollutant and day\r\ndata_pair_mean_difference <- data_pair_difference_pollutant %>%\r\n  filter(pollutant != \"PM2.5\") %>%\r\n  group_by(pollutant, time) %>%\r\n  summarise(mean_difference = mean(difference)) %>%\r\n  ungroup()\r\n\r\n# we store the number of pairs\r\nn_pair <- nrow(data_matched) / 2\r\n\r\n# compute the standard error\r\ndata_se_neyman_pair <-\r\n  left_join(\r\n    data_pair_difference_pollutant,\r\n    data_pair_mean_difference,\r\n    by = c(\"pollutant\", \"time\")\r\n  ) %>%\r\n  mutate(squared_difference = (difference - mean_difference) ^ 2) %>%\r\n  group_by(pollutant, time) %>%\r\n  summarise(standard_error = sqrt(1 / (n_pair * (n_pair - 1)) * sum(squared_difference))) %>%\r\n  select(pollutant, time, standard_error) %>%\r\n  ungroup()\r\n\r\n# merge the average treatment effect data witht the standard error data\r\ndata_neyman <-\r\n  left_join(data_pair_mean_difference,\r\n            data_se_neyman_pair,\r\n            by = c(\"pollutant\", \"time\")) %>%\r\n# compute the 95% and 99% confidence intervals\r\n  mutate(\r\n    upper_bound_95 = mean_difference + (-qnorm((1 - 0.95) / 2) * standard_error),\r\n    lower_bound_95 = mean_difference - (-qnorm((1 - 0.95) / 2) * standard_error),\r\n    upper_bound_99 = mean_difference + (-qnorm((1 - 0.99) / 2) * standard_error),\r\n    lower_bound_99 = mean_difference - (-qnorm((1 - 0.99) / 2) * standard_error)\r\n  )\r\n\r\n\r\n\r\nWe plot below the point estimates and the associated 95% and 99% confidence intervals:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# create an indicator to alternate shading of confidence intervals\r\ndata_neyman <- data_neyman %>%\r\n  arrange(pollutant, time) %>%\r\n  mutate(stripe = ifelse((time %% 2) == 0, \"Grey\", \"White\")) %>%\r\n  ungroup()\r\n\r\n# make the graph\r\ngraph_ci <-\r\n  ggplot(data_neyman,\r\n         aes(x = as.factor(time), y = mean_difference)) +\r\n  geom_rect(\r\n    aes(fill = stripe),\r\n    xmin = as.numeric(as.factor(data_neyman$time)) - 0.42,\r\n    xmax = as.numeric(as.factor(data_neyman$time)) + 0.42,\r\n    ymin = -Inf,\r\n    ymax = Inf,\r\n    color = NA,\r\n    alpha = 0.4\r\n  ) +\r\n  geom_hline(yintercept = 0,\r\n             color = \"black\",\r\n             size = 0.3) +\r\n  geom_pointrange(\r\n    aes(\r\n      x = as.factor(time),\r\n      y = mean_difference,\r\n      ymin = lower_bound_95 ,\r\n      ymax = upper_bound_95\r\n    ),\r\n    colour = my_blue,\r\n    fatten = 1.5, \r\n    size = 2\r\n) +\r\n  geom_pointrange(\r\n    aes(\r\n      x = as.factor(time),\r\n      y = mean_difference,\r\n      ymin = lower_bound_99 ,\r\n      ymax = upper_bound_99\r\n    ),\r\n    colour = my_blue,\r\n    lwd = 0.5\r\n  ) +\r\n  scale_y_continuous(breaks = scales::pretty_breaks(n = 8)) +\r\n  facet_wrap( ~ pollutant, ncol = 4) +\r\n  scale_fill_manual(values = c('gray96', \"white\")) +\r\n  guides(fill = FALSE) +\r\n  ylab(\"Average Increase in\\n Concentrations (µg/m³)\") + xlab(\"Day\") +\r\n  theme_tufte() +\r\n  theme(axis.text.x = element_text(margin = ggplot2::margin(t = 0, unit = \"cm\")))\r\n\r\n\r\n# print the graph\r\ngraph_ci\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the graph\r\nggsave(\r\n  graph_ci,\r\n  filename = here::here(\"inputs\", \"3.outputs\", \"2.matching_analysis\", \"graph_ci.pdf\"),\r\n  width = 16,\r\n  height = 8,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nWe display below the table with the point estimates and the 95% and 99% confidence intervals:\r\n\r\n\r\n{\"x\":{\"filter\":\"none\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"],[\"NO2\",\"NO2\",\"NO2\",\"O3\",\"O3\",\"O3\",\"PM10\",\"PM10\",\"PM10\"],[-1,0,1,-1,0,1,-1,0,1],[0.7,1.5,1,-2.8,-1.2,1.3,0.2,4.4,4.9],[-4.3,-3.4,-4.5,-7.5,-5.5,-4.6,-0.9,1.7,1.8],[5.7,6.4,6.4,1.9,3.1,7.1,1.2,7.2,8.1],[-5.9,-5,-6.2,-9,-6.8,-6.4,-1.2,0.8,0.8],[7.3,7.9,8.1,3.4,4.4,9,1.6,8.1,9.1]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>Pollutant<\\/th>\\n      <th>Time<\\/th>\\n      <th>Point Estimate<\\/th>\\n      <th>Lower Bound of the 95% Neymanian Interval<\\/th>\\n      <th>Upper Bound of the 95% Neymanian Interval<\\/th>\\n      <th>Lower Bound of the 99% Neymanian Interval<\\/th>\\n      <th>Upper Bound of the 99% Neymanian Interval<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[2,3,4,5,6,7]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}\r\nWe can finally check if there is also an effect on North-East winds on PM2.5 concentrations. One issue is that Paris did not have measuring stations for background PM2.5 concentrations from 2009-09-22 to 2010-06-23, that is to say 274 days. We did not impute these missing concentrations but can nonetheless assess if the North-East winds influence the observed pollutant concentrations. We proceed as before but only work with pairs of days without missing PM2.5 recordings:\r\n\r\n\r\n# we first only select pm2.5 pair differences\r\ndata_pair_difference_pollutant_pm25 <- data_pair_difference_pollutant %>%\r\n  filter(pollutant == \"PM2.5\")\r\n\r\n# we then find pairs with missing PM2.5 concentrations\r\npairs_to_remove <- data_pair_difference_pollutant_pm25 %>%\r\n  filter(is.na(difference)) %>% \r\n  distinct(pair_number) %>%\r\n  pull(pair_number)\r\n\r\n# we remove those pairs\r\ndata_pair_difference_pollutant_pm25 <- data_pair_difference_pollutant_pm25 %>%\r\n  filter(!(pair_number %in% pairs_to_remove))\r\n\r\n# we compute the average treatment effects for pm2.5 and by day\r\ndata_pair_mean_difference_pm25 <-  data_pair_difference_pollutant_pm25 %>%\r\n  group_by(time) %>%\r\n  summarise(mean_difference = mean(difference, na.rm = TRUE)) %>%\r\n  ungroup()\r\n\r\n# we store the number of pairs\r\nn_pair <- length(unique(data_pair_difference_pollutant_pm25$pair_number))\r\n\r\n# we compute the standard error\r\ndata_se_neyman_pair_pm25 <-\r\n  left_join(\r\n    data_pair_difference_pollutant_pm25,\r\n    data_pair_mean_difference_pm25,\r\n    by = c(\"time\")\r\n  ) %>%\r\n  mutate(squared_difference = (difference - mean_difference) ^ 2) %>%\r\n  group_by(time) %>%\r\n  summarise(standard_error = sqrt(1 / (n_pair * (n_pair - 1)) * sum(squared_difference))) %>%\r\n  select(time, standard_error) %>%\r\n  ungroup()\r\n\r\n# merge the average treatment effect data witht the standard error data\r\ndata_neyman_pm25 <-\r\n  left_join(data_pair_mean_difference_pm25,\r\n            data_se_neyman_pair_pm25,\r\n            by = c(\"time\")) %>%\r\n# compute the 95% and 99% confidence intervals\r\n  mutate(\r\n    upper_bound_95 = mean_difference + (-qnorm((1 - 0.95) / 2) * standard_error),\r\n    lower_bound_95 = mean_difference - (-qnorm((1 - 0.95) / 2) * standard_error),\r\n    upper_bound_99 = mean_difference + (-qnorm((1 - 0.99) / 2) * standard_error),\r\n    lower_bound_99 = mean_difference - (-qnorm((1 - 0.99) / 2) * standard_error)\r\n  )\r\n\r\n\r\n\r\nWe display below the estimates for the ATE and the associated 95% and 99% confidence intervals:\r\n\r\n\r\n{\"x\":{\"filter\":\"none\",\"data\":[[\"1\",\"2\",\"3\"],[-1,0,1],[-0.1,1.4,2.7],[-1.2,-0.6,0.8],[1,3.4,4.5],[-1.5,-1.3,0.2],[1.3,4,5.1]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>Time<\\/th>\\n      <th>Point Estimate<\\/th>\\n      <th>Lower Bound of the 95% Neymanian Interval<\\/th>\\n      <th>Upper Bound of the 95% Neymanian Interval<\\/th>\\n      <th>Lower Bound of the 99% Neymanian Interval<\\/th>\\n      <th>Upper Bound of the 99% Neymanian Interval<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,2,3,4,5,6]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}\r\nRobustness Checks\r\nMissing Concentrations\r\nWe load non-imputed air pollution data and compute for each pollutant the 0-1 daily lags and leads:\r\n\r\n\r\n# load non-imputed data\r\ndata_not_imputed <-\r\n  readRDS(here::here(\"inputs\", \"1.data\", \"4.data_for_analysis\", \"data_pollutants_not_imputed.rds\"))\r\n\r\n# merge with matched data\r\ndata_missing <- left_join(data_matched, data_not_imputed, by = \"date\")\r\n\r\n# display proportion of missing values\r\ndata_missing %>%\r\n  pivot_longer(\r\n    cols = c(not_imputed_mean_pm25:not_imputed_mean_pm10),\r\n    names_to = \"Pollutant\",\r\n    values_to = \"concentration\"\r\n  ) %>%\r\n  group_by(Pollutant) %>%\r\n  summarise(\"Missing Proportion (%)\" = round(sum(is.na(concentration)) /\r\n                                               n() * 100, 1)) %>%\r\n  knitr::kable(., align = c(\"l\", \"c\"))\r\n\r\n\r\n\r\nPollutant\r\n\r\n\r\nMissing Proportion (%)\r\n\r\n\r\nnot_imputed_mean_no2\r\n\r\n\r\n13.2\r\n\r\n\r\nnot_imputed_mean_o3\r\n\r\n\r\n8.3\r\n\r\n\r\nnot_imputed_mean_pm10\r\n\r\n\r\n7.4\r\n\r\n\r\nnot_imputed_mean_pm25\r\n\r\n\r\n23.1\r\n\r\n\r\n\r\n\r\n# load non-imputed data\r\ndata_not_imputed <-\r\n  readRDS(here::here(\"inputs\", \"1.data\", \"4.data_for_analysis\", \"data_pollutants_not_imputed.rds\")) %>%\r\n  select(-not_imputed_mean_pm25)\r\n\r\n# we first define data_not_imputed_leads and data_not_imputed_lags\r\n# to store leads and lags\r\n\r\ndata_not_imputed_leads <- data_not_imputed\r\ndata_not_imputed_lags <- data_not_imputed\r\n\r\n#\r\n# create leads\r\n# \r\n\r\n# create a list to store dataframe of leads\r\nleads_list <- vector(mode = \"list\", length = 1)\r\nnames(leads_list) <- c(1) \r\n\r\n# create the leads\r\nfor(i in 1){\r\n  leads_list[[i]] <- data_not_imputed_leads %>%\r\n    mutate_at(vars(-date), ~  lead(., n = i, order_by = date)) %>%\r\n    rename_at(vars(-date),function(x) paste0(x,\"_lead_\", i))\r\n}\r\n\r\n# merge the dataframes of leads\r\ndata_leads <- leads_list %>%\r\n  reduce(left_join, by = \"date\")\r\n\r\n# merge the leads with the data_not_imputed_leads\r\ndata_not_imputed_leads <- left_join(data_not_imputed_leads, data_leads, by = \"date\") %>%\r\n  select(-c(not_imputed_mean_no2:not_imputed_mean_pm10))\r\n\r\n#\r\n# create lags\r\n# \r\n\r\n# create a list to store dataframe of lags\r\nlags_list <- vector(mode = \"list\", length = 1)\r\nnames(lags_list) <- c(1) \r\n\r\n# create the lags\r\nfor(i in 1){\r\n  lags_list[[i]] <- data_not_imputed_lags %>%\r\n    mutate_at(vars(-date), ~  lag(., n = i, order_by = date)) %>%\r\n    rename_at(vars(-date),function(x) paste0(x,\"_lag_\", i))\r\n}\r\n\r\n# merge the dataframes of lags\r\ndata_lags <- lags_list %>%\r\n  reduce(left_join, by = \"date\")\r\n\r\n# merge the lags with the initial data_not_imputed_lags\r\ndata_not_imputed_lags <- left_join(data_not_imputed_lags, data_lags, by = \"date\")\r\n\r\n#\r\n# merge data_not_imputed_leads with data_not_imputed_lags\r\n#\r\n\r\ndata_not_imputed <- left_join(data_not_imputed_lags, data_not_imputed_leads, by = \"date\")\r\n\r\n\r\n\r\nWe merge these data with the matched data and compute pair differences:\r\n\r\n\r\n# merge with the matched_data\r\ndata_matched_with_missing_pollutants <- left_join(data_matched, data_not_imputed, by = \"date\")\r\n\r\n# compute pair differences\r\ndata_matched_wide_missing_pollutants <- data_matched_with_missing_pollutants %>%\r\n  mutate(is_treated = ifelse(is_treated == TRUE, \"treated\", \"control\")) %>%\r\n  select(is_treated, pair_number, contains(\"not_imputed_mean_no2\"), contains(\"not_imputed_mean_o3\"), contains(\"not_imputed_mean_pm10\")) %>%\r\n  pivot_longer(cols = -c(pair_number, is_treated), names_to = \"variable\", values_to = \"concentration\") %>%\r\n  mutate(pollutant = NA %>%\r\n           ifelse(str_detect(variable, \"no2\"), \"NO2\",.) %>%\r\n           ifelse(str_detect(variable, \"o3\"), \"O3\",.) %>%\r\n           ifelse(str_detect(variable, \"pm10\"), \"PM10\",.)) %>%\r\n  mutate(time = 0 %>%\r\n           ifelse(str_detect(variable, \"lag_1\"), -1, .) %>%\r\n           ifelse(str_detect(variable, \"lead_1\"), 1, .)) %>%\r\n  select(-variable) %>%\r\n  select(pair_number, is_treated, pollutant, time, concentration) %>% \r\n  pivot_wider(names_from = is_treated, values_from = concentration)\r\n\r\ndata_missing_pair_difference_pollutant <- data_matched_wide_missing_pollutants %>%\r\n  mutate(difference = treated-control) %>%\r\n  select(-c(treated, control)) \r\n\r\n\r\n\r\nWe display below the proportion of missing differences by pollutant and day:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# make the graph\r\ngraph_missing_pollutants <- data_missing_pair_difference_pollutant %>%\r\n  group_by(pollutant, time) %>%\r\n  summarise(proportion_missing = sum(is.na(difference))/n()*100) %>%\r\n  ggplot(., aes(x = as.factor(time), y = proportion_missing)) +\r\n  geom_segment(aes(x = as.factor(time), xend = as.factor(time), y = 0, yend = proportion_missing)) +\r\n  geom_point(shape = 21, size = 4, colour = \"black\", fill = my_blue) +\r\n  ylim(0, 100) +\r\n  facet_wrap(~ pollutant, ncol = 4) +\r\n  xlab(\"Day\") + ylab(\"Proportion of Pairs with \\nMissing Concentrations (%)\") +\r\n  theme_tufte()\r\n  \r\n# display the graph\r\ngraph_missing_pollutants\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the graph\r\nggsave(\r\n  graph_missing_pollutants,\r\n  filename = here::here(\r\n    \"inputs\", \"3.outputs\",\r\n    \"2.matching_analysis\",\r\n    \"graph_missing_pollutants.pdf\"\r\n  ),\r\n  width = 20,\r\n  height = 10,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nClearly, many missing concentrations in the matched pairs were imputed. We compute the point estimates and confidence intervals for the pairs without missing values. Here, we use a Wilcoxon’s test to also make the results less sensitive to potential outliers:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# carry out the wilcox.test \r\ndata_missing_rank_ci <- data_missing_pair_difference_pollutant %>%\r\n  drop_na() %>%\r\n  select(- pair_number) %>%\r\n  group_by(pollutant, time) %>%\r\n  nest() %>%\r\n  mutate(mean_difference = map(data, ~ wilcox.test(.$difference, conf.int = TRUE)$estimate),\r\n         lower_bound_95 = map(data, ~ wilcox.test(.$difference, conf.int = TRUE)$conf.int[1]),\r\n         upper_bound_95 = map(data, ~ wilcox.test(.$difference, conf.int = TRUE)$conf.int[2])) %>%\r\n  unnest(cols = c(mean_difference, lower_bound_95, upper_bound_95)) %>%\r\n  mutate(data = \"Pairs without Missing Concentrations\")\r\n\r\n# bind with analysis on imputed concentrations\r\ndata_imputed_nonimputed <- data_neyman %>%\r\n  mutate(data = \"Pairs with Imputed Concentrations\") %>%\r\n  select(pollutant,\r\n         time,\r\n         mean_difference,\r\n         lower_bound_95,\r\n         upper_bound_95,\r\n         data) %>%\r\n  bind_rows(.,  data_missing_rank_ci)\r\n\r\n# create an indicator to alternate shading of confidence intervals\r\ndata_imputed_nonimputed <- data_imputed_nonimputed %>%\r\n  arrange(pollutant, time) %>%\r\n  mutate(stripe = ifelse((time %% 2) == 0, \"Grey\", \"White\")) %>%\r\n  ungroup()\r\n\r\n# make the graph\r\ngraph_ci_missing <-\r\n  ggplot(data_imputed_nonimputed,\r\n         aes(x = as.factor(time), y = mean_difference, ymin = lower_bound_95, ymax = upper_bound_95, colour = data, shape = data)) +\r\n  geom_rect(\r\n    aes(fill = stripe),\r\n    xmin = as.numeric(as.factor(data_imputed_nonimputed$time)) - 0.42,\r\n    xmax = as.numeric(as.factor(data_imputed_nonimputed$time)) + 0.42,\r\n    ymin = -Inf,\r\n    ymax = Inf,\r\n    color = NA,\r\n    alpha = 0.4\r\n  ) +\r\n  geom_hline(yintercept = 0,\r\n             color = \"black\",\r\n             size = 0.3) +\r\n  geom_pointrange(position = position_dodge(width = 1), size = 1.2) +\r\n  scale_shape_manual(name = \"Dataset:\", values = c(16, 17)) +\r\n  scale_color_manual(name = \"Dataset:\", values = c(my_orange, my_blue)) +\r\n  scale_y_continuous(breaks = scales::pretty_breaks(n = 8)) +\r\n  facet_wrap( ~ pollutant, ncol = 4) +\r\n  scale_fill_manual(values = c('gray96', \"white\")) +\r\n  guides(fill = FALSE) +\r\n  ylab(\"Average Increase in\\n Concentrations (µg/m³)\") + xlab(\"Day\") +\r\n  theme_tufte() +\r\n  theme(axis.text.x = element_text(margin = ggplot2::margin(t = 0, unit = \"cm\")))\r\n\r\n\r\n# print the graph\r\ngraph_ci_missing\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the graph\r\nggsave(\r\n  graph_ci_missing,\r\n  filename = here::here(\"inputs\", \"3.outputs\", \"2.matching_analysis\", \"graph_ci_missing.pdf\"),\r\n  width = 16,\r\n  height = 8,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nResults seem relatively robust to the imputation of missing values.\r\nAre results on PM\\(_{10}\\) sensitive to hidden bias?\r\nTo assess whether the effects of North-East winds on PM\\(_{10}\\) concentrations could be due to hidden bias, we implement the studentized sensitivity analysis for the ATE developed by Colin B. Fogarty (2019). We first load the relevant functions:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# load fogarty's studentized Sensitivity Analysis functions\r\n# retrieved from http://www.mit.edu/~cfogarty/StudentizedSensitivity.R\r\n\r\n#' StudentizedSensitivity\r\n#'Function to perform a Studentized Sensitivity analysis on the sample average treatment\r\n#'effect in a paired observational study\r\n#'\r\n#' @param PairedDiff: Vector of treated-minus-control paired differences.\r\n#' @param null: Value of the sample average treatment effect under the null.\r\n#' @param alpha: Desired Type I error rate.\r\n#' @param alternative: Can be \"less\", \"greater\", or \"two.sided\".\r\n#' @param Gamma: Vector of values for Gamma at which to perform the sensitivity\r\n#'  analysis.\r\n#' @param nperm: Number of permutations to perform permutation test.\r\n#' @param Changepoint: If true, function returns the maximal Gamma for which the\r\n#' test rejects at level alpha.\r\n#' @param SensitivityInterval: If true, function returns (100-alpha) sensitivity\r\n#' intervals. They will be one-sided if the alternative is less than or greater than,\r\n#' and two-sided if the alternative is two-sided.\r\n#'\r\n#' @return Gamma: Vector of Gammas for which the sensitivity analysis was performed.\r\n#' @return pval: P-values for each value of Gamma.\r\n#' @return GammaPval: Matrix combining Gamma and pval.\r\n#' @return Changepoint: Maximal Gamma for which the test rejected at level alpha.\r\n#' @return SensitivityInterval: Upper and lower bounds for 100(1-alpha) sensitivity\r\n#' intervals for each value of Gamma.\r\n#' @export\r\n\r\n\r\nStudentizedSensitivity = function(PairedDiff, null = 0, alpha = 0.05, alternative = \"greater\", Gamma = 1, nperm = 50000, Changepoint = T, SensitivityInterval = T)\r\n{\r\n   if(any(Gamma < 1))\r\n   {\r\n     stop(\"Values for Gamma must be >= 1\")\r\n   }\r\n   if(alternative!=\"less\" & alternative!= \"greater\" & alternative != \"two.sided\")\r\n   {\r\n     stop(\"Values for alternative are `less', `greater', or `two.sided'\")\r\n   }\r\n   if(length(null) > 1)\r\n   {\r\n     stop(\"Value under the null must be a scalar\")\r\n   }\r\n      if(alpha < 0 | alpha > 0.5)\r\n   {\r\n     stop(\"alpha must be between 0 and 0.5\")\r\n      }\r\n\r\n  PairedDifftrue <- PairedDiff\r\n  alphatrue <- alpha\r\n  I <- length(PairedDiff)\r\n  Adjust <- PairedDiff - null\r\n\r\n  if(alternative == \"less\")\r\n  {\r\n    Adjust <- -Adjust\r\n  }\r\n  if(alternative == \"two.sided\")\r\n  {\r\n    alpha <- alphatrue/2\r\n\r\n    if(mean(Adjust) < 0)\r\n    {\r\n      Adjust <- -Adjust\r\n    }\r\n  }\r\n\r\n  pval <- rep(0, length(Gamma))\r\n\r\n  for(i in 1:length(Gamma))\r\n\r\n  {\r\n  D <- (Adjust) - (Gamma[i]-1)/(1+Gamma[i])*abs(Adjust)\r\n  obs <- mean(D)/(sd(D)/sqrt(I))\r\n  Adjmat <- matrix(abs(Adjust), I, nperm)\r\n  Zmat <- matrix(runif(I*nperm) < Gamma[i]/(1+Gamma[i]), I, nperm)\r\n  Dmat <- (2*Zmat-1)*(Adjmat) - (Gamma[i]-1)/(1+Gamma[i])*Adjmat\r\n  perm <- colMeans(Dmat)/(sqrt(colVars(Dmat)/I))\r\n  pval[i] <- (1+sum(perm>=obs))/(nperm + 1)\r\n  }\r\n  pvalret = pval\r\n  if(alternative == \"two.sided\")\r\n  {\r\n    pvalret = 2*pval\r\n  }\r\n  Pmatrix <- cbind(Gamma, pvalret)\r\n  colnames(Pmatrix) <- c(\"Gamma\", \"P-value\")\r\n\r\n  if(Changepoint == T)\r\n  {\r\n    proceed <- StudentizedSensitivity(PairedDifftrue, null, alphatrue, alternative, Gamma=1, nperm,\r\n                                      Changepoint = F, SensitivityInterval = F)$pval <= alphatrue\r\n\r\n    change <- 1\r\n\r\n    if(proceed)\r\n    {\r\n      change <- uniroot(StudentizedChangepoint, interval = c(1, 30), PairedDiff = PairedDifftrue, null = null,\r\n                        alpha = alphatrue, alternative = alternative, nperm = nperm,\r\n                        extendInt = \"upX\")$root\r\n    }\r\n  }\r\n\r\n  if(SensitivityInterval == T)\r\n    {\r\n      lb = rep(-Inf, length(Gamma))\r\n      ub = rep(Inf, length(Gamma))\r\n      for(i in 1:length(Gamma))\r\n      {\r\n        # Warm Starts\r\n      UB = uniroot(BoundFinder, PairedDifftrue, Gamma[i],\r\n                   interval = c(mean(PairedDifftrue), mean(PairedDifftrue)+4*sd(PairedDifftrue)/sqrt(I)), extendInt = \"yes\")$root\r\n      LB = -uniroot(BoundFinder, -PairedDifftrue, Gamma[i],\r\n                    interval = c(-mean(PairedDifftrue)-4*sd(PairedDifftrue)/sqrt(I), -mean(PairedDifftrue)), extendInt = \"yes\")$root\r\n\r\n      SUB = Inf\r\n      SLB = -Inf\r\n\r\n      if(alternative == \"greater\")\r\n      {\r\n        SLB = uniroot(StudentizedSI, interval = c(UB-4*sd(PairedDifftrue)/sqrt(I), UB), extendInt = \"yes\",\r\n                      Gamma = Gamma[i], PairedDiff=PairedDifftrue, alternative = \"greater\", alpha = alpha, nperm = nperm)$root\r\n      }\r\n\r\n      if(alternative == \"less\")\r\n      {\r\n        SUB = uniroot(StudentizedSI, interval = c(LB, LB + 4*sd(PairedDifftrue)/sqrt(I)), extendInt = \"yes\",\r\n                      Gamma = Gamma[i], PairedDiff=PairedDifftrue, alternative = \"less\", alpha = alpha, nperm = nperm)$root\r\n      }\r\n\r\n      if(alternative == \"two.sided\")\r\n      {\r\n       SLB = uniroot(StudentizedSI, interval = c(UB-4*sd(PairedDifftrue)/sqrt(I), UB), extendInt = \"yes\",\r\n                     Gamma = Gamma[i], PairedDiff=PairedDifftrue, alternative = \"greater\", alpha = alpha, nperm = nperm)$root\r\n       SUB = uniroot(StudentizedSI, interval = c(LB, LB+4*sd(PairedDifftrue)/sqrt(I)), extendInt = \"yes\",\r\n                     Gamma = Gamma[i], PairedDiff=PairedDifftrue, alternative = \"less\", alpha = alpha, nperm = nperm)$root\r\n      }\r\n\r\n      lb[i] = SLB\r\n      ub[i] = SUB\r\n      }\r\n\r\n    SImat = cbind(Gamma, lb, ub)\r\n    colnames(SImat) = c(\"Gamma\", \"Lower Bound\", \"Upper Bound\")\r\n    }\r\n    if(Changepoint == F & SensitivityInterval == F)\r\n    {\r\n      return(list(Gamma=Gamma, pval = pvalret, GammaPval = Pmatrix))\r\n    }\r\n    if(Changepoint == F & SensitivityInterval == T)\r\n    {\r\n      return(list(Gamma = Gamma, pval = pvalret, GammaPval = Pmatrix, SensitivityInterval = SImat))\r\n    }\r\n    if(Changepoint == T & SensitivityInterval == F)\r\n    {\r\n      return(list(Gamma = Gamma, pval = pvalret, GammaPval = Pmatrix, Changepoint = change))\r\n    }\r\n    if(Changepoint == T & SensitivityInterval == T)\r\n    {\r\n      return(list(Gamma = Gamma, pval = pvalret, GammaPval = Pmatrix, Changepoint = change,\r\n                  SensitivityInterval = SImat))\r\n    }\r\n\r\n}\r\n\r\n####These are auxiliary functions used for root finding and for calculating columnwise variances in StudentizedSensitivity\r\nStudentizedChangepoint = function(Gamma, PairedDiff, null, alternative, alpha, nperm)\r\n{\r\n  alphachange = alpha\r\n  StudentizedSensitivity(PairedDiff, null, alpha, alternative, Gamma, nperm, Changepoint = F, SensitivityInterval = F)$pval - alphachange\r\n}\r\n\r\nStudentizedSI = function(null,  Gamma, PairedDiff,  alternative, alpha, nperm)\r\n{\r\n  StudentizedSensitivity(PairedDiff, null, alpha, alternative, Gamma, nperm, Changepoint = F, SensitivityInterval = F)$pval - alpha\r\n}\r\n\r\nBoundFinder = function(null,  PairedDiff, Gamma)\r\n{\r\n  mean(PairedDiff - null - (Gamma-1)/(1+Gamma)*abs(PairedDiff-null))\r\n}\r\n\r\ncolVars <- function(x) {\r\n  N = nrow(x)\r\n  (colSums(x^2) - colSums(x)^2/N) / (N-1)\r\n}\r\n\r\n\r\n\r\nWe select the pair differences for PM\\(_{10}\\) concentrations in \\(t\\) and run the function for \\(\\Gamma\\)=2:\r\n\r\n\r\n# we select the relevant pair differences\r\nPairedDiff <- data_pair_difference_pollutant %>%\r\n  filter(pollutant == \"PM10\" & time == 0) %>%\r\n  pull(difference)\r\n\r\n# we run the function\r\ndata_sensitivity_pm10_0 <- StudentizedSensitivity(\r\n  PairedDiff,\r\n  null = 0,\r\n  alpha = 0.05,\r\n  alternative = \"two.sided\",\r\n  Gamma = 2,\r\n  nperm = 50000,\r\n  Changepoint = T,\r\n  SensitivityInterval = T\r\n)$SensitivityInterval %>%\r\n  as_tibble() %>%\r\n  mutate_all(~ round(., 2)) \r\n\r\n# save results\r\nsaveRDS(data_sensitivity_pm10_0, here::here(\"inputs\", \"1.data\", \"5.matched_data\", \"data_sensitivity_pm10_0.rds\"))\r\n\r\n\r\n\r\nWe display below the results:\r\n\r\n\r\nPlease show me the code!\r\n\r\nreadRDS(\r\n  here::here(\r\n    \"inputs\",\r\n    \"1.data\",\r\n    \"5.matched_data\",\r\n    \"data_sensitivity_pm10_0.rds\"\r\n  )\r\n) %>%\r\n  datatable(.)\r\n\r\n\r\n\r\n{\"x\":{\"filter\":\"none\",\"data\":[[\"1\"],[2],[0.52],[9]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>Gamma<\\/th>\\n      <th>Lower Bound<\\/th>\\n      <th>Upper Bound<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,2,3]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}\r\nWe then implement the same procedure but for concentrations in \\(t+1\\):\r\n\r\n\r\n# we select the relevant pair differences\r\nPairedDiff <- data_pair_difference_pollutant %>%\r\n  filter(pollutant == \"PM10\" & time == 1) %>%\r\n  pull(difference)\r\n\r\n# we run the function\r\ndata_sensitivity_pm10_1 <- StudentizedSensitivity(\r\n  PairedDiff,\r\n  null = 0,\r\n  alpha = 0.05,\r\n  alternative = \"two.sided\",\r\n  Gamma = 2,\r\n  nperm = 50000,\r\n  Changepoint = T,\r\n  SensitivityInterval = T\r\n)$SensitivityInterval %>%\r\n  as_tibble() %>%\r\n  mutate_all( ~ round(., 2)) \r\n\r\n# save results\r\nsaveRDS(data_sensitivity_pm10_1, here::here(\"inputs\", \"1.data\", \"5.matched_data\", \"data_sensitivity_pm10_1.rds\"))\r\n\r\n\r\n\r\nWe display below the results:\r\n\r\n\r\nPlease show me the code!\r\n\r\nreadRDS(\r\n  here::here(\r\n    \"inputs\",\r\n    \"1.data\",\r\n    \"5.matched_data\",\r\n    \"data_sensitivity_pm10_1.rds\"\r\n  )\r\n) %>%\r\n  datatable(.)\r\n\r\n\r\n\r\n{\"x\":{\"filter\":\"none\",\"data\":[[\"1\"],[2],[-0.19],[10.04]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>Gamma<\\/th>\\n      <th>Lower Bound<\\/th>\\n      <th>Upper Bound<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,2,3]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}\r\nDoes pairing improve precision?\r\nTo check that our pair matching procedure improves precision, we compare the estimate of the variance for a pair experiment with the one of a complete experiment (the formula can be found in Imbens & Rubin 2015’s textbook):\r\n\r\n\r\nPlease show me the code!\r\n\r\n# compute estimates of the sampling variability\r\n# for a complete experiment\r\nsampling_variability_complete <- data_matched %>%\r\n  select(is_treated, mean_no2, mean_o3, mean_pm10) %>%\r\n  pivot_longer(\r\n    cols = c(mean_no2:mean_pm10),\r\n    names_to = \"pollutant\",\r\n    values_to = \"concentration\"\r\n  ) %>%\r\n  group_by(pollutant, is_treated) %>%\r\n  mutate(\r\n    n_obs = n(),\r\n    average_concentration = mean(concentration),\r\n    squared_difference = (concentration - average_concentration) ^\r\n      2,\r\n    variance_group = sum(squared_difference) / (n_obs - 1)\r\n  ) %>%\r\n  summarise(variance_component = mean(variance_group / n_obs)) %>%\r\n  group_by(pollutant) %>%\r\n  summarise(\r\n    variance = sum(variance_component),\r\n    standard_error_complete = sqrt(variance)\r\n  ) %>%\r\n  select(-variance) %>%\r\n  mutate(\r\n    pollutant = case_when(\r\n      pollutant == \"mean_no2\" ~ \"NO2\",\r\n      pollutant == \"mean_o3\" ~ \"O3\",\r\n      pollutant == \"mean_pm10\" ~ \"PM10\"\r\n    )\r\n  )\r\n\r\n# estimates of the sampling variability for a pair experiment\r\nsampling_variability_pair <- data_se_neyman_pair %>%\r\n  filter(time == 0 & pollutant != \"PM2.5\") %>%\r\n  select(-time) %>%\r\n  rename(standard_error_pair = standard_error)\r\n\r\n# merge the two datasets and display results\r\nleft_join(sampling_variability_pair,\r\n          sampling_variability_complete,\r\n          by = c(\"pollutant\")) %>%\r\n  mutate(\r\n    \"Precision Improvement (%)\" = (standard_error_pair - standard_error_complete) /\r\n      standard_error_complete * 100\r\n  ) %>%\r\n  mutate_at(vars(standard_error_pair, standard_error_complete), ~ round(., 2)) %>%\r\n  mutate(`Precision Improvement (%)` = round(`Precision Improvement (%)`, 0)) %>%\r\n  rename(\r\n    \"Pollutant\" = pollutant,\r\n    \"S.E Pair Experiment\" = standard_error_pair,\r\n    \"S.E Complete Experiment\" = standard_error_complete\r\n  ) %>%\r\n  datatable(.)\r\n\r\n\r\n\r\n{\"x\":{\"filter\":\"none\",\"data\":[[\"1\",\"2\",\"3\"],[\"NO2\",\"O3\",\"PM10\"],[2.5,2.17,1.4],[1.76,2.83,1.35],[42,-23,4]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>Pollutant<\\/th>\\n      <th>S.E Pair Experiment<\\/th>\\n      <th>S.E Complete Experiment<\\/th>\\n      <th>Precision Improvement (%)<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[2,3,4]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}\r\nComparison with an Outcome Regression Analysis on Initial Data\r\nFinally, we ran a simple time-stratified regression model on the matching data to see how the results differ with those found in our matched data analysis. We only adjust for calendar indicator and weather covariate measured at time \\(t\\). We load the matching data:\r\n\r\n\r\n# load matching data\r\ndata_matching <-\r\n  readRDS(here::here(\"inputs\", \"1.data\", \"5.matched_data\", \"matching_data.Rds\"))\r\n\r\n\r\n# reshape in long according to pollutants\r\ndata_regression_analysis <- data_matching %>%\r\n  pivot_longer(\r\n    cols = c(\r\n      contains(\"no2\"),\r\n      contains(\"o3\"),\r\n      contains(\"pm10\"),\r\n      contains(\"pm25\")\r\n    ),\r\n    names_to = \"variable\",\r\n    values_to = \"concentration\"\r\n  ) %>%\r\n  mutate(\r\n    pollutant = NA %>%\r\n      ifelse(str_detect(variable, \"no2\"), \"NO2\", .) %>%\r\n      ifelse(str_detect(variable, \"o3\"), \"O3\", .) %>%\r\n      ifelse(str_detect(variable, \"pm10\"), \"PM10\", .) %>%\r\n      ifelse(str_detect(variable, \"pm25\"), \"PM2.5\", .)\r\n  ) %>%\r\n  mutate(time = 0 %>%\r\n           ifelse(str_detect(variable, \"lag_1\"),-1, .) %>%\r\n           ifelse(str_detect(variable, \"lead_1\"), 1, .)) %>%\r\n  select(-variable)\r\n\r\n# we nest the data by pollutant and time\r\ndata_regression_analysis <- data_regression_analysis %>%\r\n  group_by(pollutant, time) %>%\r\n  nest()\r\n\r\n\r\n\r\nWe run the regression model:\r\n\r\n\r\n# running the model\r\ndata_regression_analysis <- data_regression_analysis %>%\r\n  mutate(\r\n    # regression model\r\n    model = map(data, ~lm(concentration ~ is_treated + \r\n                                 temperature_average + I(temperature_average^2) + \r\n                                 temperature_average_lag_1 + I(temperature_average_lag_1^2) +\r\n                                 rainfall_duration + rainfall_duration_lag_1 +\r\n                                 humidity_average + humidity_average_lag_1 +\r\n                                 wind_speed + wind_speed_lag_1 +\r\n                                 weekday + holidays_dummy +\r\n                                 bank_day_dummy + month*as.factor(year), data = .)))\r\n\r\n# transform in long according to models\r\ndata_regression_analysis <- data_regression_analysis %>%\r\n  pivot_longer(cols = c(model), names_to = \"model\", values_to = \"coefficients\") %>%\r\n  select(-data)\r\n\r\n# tidy regression ouputs\r\ndata_regression_analysis <- data_regression_analysis %>%\r\n  mutate(models_dfs = map(coefficients, ~ broom::tidy(.)))\r\n\r\n# unnest results and select coefficient for total gross tonnage\r\ndata_regression_analysis <- data_regression_analysis %>%  \r\n  unnest(models_dfs) %>%\r\n  dplyr::filter(term==\"is_treatedTRUE\") %>%\r\n  select(pollutant, time, estimate, std.error)\r\n\r\n# we compute the 95% confidence intervals\r\ninterval_95 <- -qnorm((1-0.95)/2)\r\n\r\n# compute lower and upper bound of each interval\r\ndata_regression_analysis <- data_regression_analysis %>%\r\n  mutate(ci_lower_95 = estimate - std.error*interval_95,\r\n         ci_upper_95 = estimate + std.error*interval_95)\r\n\r\n\r\n\r\nWe draw the graph of results:\r\n\r\n\r\nPlease show me the code!\r\n\r\n# create an indicator to alternate shading of confidence intervals\r\ndata_regression_analysis <- data_regression_analysis %>%\r\n  arrange(pollutant, time) %>%\r\n  mutate(stripe = ifelse((time %% 2) == 0, \"Grey\", \"White\")) %>%\r\n  ungroup()\r\n\r\n# make the graph\r\ngraph_regression_ci <-\r\n  ggplot(data_regression_analysis,\r\n         aes(x = as.factor(time), y = estimate)) +\r\n  geom_rect(\r\n    aes(fill = stripe),\r\n    xmin = as.numeric(as.factor(data_regression_analysis$time)) - 0.42,\r\n    xmax = as.numeric(as.factor(data_regression_analysis$time)) + 0.42,\r\n    ymin = -Inf,\r\n    ymax = Inf,\r\n    color = NA,\r\n    alpha = 0.4\r\n  ) +\r\n  geom_hline(yintercept = 0,\r\n             color = \"black\",\r\n             size = 0.3) +\r\n  geom_pointrange(\r\n    aes(\r\n      x = as.factor(time),\r\n      y = estimate,\r\n      ymin = ci_lower_95 ,\r\n      ymax = ci_upper_95\r\n    ),\r\n    size = 0.5,\r\n    colour = my_blue,\r\n    lwd = 0.8\r\n  ) +\r\n  scale_y_continuous(breaks = scales::pretty_breaks(n = 8)) +\r\n  facet_wrap( ~ pollutant, ncol = 4) +\r\n  scale_fill_manual(values = c('gray96', \"white\")) +\r\n  guides(fill = FALSE) +\r\n  ylab(\"Average Increase in\\n Concentrations (µg/m³)\") + xlab(\"Day\") +\r\n  theme_tufte() +\r\n  theme(axis.text.x = element_text(margin = ggplot2::margin(t = 0, unit = \"cm\")))\r\n\r\n\r\n# print the graph\r\ngraph_regression_ci\r\n\r\n\r\n\r\nPlease show me the code!\r\n\r\n# save the graph\r\nggsave(\r\n  graph_regression_ci,\r\n  filename = here::here(\"inputs\", \"3.outputs\", \"2.matching_analysis\", \"graph_regression_ci.pdf\"),\r\n  width = 16,\r\n  height = 8,\r\n  units = \"cm\",\r\n  device = cairo_pdf\r\n)\r\n\r\n\r\n\r\nWe display below the values of the point estimates and 95% confidence intervals:\r\n\r\n\r\n{\"x\":{\"filter\":\"none\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\"],[\"NO2\",\"NO2\",\"NO2\",\"O3\",\"O3\",\"O3\",\"PM10\",\"PM10\",\"PM10\",\"PM2.5\",\"PM2.5\",\"PM2.5\"],[-1,0,1,-1,0,1,-1,0,1,-1,0,1],[0.5,-0.5,0.8,-0.9,-0.9,1.1,3.9,5.5,7.4,2.8,4,5.7],[0.1,-0.9,0.4,-1.4,-1.4,0.6,3.4,5,6.9,2.1,3.3,5],[0.9,-0.2,1.2,-0.4,-0.5,1.7,4.5,6,8,3.6,4.7,6.4]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>Pollutant<\\/th>\\n      <th>Time<\\/th>\\n      <th>Point Estimate<\\/th>\\n      <th>Lower Bound of the 95% Confidence Interval<\\/th>\\n      <th>Upper Bound of the 95% Confidence Interval<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[2,3,4,5]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}\r\n\r\n\r\n\r\n",
      "last_modified": "2022-04-08T10:22:38+02:00"
    },
    {
      "path": "index.html",
      "title": "Improving the Design Stage of Air Pollution Studies Based On Wind Patterns",
      "author": [],
      "contents": "\r\n\r\n          \r\n          \r\n          Improving the Design Stage of Air Pollution Studies Based On Wind Patterns\r\n          \r\n          \r\n          Home\r\n          Article\r\n          \r\n          \r\n          Data\r\n           \r\n          ▾\r\n          \r\n          \r\n          Data Wrangling\r\n          EDA\r\n          \r\n          \r\n          \r\n          \r\n          Matching Analysis\r\n           \r\n          ▾\r\n          \r\n          \r\n          Matching Procedure\r\n          Initial Data vs. Matched Data\r\n          Covariates Balance\r\n          Balance Improvement\r\n          Analysis of Results\r\n          \r\n          \r\n          \r\n          \r\n          \r\n          ☰\r\n          \r\n          \r\n      \r\n        \r\n          \r\n            \r\n              \r\n            \r\n              Improving the Design Stage of Air Pollution Studies Based On Wind Patterns\r\n            \r\n            \r\n              \r\n                \r\n                    \r\n                      \r\n                        \r\n                      \r\n                    \r\n                  \r\n                                    \r\n                    \r\n                      \r\n                        \r\n                      \r\n                    \r\n                  \r\n                                  \r\n            \r\n          \r\n        \r\n\r\n          \r\n            Hello and welcome!\r\n            This website gathers all the materials for the paper Improving the Design Stage of Air Pollution Studies Based On Wind Patterns by Léo Zabrocki, Anna Alari and Tarik Benmarhnia.\r\n            To illustrate how our approach works, we study the effect of North-East winds on particulate matter concentrations in Paris over the 2008-2018 period. We were not allowed to share weather data from Météo-France so we added some noise to the weather parameters.\r\n            The website is structured as follows:\r\n            A PDF version of preprint of the article is accessible through the Article.\r\n            The Data tab describes the data wrangling procedure. It also contains a detailed exploratory data analysis.\r\n            The Matching Analysis tab presents all steps to implement the matching procedure, check covariates balance, analyse the matched data and carry out robustness checks.\r\n            The GitHub directory contains the R codes to reproduce all results of the article.\r\n            \r\n        \r\n      \r\n    \r\n\r\n    \r\n      \r\n        \r\n          \r\n            \r\n              \r\n            \r\n              Improving the Design Stage of Air Pollution Studies Based On Wind Patterns\r\n            \r\n            \r\n              \r\n                \r\n                                    \r\n                    \r\n                      \r\n                    \r\n                  \r\n                                    \r\n                    \r\n                      \r\n                    \r\n                  \r\n                                  \r\n              \r\n            \r\n            \r\n              Hello and welcome!\r\n              This website gathers all the materials for the paper Improving the Design Stage of Air Pollution Studies Based On Wind Patterns by Léo Zabrocki, Anna Alari and Tarik Benmarhnia.\r\n              To illustrate how our approach works, we study the effect of North-East winds on particulate matter concentrations in Paris over the 2008-2018 period. We were not allowed to share weather data from Météo-France so we added some noise to the weather parameters.\r\n              The website is structured as follows:\r\n              A PDF version of preprint of the article is accessible through the Article.\r\n              The Data tab describes the data wrangling procedure. It also contains a detailed exploratory data analysis.\r\n              The Matching Analysis tab presents all steps to implement the matching procedure, check covariates balance, analyse the matched data and carry out robustness checks.\r\n              The GitHub directory contains the R codes to reproduce all results of the article.\r\n              \r\n        \r\n      \r\n    \r\n\r\n    \r\n    \r\n    ",
      "last_modified": "2022-04-08T10:22:38+02:00"
    },
    {
      "path": "README.html",
      "author": [],
      "contents": "\r\nImproving the Design Stage of Air Pollution Studies Based On Wind Patterns\r\nThis repo provides all the necessary materials to reproduce the analysis of our paper entitled Improving the Design Stage of Air Pollution Studies Based On Wind Patterns.\r\nThe website of the tutorial can be accessed at this link: https://lzabrocki.github.io/design_stage_wind_air_pollution/\r\nShould you find any errors or have any questions, please dot not hesitate to reach me.\r\n\r\n\r\n",
      "last_modified": "2022-04-08T11:02:01+02:00"
    }
  ],
  "collections": []
}
